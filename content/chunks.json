[
  {
    "id": "d592cbf0-e312-4598-a6ac-687a2566534e",
    "source_file": "README_DS_Bootcamp.Day00-1.md",
    "section": "UNIX Command Line Tools",
    "content": "Summary: On the first day, we will help you to acquire the skills of using UNIX\ncommand-line tools for basic data science tasks. You will learn how to use curl, sort,\nuniq, jq, sed, and cat for data collection and preprocessing.\n\nüí° –ù–∞–∂–º–∏ —Å—é–¥–∞, —á—Ç–æ–±—ã –ø–æ–¥–µ–ª–∏—Ç—å—Å—è —Å –Ω–∞–º–∏ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é –Ω–∞ —ç—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç. –≠—Ç–æ –∞–Ω–æ–Ω–∏–º–Ω–æ –∏ –ø–æ–º–æ–∂–µ—Ç –Ω–∞—à–µ–π –∫–æ–º–∞–Ω–¥–µ —Å–¥–µ–ª–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∑–∞–ø–æ–ª–Ω–∏—Ç—å –æ–ø—Ä–æ—Å —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞."
  },
  {
    "id": "2089b80c-72cf-4055-b97a-e27a8bc996e3",
    "source_file": "README_DS_Bootcamp.Day00-1.md",
    "section": "Contents",
    "content": "1. Chapter I 1.1. Foreword\n2. Chapter II 2.1. Instructions\n3. Chapter III 3.1. Exercise 00 : First shell script\n4. Chapter IV 4.1. Exercise 01 : Transforming JSON to CSV\n5. Chapter V 5.1. Exercise 02 : Sorting a file\n6. Chapter VI 6.1. Exercise 03 : Replacing strings in a file\n7. Chapter VII 7.1. Exercise 04 : Descriptive statistics\n8. Chapter VIII \n   8.1. Exercise 05 : Partitioning and concatenation"
  },
  {
    "id": "af941dc8-ee01-41b4-99c7-0c7a56b059f9",
    "source_file": "README_DS_Bootcamp.Day00-1.md",
    "section": "Foreword",
    "content": "We as Humanity has long known that data helps us to make better decisions. In\nAncient Egypt, the government would conduct censuses to get a better\nunderstanding of how much taxes they could gather from the population. Even\nearlier, shepherds would count livestock to find out how many animals they could sell\nand how many they needed for the production of goods.\n\nSince then, we have been developing more and more sophisticated algorithms for\ndata processing. Now, we are able to replace something that we do not know with a\nprediction from machine learning algorithms. This helps us to prepare for the future:\nto predict demand for our goods and to make the according adjustments in our\nfacilities. We can predict whether a person will return their credit or not so we can put\nour money aside for others and reap greater profits.\n\nWe have not only been developing algorithms but technologies and tools that have\nmade data analysis cheaper and more convenient. They have democratized the\nwhole field of data. Todays, it is much easier for a company to start using data for its\nown benefit. That is why there is so much hype around big data, artificial intelligence,\nand other such buzzwords.\n\nEverybody can use data. Everybody can get value from it. Not only those who have\na lot of money and resources, as was the case in the past.\n\nAs noted in the TV series Mr. Robot, ‚Äúit‚Äôs an exciting time in the world right now‚Äù."
  },
  {
    "id": "c718b870-5ae4-46b8-a7e0-234137bb6884",
    "source_file": "README_DS_Bootcamp.Day00-1.md",
    "section": "Instructions",
    "content": "* Use this page as your only reference. Do not listen to any rumors and speculations\n  about how to prepare your solution.\n* Here and further on we use Python 3 as the only correct version of Python.\n* The python files for python exercises (module01, module02, module03) must have\n  the following block at the end: if __name__ == ‚Äò__main__‚Äô.\n* Pay attention to the permissions of your files and directories.\n* To be assessed your solution must be in your GIT repository.\n* Your solutions will be evaluated by your piscine peers.\n* You should not leave any other files in your directory other than those explicitly\n  specified in the exercise instructions. It is recommended that you modify\n  your .gitignore to avoid any accidents.\n* When you need to get precise output in your programs, it is forbidden to display a\n  precalculated output instead of performing the exercise correctly.\n* Have a question? Ask your neighbor on the right. If that fails, try your neighbor\n  on the left.\n* Your reference materials: peers / Internet / Google.\n* Read the examples carefully. They may require things that are not otherwise spec-\n  ified in the subject.\n* And may the Force be with you!"
  },
  {
    "id": "77a195ce-31b7-499d-b7d0-bfd27b7256bd",
    "source_file": "README_DS_Bootcamp.Day00-1.md",
    "section": "Exercise 00 : First shell script",
    "content": "Exercise 00\n\nFirst shell script\n\nTurn-in directory : ex00/\n\nFiles to turn in : hh.sh, hh.json\n\nAllowed functions : curl, jq\n\nIn this exercise, you will need to interact with the HeadHunter API to parse some\ninformation about vacancies. In order to do this, you will need to understand how\nboth curl and the HeadHunter API work.\n\nWrite a shell script that:\n\n* gets the name of a vacancy - ‚Äòdata scientist‚Äô as an argument (some later exercises\n  will be based on this),\n* downloads information about the first 20 vacancies corresponding to the search\n  parameters,\n* stores it in a file with the name hh.json.\n\nThe result in the file must be formatted in such a way that each field is placed on a\ndifferent line. See the example below:\n\n!0\n\nYour script must be executable. The interpreter to use is /bin/sh.\n\nPut your script as well as your result of parsing in the folder ex00 in the root directory\nof your repository."
  },
  {
    "id": "21dd8a94-92d9-4bc8-9551-a46504da6bb5",
    "source_file": "README_DS_Bootcamp.Day00-1.md",
    "section": "Exercise 01 : Transforming JSON to CSV",
    "content": "Exercise 01\n\nTransforming JSON to CSV\n\nTurn-in directory : ex01/\n\nFiles to turn in : filter.jq, json_to_csv.sh, hh.csv\n\nAllowed functions : jq\n\nWhat you got in the previous exercise was a JSON file. It is a popular file format for\nAPIs but can be inconvenient for actual data analysis. So, you will need to convert it\ninto a more convenient CSV file.\n\nWrite a shell script called json_to_csv.sh that:\n\n* executes jq with a filter written in a separate file filter.jq\n* filters the following 5 columns corresponding to the vacancies: ‚Äúid‚Äù, ‚Äúcreated_at‚Äù,\n  ‚Äúname‚Äù, ‚Äúhas_test‚Äù, and ‚Äúalternate_url‚Äù\n* saves the result to the CSV file hh.csv\n\nSee the example below:\n\n!1\n\nThe CSV file must have headers in the first row.\n\nYour script must be executable. The interpreter to use is /bin/sh.\n\nPut your filter file - the file that converts JSON to CSV, as well as the result of your\nconversion in the ex01 folder in the root directory of your repository."
  },
  {
    "id": "a80a5e35-f5d4-40d6-ba5a-60b1fd2adb33",
    "source_file": "README_DS_Bootcamp.Day00-1.md",
    "section": "Exercise 02 : Sorting a file",
    "content": "Exercise 02\n\nSorting a file\n\nTurn-in directory : ex02/\n\nFiles to turn in : sorter.sh, hh_sorted.csv\n\nAllowed functions : cat, sort, head, tail\n\nSometimes having your data in a non-random order, having it but sorted in some\nway can be efficient for later stages of data analysis. So in this exercise, you will\nneed to sort your CSV file with several columns.\n\nWrite a shell script called sorter.sh that:\n\n* sorts the hh.csv file from the previous exercise according to the column\n  ‚Äúcreated_at‚Äù and then by the ‚Äúid‚Äù in ascending order\n* saves the result in the CSV file hh_sorted.csv\n\nThe CSV file must still have headers in its first row.\n\nYour script must be executable. The interpreter to use is /bin/sh.\n\nPut your shell script as well as your result of the sorting in the folder ex02 in the root\ndirectory of your repository."
  },
  {
    "id": "f377c7d8-5356-41c0-9d89-1de212e3f578",
    "source_file": "README_DS_Bootcamp.Day00-1.md",
    "section": "Exercise 03 : Replacing strings in a file",
    "content": "Exercise 03\n\nReplacing strings in a file\n\nTurn-in directory : ex03/\n\nFiles to turn in : cleaner.sh, hh_positions.csv\n\nAllowed functions : no restrictions\n\nRaw data is a mess. Before you can start analyzing it, you need to do a lot of\npreprocessing. In this exercise, that is what you are continuing to do. If you look at\nyour file from the previous exercise, you will see that every position name of contains\n‚ÄúData Scientist‚Äù(you don‚Äôt have to check this). This is not surprise since we used that\nstring as the keyword for the search in the HeadHunter API. But for us, as for the\nalgorithms, it does not give any useful information. To be honest, it is just noise that\nworsens data analysis.\n\nWrite a shell called script cleaner.sh that:\n\n* takes ‚ÄúJunior‚Äù, ‚ÄúMiddle‚Äù, ‚ÄúSenior‚Äù from the names of position, if the name does not\n  contain any of these words use ‚Äú-‚Äù (e.g. ‚ÄúSenior Data Scientist‚Äù -> ‚ÄúSenior‚Äù, ‚Äúanalyst\n  /(data scientist)‚Äù -> ‚Äú-‚Äù, ‚Äú–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç / data scientist (big data, –ø—Ä–æ–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è\n  –∞–Ω–∞–ª–∏—Ç–∏–∫–∞, data mining)‚Äù -> ‚Äú-‚Äù ), if there are several of them, keep them all(e.g.\n  ‚ÄúMiddle/Senior Data Scientist‚Äù -> ‚ÄúMiddle/Senior‚Äù)\n* saves the result in the CSV file hh_positions.csv.\n\nYou can see the example below:\n\n    \"id\",\"created_at\",\"name\",\"has_test\",\"alternate_url\"\n    \"35218725\",\"2020-04-11T18:03:53+0300\",\"Junior\",false,\"https://hh.ru/vacancy/35218725\"\n    \"36359628\",\"2020-04-11T19:25:48+0300\",\"Senior\",false,\"https://hh.ru/vacancy/36359628\"\n    \"35895583\",\"2020-04-12T12:06:33+0300\",\"-\",false,\"https://hh.ru/vacancy/35895583\"\n\nThe CSV file must still have headers in its first row and be sorted as per the previous\nexercise.\n\nYour script must be executable. The interpreter to use is /bin/sh.\n\nPut your shell script as well as your result from cleaning in the ex03 folder in the root\ndirectory of your repository."
  },
  {
    "id": "dd339323-5eca-4f10-98c9-649144e72566",
    "source_file": "README_DS_Bootcamp.Day00-1.md",
    "section": "Exercise 04 : Descriptive statistics",
    "content": "Exercise 04\n\nDescriptive statistics\n\nTurn-in directory : ex04/\n\nFiles to turn in : counter.sh, hh_uniq_positions.csv\n\nAllowed functions : no restrictions\n\nBefore doing anything more sophisticated, it is best to get a basic knowledge of your\ndata. In this exercise, you will need to count the unique positions in your file. As a\nresult, you can understand that your data skewed somehow: for instance, there are\nmore seniors than juniors. Such facts might be useful for further analysis.\n\nWrite a shell script called counter.sh that:\n\n* counts unique values of the name column in the file you prepared in the\n* previous exercise,\n* sorts the table by that count in descending order\n* stores the result in the CSV file hh_uniq_positions.csv\n\nSee the example below:\n\n    \"name\",\"count\"\n    \"Junior\",10\n    \"Middle\",5\n    \"Senior\",3\n\nThe CSV file must have headers in the first row as in the example.\n\nYour script must be executable. The interpreter to use is /bin/sh.\nPut your shell script as well as the result of counting in the ex04 folder in the root\ndirectory of your repository."
  },
  {
    "id": "9046b83f-abed-458a-a78c-17c378be0c03",
    "source_file": "README_DS_Bootcamp.Day00-1.md",
    "section": "Exercise 05 : Partitioning and concatenation",
    "content": "Exercise 05\n\nPartitioning and concatenation\n\nTurn-in directory : ex05/\n\nFiles to turn in : partitioner.sh, concatenator.sh\n\nAllowed functions : no restrictions\n\nWhen you have a big dataset, sometimes it might be useful to slice it into partitions.\nEach partition has a specific range of keys. One of the popular ways to partition is to\ndo it by date. Each partition contains data on a specific date. In this exercise, you will\nneed to perform that task.\n\nWrite one shell script called partitioner.sh that:\n\n* takes as input the result of Exercise 03\n* stores slices of data with different \"created_at\" dates in separate CSV files named\n  for that date\n\nSee the example of such a file below:\n\n    \"id\",\"created_at\",\"name\",\"has_test\",\"alternate_url\"\n    \"35218725\",\"2020-04-11T18:03:53+0300\",\"Junior\",false,\"https://hh.ru/vacancy/35218725\"\n    \"36359628\",\"2020-04-11T19:25:48+0300\",\"Senior\",false,\"https://hh.ru/vacancy/36359628\"\n\nWrite another shell script called concatenator.sh that:\n\n* takes as input the separate files from the result of partitioner.sh\n* concatenates all separate files into one CSV file\n\nThe CSV files must have headers in the first row, as in the example. The CSV from\nthe result of concatenator.sh must be equal to the result of Exercise 3\n\nYour scripts must be executable. The interpreter to use is /bin/sh.\n\nPut your shell scripts in the ex05 folder in the root directory of your repository."
  },
  {
    "id": "7959a580-76b6-43c0-ac86-c468a7ebaaf5",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Intro to Python: Syntax and Semantics",
    "content": "Summary: Today we will help you acquire basic knowledge of the syntax and semantics\nof Python.\n\nüí° Tap here to leave your feedback on the project. It's anonymous and will help our team make your educational experience better. We recommend completing the survey immediately after the project."
  },
  {
    "id": "f4362b5f-140e-41d6-b1af-09dd73c638a6",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Contents",
    "content": "1. Chapter I 1.1. Foreword\n2. Chapter II 2.1. Instructions\n3. Chapter III 3.1. Specific instructions of the day\n4. Chapter IV 4.1. Exercise 00 : Data types\n5. Chapter V 5.1. Exercise 01 : Working with files\n6. Chapter VI 6.1. Exercise 02 : Search by key\n7. Chapter VII 7.1. Exercise 03 : Search by value and by key\n8. Chapter VIII 8.1. Exercise 04 : Dictionaries\n9. Chapter IX 9.1. Exercise 05 : Search by value or by key\n10. Chapter X 10.1. Exercise 06 : Sorting a dictionary\n11. Chapter XI 11.1. Exercise 07 : Sets\n12. Chapter XII 12.1. Exercise 08 : Working with strings as lists\n13. Chapter XIII \n    13.1. Exercise 09 : Caesar cipher"
  },
  {
    "id": "358559c1-26e3-40d5-9e05-b9b626a86ffb",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Foreword",
    "content": "Python is the most popular programming language for data science. Why is it so good\nfor that kind of task? Python is an interpreted language. That means that you can easily\ninteract with different pieces of code and get fast results. And that is exactly what we\nneed if we want to analyze data from different angles or try different hyperparameters for\na machine learning model. Besides this, Python has a lot of libraries that are suitable for\nscientific tasks, including data science. Add to this a pretty simple syntax and you will\nget the most popular programming language for data science tasks.\n\nJust for fun, look at these 19 beautiful guiding principles that influenced the design\nof Python:\n\n* Beautiful is better than ugly.\n* Explicit is better than implicit.\n* Simple is better than complex.\n* Complex is better than complicated.\n* Flat is better than nested.\n* Sparse is better than dense.\n* Readability counts.\n* Special cases aren‚Äôt special enough to break the rules.\n* Although practicality beats purity.\n* Errors should never pass silently.\n* Unless explicitly silenced.\n* In the face of ambiguity, refuse the temptation to guess.\n* There should be one - and preferably only one - obvious way to do it.\n* Although that way may not be obvious at first unless you‚Äôre Dutch.\n* Now is better than never.\n Although never is often better than right* now.\n* If the implementation is hard to explain, it‚Äôs a bad idea.\n* If the implementation is easy to explain, it may be a good idea.\n* Namespaces are one honking great idea - let‚Äôs do more of those!\n\nIn case you forget any of them, you can just write import this in Python and ythey\nwill quickly appear."
  },
  {
    "id": "ad442a09-e96d-42cd-a2cc-21d9423befc5",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Instructions",
    "content": "* Use this page as your only reference. Do not listen to any rumors or speculations\n  about how to prepare your solution.\n* Here and further on we use Python 3 as the only correct version of Python.\n* The python files for python exercises (module01, module02, module03) must have\n  the following block at the end: if __name__ == ‚Äò__main__‚Äô.\n* Pay attention to the permissions of your files and directories.\n* To be assessed your solution must be in your GIT repository.\n* Your solutions will be evaluated by your piscine peers.\n* You should not leave any files in your directory other than those explicitly specified\n  by the exercise instructions. It is recommended that you modify your .gitignore to\n  avoid any accidents.\n* When you need to get precise output in your programs, it is forbidden to display a\n  precalculated output instead of performing the exercise correctly.\n* Have a question? Ask your neighbor on the right. If that fails, try your neighbor\n  on the left.\n* Your reference material: peers / Internet / Google.\n* Remember, you can engage in discussion on the Intra Piscine forum.\n* Read the examples carefully. They may require things that are not otherwise spec-\n  ified in the subject.\n* And may the Force be with you!"
  },
  {
    "id": "674db949-8936-415e-943e-bc3e521601e3",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Specific instructions of the day",
    "content": "* No code in the global scope. Use functions!\n* Each file must ended with a function call in a condition similar to:\n  if __name__ == ‚Äô__main__‚Äô:\n  your_function( whatever, parameter, is, required )\n* You may place an error handling in this same condition.\n* No imports are allowed, except those explicitly mentioned in the section ‚ÄôAuthorized\n  functions‚Äô of the title block of each exercise.\n* You can use any built-in function if it is not prohibited in an exercise.\n* The exceptions raised by the open() function are not to be handled.\n* The interpreter to be used is Python 3"
  },
  {
    "id": "95f73aa1-3c51-4268-9e9c-9220c53b1b66",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Exercise 00 : Data types",
    "content": "Exercise 00\n\nData types\n\nTurn-in directory : ex00/\n\nFiles to turn in : data_types.py\n\nAllowed functions : any import is restricted\n\n* Like any other language, Python has several built-in data types. In this exercise,\n  you will become familiar with the most popular and useful ones.\n* Create a script called data_types.py in which you need to define a data_types()\n  function. In this function, you need to declare 8 variables with different types and\n  print their types on the standard output.\n* You must reproduce the following output exactly:\n\n  > python3 data_types.py\n  [int, str, float, bool, list, dict, tuple, set]\n* It is forbidden to explicitly write the data types in your print. Remember to call\n  your function at the end of your script as explained in the instructions for the day:\n\n  if __name__ == '__main__':\n  data_types()\n* Put your file in the ex00 folder in the root directory of your repository."
  },
  {
    "id": "feb2e422-f747-4a4d-9098-9fa9a0ad5802",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Exercise 01 : Working with files",
    "content": "Exercise 01\n\nWorking with files\n\nTurn-in directory : ex01/\n\nFiles to turn in : read_and_write.py\n\nAllowed functions : any import is restricted\n\n* For this exercise, you are free to define as many functions as you need and to name\n  them whatever you want. In the attached file ds.csv (you will recognize it from the\n  previous day), you will have several columns separated by a comma with different\n  data about vacancies.\n* Design a Python script called read_and_write.py whose role is to open the file\n  ds.csv, read the data it contains, replace all the comma delimiters with ‚Äô\\t‚Äô and\n  save it to another file ds.tsv. Be careful, your data may contain commas. If you\n  replace them, you will corrupt the data.\n* Put your script in the ex01 folder in the root directory of your repository."
  },
  {
    "id": "66da99e0-ce88-4308-a193-1ea132bd5f5a",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Exercise 02 : Search by key",
    "content": "Exercise 02\n\nSearch by key\n\nTurn-in directory : ex02/\n\nFiles to turn in : stock_prices.py\n\nAllowed functions : import sys\n\n* You have the following dictionaries to copy to one of your functions:\n\n  COMPANIES = {\n  'Apple': 'AAPL',\n  'Microsoft': 'MSFT',\n  'Netflix': 'NFLX',\n  'Tesla': 'TSLA',\n  'Nokia': 'NOK'\n  }\n\n  STOCKS = {\n  'AAPL': 287.73,\n  'MSFT': 173.79,\n  'NFLX': 416.90,\n  'TSLA': 724.88,\n  'NOK': 3.37\n  }\n* Write a program that takes a name of a company (ex: Apple) as an argument\n  and displays the stock price (ex: 287.73) on the standard output. If you give\n  the program a company that is not from the dictionary as an argument, your\n  script should display Unknown company. If there are no arguments, or too many\n  arguments, your program should do nothing and quit.\n\n  $> python3 stock_prices.py tesla\n  724.88\n  $> python3 stock_prices.py Facebook\n  Unknown company\n  $> python3 stock_prices.py Tesla Apple"
  },
  {
    "id": "4eb48d63-02d1-458c-baa3-4ccc01920d4b",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Exercise 03 : Search by value and by key",
    "content": "Exercise 03\n\nSearch by value and by key\n\nTurn-in directory : ex03/\n\nFiles to turn in : ticker_symbols.py\n\nAllowed functions : import sys\n\n* You have the same two dictionaries from the previous exercise. You should copy\n  them again in one of the functions of your script.\n* Create a program this time that takes a ticker symbol (ex: AAPL) and displays\n  the company name and the stock price with space as the delimiter. The rest of the\n  behavior must be identical to that of the previous exercise.\n\n  $> python3 ticker_symbols.py tsla\n  Tesla 724.88\n  $> python3 ticker_symbols.py FB\n  Unknown ticker\n  $> python3 ticker_symbols.py TSLA AAPL"
  },
  {
    "id": "0ee05b68-0f92-42bc-8ca7-d52c50d70dc9",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Exercise 04 : Dictionaries",
    "content": "Exercise 04\n\nDictionaries\n\nTurn-in directory : ex04/\n\nFiles to turn in : to_dictionary.py\n\nAllowed functions : any import is restricted\n\n* Create a script named to_dictionary.py into one of the functions of which you need\n  to copy the following list of the tuples as is:\n\n  list_of_tuples = [\n  ('Russia', '25'),\n  ('France', '132'),\n  ('Germany', '132'),\n  ('Spain', '178'),\n  ('Italy', '162'),\n  ('Portugal', '17'),\n  ('Finland', '3'),\n  ('Hungary', '2'),\n  ('The Netherlands', '28'),\n  ('The USA', '610'),\n  ('The United Kingdom', '95'),\n  ('China', '83'),\n  ('Iran', '76'),\n  ('Turkey', '65'),\n  ('Belgium', '34'),\n  ('Canada', '28'),\n  ('Switzerland', '26'),\n  ('Brazil', '25'),\n  ('Austria', '14'),\n  ('Israel', '12')\n  ]\n* Your script should transform this variable into a dictionary where the number is\n  the key and a country is the value. The same key may have several values as you\n  see. The script must display the content of the dictionary on standard output\n  accordingly to this precise formatting:\n\n  '132' : 'France'\n  '132' : 'Germany'\n  '178' : 'Spain'\n  ...\n* Think about why the order is not necessarily identical to that of the example."
  },
  {
    "id": "cc6cb5c1-418d-40f7-9d10-2e156ae4dd69",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Exercise 05 : Search by value or by key",
    "content": "Exercise 05\n\nSearch by value or by key\n\nTurn-in directory : ex05/\n\nFiles to turn in : all_stocks.py\n\nAllowed functions : import sys\n\n* You still have those two dictionaries from ex02. And you should still copy them\n  into one of your functions in the script.\n* Write a program that has the following behavior:\n  * the program must take as an argument a string containing many expressions\n    (to find whatever you want) separated by a comma\n  * for each expression of the string, the program must detect whether it is a\n    company name or a ticker symbol, or neither\n  * the program should not be case-sensitive but be able to work with white spaces\n  * if there are no arguments or too many arguments, the program displays nothing\n  * when there are two commas in a row in the string, the program does not\n    display anything\n  * the program must display the results separated by a line break and use the\n    following formatting:\n\n    $ python3 all_stocks.py 'TSLA , aPPle, Facebook'\n    TSLA is a ticker symbol for Tesla\n    Apple stock price is 287.73\n    Facebook is an unknown company or an unknown ticker symbol\n    $ python3 all_stocks.py 'TSLA,, apple'\n    $ python3 all_stocks.py 'TSLA, , apple'\n    $ python3 all_stocks.py TSLA AAPL"
  },
  {
    "id": "4c1e19c8-fa36-4132-82fa-bdc2fd055e2d",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Exercise 06 : Sorting a dictionary",
    "content": "Exercise 06\n\nSorting a dictionary\n\nTurn-in directory : ex06/\n\nFiles to turn in : dict_sorter.py\n\nAllowed functions : any import is restricted\n\n* In this exercise, you need to take the list of tuples from ex04 with the countries\n  and numbers and make a dictionary out of it where the countries are keys and the\n  numbers are values . You should copy it into one of your functions in the script.\n* Write a program that displays the country names in descending order by number,\n  then in alphabetical order by name if the numbers are equal. You need to display\n  one per line, without the numbers:\n\n  The USA\n  Spain\n  Italy\n  France\n  Germany\n  ..."
  },
  {
    "id": "9a9578aa-db6b-404e-8b50-f48d171e302d",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Exercise 07 : Sets",
    "content": "Exercise 07\n\nSets\n\nTurn-in directory : ex07/\n\nFiles to turn in : marketing.py\n\nAllowed functions : import sys\n\nIn this exercise, imagine that you work in a marketing department. You will operate\nwith different lists of email accounts. The first list is your clients‚Äô email accounts. The\nsecond list contains the email accounts of the participants in your most recent event\n(some of them were your clients). The third list contains the accounts of your clients who\nviewed your most recent promotional email.\n\nIn business terms, you need to:\n\n* Create a list of those clients who have not seen your promotional email yet. The list will\n  be sent to the call center to reach those people.\n* Create a list of the participants who are not your clients. You will send them an\n  introductory email about your products.\n* Create a list of the clients who did not participate in the event. You will send them\n  a link to the video and slides of the event.\n\nTechnical details:\n\n* Create different functions that convert your lists to sets and use the set operators\n  that you need to use to perform the aforementioned business tasks and return the\n  required lists of email accounts.\n* Arrange your code in a script. The script takes the name of the task to perform as\n  an argument: call_center, potential_clients, loyalty_program. If the wrong name\n  is given, raise an exception.\n* For this exercise you need to use the following three lists:\n\n  clients = ['andrew@gmail.com', 'jessica@gmail.com', 'ted@mosby.com',\n  'john@snow.is', 'bill_gates@live.com', 'mark@facebook.com',\n  'elon@paypal.com', 'jessica@gmail.com']\n  participants = ['walter@heisenberg.com', 'vasily@mail.ru',\n  'pinkman@yo.org', 'jessica@gmail.com', 'elon@paypal.com',\n  'pinkman@yo.org', 'mr@robot.gov', 'eleven@yahoo.com']\n  recipients = ['andrew@gmail.com', 'jessica@gmail.com', 'john@snow.is']"
  },
  {
    "id": "7f17d314-58dc-49c2-898b-98a2d6b1244d",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Exercise 08 : Working with strings as lists",
    "content": "Exercise 08\n\nWorking with strings as lists\n\nTurn-in directory : ex08/\n\nFiles to turn in : names_extractor.py, letter_starter.py\n\nAllowed functions : import sys\n\n* Imagine that you work in a corporation where the email accounts always have the\n  same template: name.surname@corp.com.\n* Create a script that takes the path to a file with such email accounts as an argument.\n  All the emails are delimited by ‚Äô\\n‚Äô in the file. The script should return a table\n  with the fields: Name, Surname, E-mail delimited by ‚Äô\\t‚Äô. Name and surname\n  values should start from a capital letter. The table should be stored in the file\n  employees.tsv.\n* The example:\n\n!1\n\n* Create another script that takes an email, searches the corresponding name from\n  the file created by the first script and returns the first paragraph of a letter:\n* Dear Ivan, welcome to our team. We are sure that it will be a pleasure to work with\n  you. That‚Äôs a precondition for the professionals that our company hires.\n* It is prohibited to use the structure ‚Äôla-la {0}‚Äô.format(text). Please, use f-strings.\n  They are faster and more readable."
  },
  {
    "id": "937fc641-50cd-4f31-b695-cb65c9bc477c",
    "source_file": "README_DS_Bootcamp.Day01-1.md",
    "section": "Exercise 09 : Caesar cipher",
    "content": "Exercise 09\n\nCaesar cipher\n\nTurn-in directory : ex09/\n\nFiles to turn in : caesar.py\n\nAllowed functions : import sys\n\n* There is something called Caesar cipher that helps encode some text using a shift\n  in the alphabetical order. For example, the encoded version of hello might be tqxxa\n  if we use a shift equal to 12\n* Write a program that will encode any string using a given shift or will decode any\n  string using a given shift accordingly to the argument given:\n\n  $ python3 caesar.py encode 'ssh -i private.key user@school21.ru' 12\n  eet -u bduhmfq.wqk geqd@eotaax21.dg\n  $ python3 caesar.py decode 'eet -u bduhmfq.wqk geqd@eotaax21.dg' 12\n  ssh -i private.key user@school21.ru\n* If the scripts are given a string with, for example, Cyrillic symbols, the scripts\n  should raise the exception The script does not support your language yet. If an\n  incorrect number of arguments is given, raise an exception"
  },
  {
    "id": "d1dd52ef-f3d7-4d3e-8e0d-151162c2659a",
    "source_file": "README_DS_Bootcamp.Day02-2.md",
    "section": "Intro to Python: OOP skills",
    "content": "Summary: Today we will help you acquire a basic knowledge of the OOP approach in\nPython.\n\nüí° Tap here to leave your feedback on the project. It's anonymous and will help our team make your educational experience better. We recommend completing the survey immediately after the project."
  },
  {
    "id": "c811b4f2-f14c-47a8-95bd-3c3cfeee5129",
    "source_file": "README_DS_Bootcamp.Day02-2.md",
    "section": "Contents",
    "content": "1. Chapter I 1.1. Foreword\n2. Chapter II 2.1. Instructions\n3. Chapter III 3.1. Specific instructions of the day\n4. Chapter IV 4.1. Exercise 00 : Simple class\n5. Chapter V 5.1. Exercise 01 : Method\n6. Chapter VI 6.1. Exercise 02 : Constructor\n7. Chapter VII 7.1. Exercise 03 : Nested class\n8. Chapter VIII 8.1. Exercise 04 : Inheritance\n9. Chapter IX 9.1. Exercise 05 : Config and the main program\n10. Chapter X \n    10.1. Exercise 06 : Logging"
  },
  {
    "id": "79de6de5-803e-44ce-b751-52fcfe9854dd",
    "source_file": "README_DS_Bootcamp.Day02-2.md",
    "section": "Foreword",
    "content": "A common complaint to data scientists is that they write shitcode (by the way, only for\neducational purposes you may find a lot of examples of Python shitcode here, provided\nstrictly for educational purposes). Why? Because the average data scientist uses a lot of\ninefficient techniques and hard coded variables and neglects object-oriented programming.\n\nDo not be like them.\n\nHere are the top few examples from the website mentioned above:\n\n* How to get the absolute value in just 6 lines of python\n\n  python\n  def absolute\\_value(value):\n      if str(value)[0]=='-':\n          value = -1 * value\n          return value\n      else:\n          return value\n  \n* How to evaluate the factorial of 40000 in approximately 1 second:\n\n  python\n  for module in next\\_possible\\_modules:\n      import math; math.factorial(40000) # approx. a 1 second operation\n      end\\_time = start\\_time + timedelta(minutes=module.duration)\n  \n* Gotta check that date\n\n  python\n  if (SelectionAndTimeData[1]  12 or \\\n          SelectionAndTimeData[3]  31 or \\\n          SelectionAndTimeData[4]  24 or \\\n          SelectionAndTimeData[5]  60 or \\\n          SelectionAndTimeData[2] 60):\n      print('*')\n      print(' Entered date is not valid')\n      print('*')"
  },
  {
    "id": "81f80490-e4db-4032-9329-e63deb025e1d",
    "source_file": "README_DS_Bootcamp.Day02-2.md",
    "section": "Instructions",
    "content": "* Use this page as your only reference. Do not listen to any rumors or speculations\n  about how to prepare your solution.\n* Here and further on we use Python 3 as the only correct version of Python.\n* The solutions for python exercises (module01, module02, module03) must include\n  the following block in the end: if __name__ == ‚Äò__main__‚Äô.\n* Pay attention to the permissions of your files and directories.\n* To be assessed your solution must be in your GIT repository.\n* Your solutions will be evaluated by your piscine mates.\n* You should not leave any additional files in your directory other than those explicitly\n  specified in the subject. It is recommended that you modify your .gitignore to avoid\n  any accidents.\n* When you need to get precise output in your programs, it is forbidden to display a\n  precalculated output instead of performing the exercise correctly.\n* Have a question? Ask your neighbor on the right. If that fails, try your neighbor\n  on the left.\n* Your reference material: peers / Internet / Google.\n* Read the examples carefully. They may require things that are not otherwise specified in the subject.\n* And may the Force be with you!"
  },
  {
    "id": "5fafc727-415a-43e4-b0a3-3ff3bfa4264e",
    "source_file": "README_DS_Bootcamp.Day02-2.md",
    "section": "Specific instructions of the day",
    "content": "* No code in the global scope. Use functions!\n* Each file must end with a function call in a condition similar to:\n\n  python\n  if __name__ == '__main__':"
  },
  {
    "id": "1de1c3fd-8d5b-4b7b-a793-65f4671dd685",
    "source_file": "README_DS_Bootcamp.Day02-2.md",
    "section": "your tests and your error handling",
    "content": "* Any exception not caught will invalidate your work, even in the event of an error\n  that you were asked to test.\n* No imports are allowed, except those explicitly mentioned in the section ‚ÄúAuthorized\n  functions‚Äù of the title block of each exercise.\n* Any built-in function is allowed."
  },
  {
    "id": "eef98950-2bfa-4b8f-9f46-11df26a2fcb4",
    "source_file": "README_DS_Bootcamp.Day02-2.md",
    "section": "Exercise 00 : Simple class",
    "content": "Exercise 00\n\nSimple class\n\nTurn-in directory : ex00/\n\nFiles to turn in : first_class.py\n\nAllowed functions : all imports are restricted\n\nThis is going to be an easy warm-up exercise to get you started with object-oriented\nprogramming in Python.\n\n* Create a python script called first_class.py that contains a class called Must_read.\n  It does the only thing reads the file data.csv and prints it. You can hardcode the\n  name of the csv file inside the class. Put print() inside your class (you will learn\n  about methods and constructors later, forget about them in this exercise).\n* data.csv contains the following data (you can create the file any way you want):\n\n  \n  head,tail\n  0,1\n  1,0\n  0,1\n  1,0\n  0,1\n  0,1\n  0,1\n  1,0\n  1,0\n  0,1\n  1,0\n  \n\nExample of launching the script:\n\n        $ python3 first_class.py     head,tail     0,1     1,0     0,1     1,0     0,1     0,1     0,1     1,0     1,0     0,1     1,0"
  },
  {
    "id": "cd8c1565-972a-45a5-b851-e7c6a2641529",
    "source_file": "README_DS_Bootcamp.Day02-2.md",
    "section": "Exercise 01 : Method",
    "content": "Exercise 01\n\nMethod\n\nTurn-in directory : ex01/\n\nFiles to turn in : first_method.py\n\nAllowed functions : all imports are is restricted\n\nIn the previous exercise, you managed to create a class. To be honest, nobody creates\nsuch classes in real life. Classes usually help to unite different functions with a common\ntopic and common parameters. That is a better way to organize them. In this case,\nfunctions are called methods.\n\n* In this exercise you need to move the code from the body of the class to the method\n  of that class with the name file_reader(). Methods are like functions - they can\n  return something. Classes are unable to do that. So you need to replace print()\n  with return() in the method. Change the name of the class to Research.\n* The script still must have the exact same behavior. It needs to display the content\n  of the file data.csv. Save the script with the name first_method.py."
  },
  {
    "id": "4d273d1b-ac2d-4d68-b83d-619135e80fac",
    "source_file": "README_DS_Bootcamp.Day02-2.md",
    "section": "Exercise 02 : Constructor",
    "content": "Exercise 02\n\nConstructor\n\nTurn-in directory : ex02/\n\nFiles to turn in : first_constructor.py\n\nAllowed functions : import sys, import os\n\nIt was not a very good idea to hardcode the name of the file in the method. It would\nbe great if we could give the path to the file as a parameter of the script. It would be\ngreat if we did not have to put the path in every method that we bring in later. There is\na solution. There can be a constructor in python classes: __init__(). It is the method\nthat runs first when the instance of a class is instantiated.\n\nModify your code in the following way:\n\n* Inside the class Research create an __init__() method that takes the path to the\n  file that needs to be read as an argument.\n* Modify the method file_reader(). This method does almost the same thing as in\n  the previous exercise - just reads the file and returns its data. The difference is that\n  the path to the file should be used from the __init__() method.\n* If a file with a different structure was given, and your program cannot read it, raise\n  an exception. The correct file contains a header with two strings delimited by a\n  comma. There are one or more lines after that that contain either 0 or 1 and never\n  both of them delimited by a comma.\n* Modify the main program. The script must still have the exact same behavior. The\n  path to the file should be given as an argument to the script. It needs to display\n  the content of the file data.csv. Save the script with the name first_constructor.py.\n\nExample of launching the script:\n\n\n$ python3 first_constructor.py data.csv\nhead,tail\n0,1\n1,0\n0,1\n1,0\n0,1\n0,1\n0,1\n1,0\n1,0\n0,1\n1,0"
  },
  {
    "id": "23809919-ca5a-49d9-b99c-ecd41b3d1144",
    "source_file": "README_DS_Bootcamp.Day02-2.md",
    "section": "Exercise 03 : Nested class",
    "content": "Exercise 03\n\nNested class\n\nTurn-in directory : ex03/\n\nFiles to turn in : first_nest.py\n\nAllowed functions : import sys, import os\n\nLet us go further with OOP in Python. Can a class be inside another class? Sure,\nwhy not? We can still benefit from it by giving our code a clearer structure by uniting\nseveral methods in one nested class.\n\nWhat you need to do in this exercise:\n\n* Modify the file_reader() method by adding one more argument has_header with\n  the default value True. You should use it if your file has a header, if it is not - it\n  should be False. The return of this method in this exercise is not a string anymore\n  but a list of lists [0, 1] or [1, 0]. So the argument has_header influences the logic\n  of how to process the file. In both cases, the return should be the same without a\n  header.\n* Create a nested class called Calculations without a constructor. In that class,\n  create two methods: counts() and fractions(). The method counts() takes data from\n  file_reader() as an argument and returns the count of heads and tails, for example,\n  3 and 7 The method fractions() takes counts of head and tails as arguments and\n  calculates fractions in percents, for example, 30 and 70\n* The script should display:\n  * the data from file_reader()\n  * the counts from counts()\n  * the fractions from fractions()\n\nHere is an example:\n\n\n$ python3 first\\_nest.py data.csv\n[[0, 1], [1, 0], [0, 1], [1, 0], [0, 1], [0, 1], [0, 1], [1, 0], [1,\n0], [0, 1], [1, 0], [0, 1]]\n5 7\n41.66666666666667 58.333333333333336"
  },
  {
    "id": "ae2d5545-d9a1-4ca6-a31e-005063824d4f",
    "source_file": "README_DS_Bootcamp.Day02-2.md",
    "section": "Exercise 04 : Inheritance",
    "content": "Exercise 04\n\nInheritance\n\nTurn-in directory : ex04/\n\nFiles to turn in : first_child.py\n\nAllowed functions : import sys, from random import randint\n\nYou have one class with many useful methods and you need another class with all or\nsome of those methods? No problem! Inherit one from the other.\n\nWhat you need to do in this exercise:\n\n* In the previous exercise, you had the argument data in your method counts(). Let\n  us move it to the constructor of the class Calculations. The same data might be\n  useful for the future methods of this class, right?\n* Create a new class called Analytics, inherited from Calculations.\n* In the new class, create two methods:\n  * predict_random() that takes the number of predictions that it should return\n    and returns a list of lists of predicted observations of heads and tails: if heads\n    equals 1, then tails equals 0 and vice versa: [[1, 0], [1, 0], [0, 1]]\n  * predict_last() that just returns the last item of the data from file_reader()\n    (this method has the same functionality as in the previous exercise), it should\n    be a list.\n* The script should display:\n  * the data from file_reader()\n  * the counts from counts()\n  * the fractions from fractions()\n  * the list of lists from predict_random() for the 3 steps\n  * the list from predict_last()"
  },
  {
    "id": "2a995e7d-313d-4696-b3e5-aff70537d2d7",
    "source_file": "README_DS_Bootcamp.Day02-2.md",
    "section": "Exercise 05 : Config and the main program",
    "content": "Exercise 05\n\nConfig and the main program\n\nTurn-in directory : ex05/\n\nFiles to turn in : config.py, analytics.py, make_report.py\n\nAllowed functions : import os, from random import randint\nOk. Now we need to make our code even clearer. We need to transfer all the logic\nof the script into a different file. And the second thing we need to do is move all the\nparameters into a config file. We will import the config file and our module file into the\nmain program script.\n\nThe same things in detail:\n\n* create a file called config.py where you will store all the external parameters like\n  num_of_steps for predict_random()\n* delete the logic after block if __name__ == ‚Äô__main__‚Äô from your script from\n  the previous exercise,\n* rename that script analytics.py\n* add to the class Analytics a method that saves any given result to a file with a\n  given extension like save_file(data, name of file, ‚Äòtxt‚Äô)\n* create a new file called make_report.py where the whole logic of your program will\n  be written, the result saved in the file should look like this (you may need additional\n  methods to add to analytics.py):\n\nReport\n\nWe have made 12 observations from tossing a coin: 5 of them were tails and 7 of\nthem were heads. The probabilities are 41.67\\% and 58.33\\%, respectively. Our\nforecast is that in the next 3 observations we will have: 1 tail and 2 heads.\n\nThe template of the text must be stored in config.py.\n\nIn this exercise config.py may have code in the global scope (for variables).\nIn this exercise config.py and analytics.py do not have to contain the block if __name__\n== ‚Äô__main__‚Äô."
  },
  {
    "id": "665e53c7-e3b0-4c91-86a9-f4db43eae28b",
    "source_file": "README_DS_Bootcamp.Day02-2.md",
    "section": "Exercise 06 : Logging",
    "content": "Exercise 06\n\nLogging\n\nTurn-in directory : ex06/\n\nFiles to turn in : config.py, analytics.py, make_report.py\n\nAllowed functions : import os, from random import randint, import logging, import\nrequests (or urllib), import json\n\n* By now you have written your own module containing several classes which contain\n  several methods, a program that uses that module and a config file. But what if\n  there are some problems during production that you will need to debug? How are\n  you going to do it? That is right! You need to log it. So the first task of the\n  exercise is to each and every method in all the classes should log useful information\n  for debugging. You need to store this in the file analytics.log. The format is a date,\n  time, and a message delimited by a space:\n\n2020-05-01 22:16:16,877 Calculating the counts of heads and tails\n\n* The second task is to write a method in the Research class that sends a message to a\n  Telegram channel using webhooks. The message should contain: ‚ÄúThe report has been\n  successfully created‚Äù or ‚ÄúThe report hasn‚Äôt been created due to an error‚Äù.\n* In this exercise, config.py may have code in the global scope (for variables).\n* In this exercise, config.py and analytics.py do not have to contain the block if\n  __name__ == ‚Äô__main__‚Äô."
  },
  {
    "id": "15d7dbce-b67c-4c12-8c4d-f8c56a3c211d",
    "source_file": "README_DS_Bootcamp.Day03-1.md",
    "section": "Intro to Python: Package management and virtual environment",
    "content": "Summary: Today we will help you acquire basic knowledge about how to manage libraries in\nPython and work with virtual environments.\n\nüí° Tap here to leave your feedback on the project. It's anonymous and will help our team make your educational experience better. We recommend completing the survey immediately after the project."
  },
  {
    "id": "e26ce37e-03c3-49d7-acfd-a1b1efb1ccc8",
    "source_file": "README_DS_Bootcamp.Day03-1.md",
    "section": "Contents",
    "content": "1. Chapter I 1.1. Foreword\n2. Chapter II 2.1. Instructions\n3. Chapter III 3.1. Specific instructions for the day\n4. Chapter IV 4.1. Exercise 00: Virtual Environment\n5. Chapter V 5.1. Exercise 01: Installing a package\n6. Chapter VI 6.1. Exercise 02: Installing many libraries\n7. Chapter VII 7.1. Exercise 03: Very beautiful soup\n8. Chapter VIII 8.1. Exercise 04: Profiling\n9. Chapter IX \n   9.1. Exercise 05: PyTest"
  },
  {
    "id": "078070c0-1c95-4b3d-bc66-d9caf9a317c4",
    "source_file": "README_DS_Bootcamp.Day03-1.md",
    "section": "Foreword",
    "content": "10 library rules:\n\n* Use a level 0-1 voice.\n* Use a shelf marker.\n* Turn the pages from the top corner.\n* Wash your hands before touching a book.\n* Return books on time.\n* Never eat or drink while reading.\n* Keep books dry.\n* Use a bookmark.\n* Do not write or draw in books.\n* Keep books away from babies and pets."
  },
  {
    "id": "836faf2b-e962-40dd-92ed-37ee49668afd",
    "source_file": "README_DS_Bootcamp.Day03-1.md",
    "section": "Instructions",
    "content": "* Use this page as the your only reference. Do not listen to any rumors or speculations\n  about how to prepare your solution.\n* Here and further on we use Python 3 as the only correct version of Python.\n* The solutions for python exercises (module01, module02, module03) must have the\n  following block in the end: if __name__ == ‚Äò__main__‚Äô.\n* Pay attention to the permissions of your files and directories.\n* To be assessed your solution must be in your GIT repository.\n* Your solutions will be evaluated by your piscine mates.\n* You should not leave any additional files in your directory other than those explicitly\n  specified in the subject. It is recommended that you modify your .gitignore to avoid\n  accidents.\n* When you need to get precise output in your programs, it is forbidden to display a\n  precalculated output instead of performing the exercise correctly.\n* Have a question? Ask your neighbor on the right. If that fails, try your neighbor\n  on the left.\n* Your reference material: peers / Internet / Google.\n* You can ask questions in Slack.\n* Read the examples carefully. They may require things that are not otherwise specified in the subject.\n* And may the Force be with you!"
  },
  {
    "id": "c0585198-e5ef-47b1-b95b-779048eefdac",
    "source_file": "README_DS_Bootcamp.Day03-1.md",
    "section": "Specific instructions for the day",
    "content": "* No code in the global scope. Use functions!\n* Each file must be ended by a function call in a condition similar to:\n  python\n  if __name__ == '__main__':"
  },
  {
    "id": "8db1d9d6-6d13-4cef-96ed-7509eabd4621",
    "source_file": "README_DS_Bootcamp.Day03-1.md",
    "section": "your tests and your error handling",
    "content": "* Any exception not caught will invalidate your work, even in the event of an error\n  that you were asked you to test.\n* No imports are allowed, except those explicitly mentioned in the section ‚ÄúAllowed functions‚Äù of the title block of each exercise."
  },
  {
    "id": "0c1e07df-0435-466b-8b6d-3a37ef6264d7",
    "source_file": "README_DS_Bootcamp.Day03-1.md",
    "section": "Exercise 00: Virtual Environment",
    "content": "Exercise 00\n\nVirtual Environment\n\nTurn-in directory: ex00/\n\nFiles to turn in: venv.py and the folder with your virtual env\n\nAllowed functions: import os\n\nLibraries, or in other words packages, are one of the means by which coding has been\ndemocratized. It has never been easier to learn to code and get quick results from this\nprocess. Some programmers have written pieces of code that can be reused by other\ncoders. And many of these libraries in Python are open-sourced, which means everybody\ncan use them. Nobody needs to write such already existing classes, methods, or functions\nfrom scratch you can reuse them. All you need to do is sudo pip install. Or wait...\n\nThis way of installing Python packages is considered bad practice. When you do it\nas described above, you install them in the system version of Python. And Python exists\non your machine not only to give you the power to code but to run some programs that\nare essential programs for the system. By installing external packages like that you may\nruin your system. So you almost never need to sudo pip install.\n\nThere is a better way ‚Äì virtual environments. Think of it as your own little sandbox\nwhere you can do whatever you want. If you ruin something, you ruin it only inside\nthis sandbox. Your machine should have a package called virtualenv preinstalled. If not,\nplease, contact the administrators or install it by yourself if you are working on your\npersonal computer. We will use it in the following exercises and projects.\n\nThis exercise is pretty simple; it‚Äôs just meant to warm you up and get you acquainted\nwith the concept of virtual environments. What you need to do is:\n\n* create a virtual environment with your nickname as its name using Python 3 (you\n  will work with this env here and further on),\n* activate it,\n* run Python 3 from the terminal,\n* print the virtual env name using os library,\n* write a small python script that does that thing by calling it in command-line:\n  \n  $ ./venv.py\n  Your current virtual env is /Users/McShtuder/shtuder\n  \n* deactivate the environment,\n* run the script again ...\n\nIf you get a KeyError or None value or an exception while deactivating the env, consider why it happened.\nYou do not have to fix it in this exercise, but be ready to explain why it happened."
  },
  {
    "id": "221d0a3e-ead3-4dbd-bc68-0f951334cdd4",
    "source_file": "README_DS_Bootcamp.Day03-1.md",
    "section": "Exercise 01: Installing a package",
    "content": "Installing a package\n\nTurn-in directory: ex01/\n\nFiles to turn in: pies_bars.sh, the file with the data and the folder with\nyour virtual env\n\nAllowed functions: no restrictions\n\n* Let us install the first package in your virtual environment!\n* We will work with the library termgraph a bit. It gives you the power to draw\n  graphs and diagrams right in your terminal. What could be cooler?\n* Install the library in the virtual environment created in the previous exercise.\n* Make exactly the same visualization as below but with a different color scheme\n  (create a file for the visualization by yourself):\n\n  !pies-bar\n* Make a shell script file for this purpose with the name pies_bars.sh. It contains\n  only the part for making the graph without activation and deactivation of the env."
  },
  {
    "id": "f8522cf2-8f64-4ab4-8a6b-67ad577e7060",
    "source_file": "README_DS_Bootcamp.Day03-1.md",
    "section": "Exercise 02: Installing many libraries",
    "content": "Exercise 02\n\nInstalling many libraries\n\nTurn-in directory: ex02/\n\nFiles to turn in: librarian.py and the archive with your virtual env\n\nAllowed functions: no restrictions\n\nDuring the following exercises, you will work with several different libraries. In this\nexercise, you need to prepare your virtual environment for them.\nInstall the latest release of BeautifulSoup and PyTest. It is prohibited to install them\none by one (pip install x, pip install y). It is prohibited to use loops. Find a clever way\nto do it, use installation via requirements.\n\nWrite a python script called librarian.py that:\n\n* checks that it runs inside the correct env\n* installs the libraries\n* displays all the installed libraries at the end like this (doesn‚Äôt have to be exactly the same\n  list):\n\n  \n  six==1.14.0\n  soupsieve==2.0\n  termgraph==0.2.0\n  wcwidth==0.1.9\n  zipp==3.1.0\n  \n* saves it to requirements.txt\n\nPut an archive of your env in the folder. You can put archivation in your code or you\ncan do it from the command line. The archive may be compressed if you think that would\nbe useful. If the script was called from the wrong env, there should be an exception."
  },
  {
    "id": "c551cead-4ec0-446a-92b5-72a97793ba2d",
    "source_file": "README_DS_Bootcamp.Day03-1.md",
    "section": "Exercise 03: Very beautiful soup",
    "content": "Exercise 03\n\nVery beautiful soup\n\nTurn-in directory: ex03/\n\nFiles to turn in: financial.py\n\nAllowed functions: no restrictions\n\nOk, so you have installed 2 libraries in the previous exercise. Let us work with one\nof them BeautifulSoup. It is very useful when you need to parse a website that does not\nhave an API (As was the case with HeadHunter on day00). The problem is that when\nyou parse a webpage, you get not only useful information but also HTML markup that\nwill be a pain for you. This package helps you navigate in different blocks and classes\nin HTML, making easier to extract what you really need from them. But keep in mind\nthat it is not a parser itself, it just helps you navigate in the mess of HTML or XML\n(meaning that you need to install an HTTP-library as per your own taste in your env).\n\nIn this exercise, you will parse Yahoo Finance (yeah, it has an API, but for learning\npurposes let us forget about that). You will need to visit a page like this and get some\ndata for a specific field of a specific company.\n\nWrite a Python script that:\n\n* gets: as the arguments the ticker symbol and the field of the table (for example,\n  MSFT, Total Revenue)\n* returns: the tuple that contains the requested information\n* special conditions: add a ‚Äôsleep for 5 seconds‚Äô inside your script (we will need it\n  later)\n\nThe example:\n\n\n$ ./financial.py 'MSFT' 'Total Revenue'\n('Total Revenue', '134,249,000', '125,843,000', '110,360,000',\n'89,950,000', '85,320,000')\n\n\nIf the URL does not exist, raise an exception. If the requested field does not exist,\nraise an exception."
  },
  {
    "id": "e7299c43-4b55-4273-ad72-82e946e7505a",
    "source_file": "README_DS_Bootcamp.Day03-1.md",
    "section": "Exercise 04: Profiling",
    "content": "Exercise 04\n\nProfiling\n\nTurn-in directory: ex04/\n\nFiles to turn in: financial.py, financial_enhanced.py, profiling-sleep.txt, profiling-tottime.txt,\nprofiling-http.txt, profiling-ncalls.txt\n\nAllowed functions: no restrictions\n\nThere is no chance that you will write code 100% perfectly in the future without any\nscope for improvement. You will likely have to figure out why your scripts don‚Äôt work\nas fast as you want. And we have the thing for such purposes - profilers. According to\nWikipedia, profiling is a form of dynamic program analysis that measures, for example,\nthe spatial or temporal complexity of a program, the usage of particular instructions,\nor the frequency and duration of function calls. Most commonly, profiling information\nserves to aid program optimization.\n\nRemember your script from the previous exercise? Let us optimize it. Even if you are\na programming guru, there was one structure that was not very effective (we asked you\nto do it that way).\n\n* Applying cProfile to your script financial.py, get a table of the functions used sorted\n  in descending order by total time spent on their execution. Save it to the file profiling-\n  sleep.txt.\n\n  !1\n* Delete the line with time.sleep(5) from your script and run the profiling again.\n  You should get a new table without built-in method time.sleep. Save it to the file\n  profiling-tottime.txt\n* Try using another HTTP-client library to see if your script got any faster. Save the new\n  script to financial_enhanced.py. Save the result of the profiling to the file profiling-http.txt\n* Get the same table but sorted in descendingly order by number of calls. Sometimes it is\n  useful to know: that you can choose to optimize those functions to make them call fewer\n  times. Save the table to the file profiling-ncalls.txt\n* This time use the library pstats. Sort by cumulative time and get the top 5 Save it to the file\n  pstats-cumulative.txt"
  },
  {
    "id": "92e3821c-54c0-47eb-9572-898f9e0bf8a8",
    "source_file": "README_DS_Bootcamp.Day03-1.md",
    "section": "Exercise 05: PyTest",
    "content": "Exercise 05\n\nPyTest\n\nTurn-in directory: ex05/\n\nFiles to turn in: financial_test.py\n\nAllowed functions: no restrictions\n\nWell, the speed of your script is not the only issue to consider. Your script may not\nwork as you intended from the start. To be sure that the script works properly, you need\nto conduct unit tests: for example, to give different things as the input and make sure\nthat it returns what expected.\n\nWe are sure that in ex03 you used one or more functions. For each of the functions,\nyou need to create at least 3 tests using the library PyTest. Check if your script gives\nthe correct information for the request:\n\n* If I ask for Total Revenue, do I get the total revenue for the given ticker?\n* Is the type of the return a tuple?\n* If I give an invalid ticker name, do I get an exception?\n\nModify your script financial.py by adding the tests into the code. Put the file in your\ndirectory with the name financial_test.py. Run PyTest. Your tests should have passed.\nIf not, work on your script to make it ready."
  },
  {
    "id": "1b610ac2-2ada-4f02-9a87-28189a4fe7d0",
    "source_file": "README_DS_Bootcamp.Day04.ID_886514-2.md",
    "section": "Intro to Python: Efficient code practices",
    "content": "Summary: Today we will help you write code that works faster.\n\nüí° Tap here to leave your feedback on the project. It's anonymous and will help our team make your educational experience better. We recommend completing the survey immediately after the project."
  },
  {
    "id": "963373c4-5765-4a7d-a1bc-75902643f7cc",
    "source_file": "README_DS_Bootcamp.Day04.ID_886514-2.md",
    "section": "Contents",
    "content": "1. Chapter I 1.1. Foreword\n2. Chapter II 2.1. Instructions\n3. Chapter III 3.1. Specific instructions for the day\n4. Chapter IV 4.1. Exercise 00 : List comprehensions\n5. Chapter V 5.1. Exercise 01 : Map\n6. Chapter VI 6.1. Exercise 02 : Filter\n7. Chapter VII 7.1. Exercise 03 : Reduce\n8. Chapter VIII 8.1. Exercise 04 : Counter\n9. Chapter IX \n   9.1. Exercise 05 : Generator"
  },
  {
    "id": "7c4e655a-fe08-4631-a34c-c3aa5edea152",
    "source_file": "README_DS_Bootcamp.Day04.ID_886514-2.md",
    "section": "Foreword",
    "content": "* There are two words in English that are commonly confused: ‚Äúefficiency‚Äù ‚Äúand\n  effectiveness‚Äù.\n* To highlight the difference, let us tell you a short joke.\n* My motto is ‚ÄúEfficiency. Efficiency. Efficiency.‚Äù Oops. I guess I only need to say it once\n* Or as Peter Drucker once said: ‚ÄúEfficiency is doing things right; effectiveness is\n  doing the right things‚Äù\n* Your code should not only be effective, but efficient as well. And vice versa\n* One of the best games for learning how to be efficient is Factorio. Google it.\n\nDownload it. And try to get back to MODULE 4 Not everyone will be able to."
  },
  {
    "id": "77444dbe-06e1-4dfc-a44e-bb9db2630fe4",
    "source_file": "README_DS_Bootcamp.Day04.ID_886514-2.md",
    "section": "Instructions",
    "content": "* Use this page as your only reference. Do not listen to any rumors or speculations\n  about how to prepare your solution.\n* Here and further on we use Python 3 as the only correct version of Python.\n* The python files for python exercises (module01, module02, module03) must have\n  the following block in the end: if __name__ == ‚Äò__main__‚Äô.\n* Pay attention to the permissions of your files and directories.\n* To be assessed your solution must be in your GIT repository.\n* Your solutions will be evaluated by your piscine mates.\n* You should not leave in your directory any other file than those explicitly specified\n  by the exercise instructions. It is recommended that you modify your .gitignore to\n  avoid any accidents.\n* Your solution must be in your GIT repository for evaluation. Always push only to the develop branch! The master branch will be ignored. Work in the src directory.\n* When you need to get precise output in your programs, it is forbidden to display a\n  precalculated output instead of performing the exercise correctly.\n* Have a question? Ask your neighbor on the right. If that fails, try your neighbor\n  on the left.\n* Your reference material: peers / Internet / Google.\n* You can ask questions in Slack.\n* Read the examples carefully. They may require things that are not otherwise specified in the subject.\n* And may the Force be with you!"
  },
  {
    "id": "3e08ed0e-1f8e-4ebb-99af-c9c7cf0304bd",
    "source_file": "README_DS_Bootcamp.Day04.ID_886514-2.md",
    "section": "Specific instructions for the day",
    "content": "* No code in the global scope. Use functions!\n* Each file must end with a function call in a condition similar to:\n\n  python\n  if __name__ == '__main__':"
  },
  {
    "id": "28154add-e966-4339-84bb-5f3167c6dbed",
    "source_file": "README_DS_Bootcamp.Day04.ID_886514-2.md",
    "section": "your tests and your error handling",
    "content": "* Any exception not caught will invalidate the work, even in the event of an error\n  that you were asked to test.\n* No imports are allowed, except those explicitly mentioned in the section ‚ÄúAutho-\n  rized functions‚Äù of the title block of each exercise.\n* You can use any built-in function if it is not prohibited in the exercise."
  },
  {
    "id": "34b0c2c3-032f-4079-9b0f-25443a0d95a1",
    "source_file": "README_DS_Bootcamp.Day04.ID_886514-2.md",
    "section": "Exercise 00 : List comprehensions",
    "content": "Exercise 00\n\nList comprehensions\n\nTurn-in directory : ex00/\n\nFiles to turn in : benchmark.py\n\nAllowed functions : import timeit\n\nImagine that your task is to get all the Gmail addresses from a list of email addresses. The usual approach is to create a loop, and iterating from\nthe initial list append the required values to a new list.\n\nBut that can be inefficient if we are talking about large amounts of data. There is a more efficient and pythonic way to do the task ‚Äì list comprehensions.\n\nIn this exercise, you need to:\n\n* write two functions:\n  * in the first you need to implement the usual approach with a loop and an\n    append\n  * in the second you use a list comprehension instead\n* use timeit to measure the time required to run those functions 90, 000, 000 times\n  and compare them\n* put this into a script that prints ‚Äúit is better to use a list comprehension‚Äù if the\n  corresponding time is less or equal than that of the loop, and ‚Äúit is better to use a\n  loop‚Äù if not,\n* also, add the time values at the end, after the print described above. Order them\n  from shortest to longest.\n\nPlease, use the following list of email addresses:\n\n\nemails = [‚Äôjohn@gmail.com‚Äô, ‚Äôjames@gmail.com‚Äô, ‚Äôalice@yahoo.com‚Äô, \n‚Äôanna@live.com‚Äô, ‚Äôphilipp@gmail.com‚Äô]\n\n\nDuplicate the values 5 times. As a result, the list will contain 25 elements, but only 5 unique\nones.\n\nAn example of the script being launched:\n\n\n$ ./benchmark.py\nit is better to use a list comprehension\n55.71611063099999 vs 58.849982983"
  },
  {
    "id": "996231d9-2885-46ab-980a-fa276274e2fd",
    "source_file": "README_DS_Bootcamp.Day04.ID_886514-2.md",
    "section": "Exercise 01 : Map",
    "content": "Exercise 01\n\nMap\n\nTurn-in directory : ex01/\n\nFiles to turn in : benchmark.py\n\nAllowed functions : import timeit\n\nOk, chances are that you saw the difference: list comprehensions are slightly more\nefficient than loops and more readable as well. But that is not the only option available.\n\nThere is also map()!\n\nMap comes from functional programming. You do not have to iterate through a list.\n\nYou can apply a function to an iterable. That is what you are going to do in this exercise!\n\nModify the script from the previous exercise:\n\n* Write a function that does the same thing: creates a list with Gmail addresses\n  taken from the initial list of emails (25 elements), but using a map. Try map() and\n  list(map()). Note the difference in speed\n* You still need to compare which function is faster, but now you have three options:\n  loop, list comprehension, and map, and add one more phrase according to this in\n  your code ‚Äúit is better to use a map‚Äù and at the end, you need to display all three\n  time values with the same condition: they should be in the ascending order by\n  length.\n\nThe example:\n\n\n$ ./benchmark.py\nit is better to use a map\n29.32016281 vs 54.620376492999995 vs 55.99120069\n\n\nCheck the results of all the functions. Are they all identical? They do not have to be."
  },
  {
    "id": "06b072ba-11c7-4eb2-9bf6-188a1b991dce",
    "source_file": "README_DS_Bootcamp.Day04.ID_886514-2.md",
    "section": "Exercise 02 : Filter",
    "content": "Exercise 02\n\nFilter\n\nTurn-in directory : ex02/\n\nFiles to turn in : benchmark.py\n\nAllowed functions : import timeit, import sys\n\n* Did you notice that what you did in the previous exercises was filtering? Why\n  not use the corresponding function filter() instead of those list comprehensions and\n  maps? It works almost the same as map(). You will love it!\n* Add a new function to your benchmark that uses filter(). But this time let us\n  refactor the code. Let us create a script that takes the name of the function (loop,\n  list comprehension, map, filter) to your benchmark and the number of calls it should\n  perform for the benchmark. In return, it should give the time spent to make that\n  number of calls of the function.\n\nThe examples:\n\n\n$ ./benchmark.py loop 10000000\n6.230267604\n$ ./benchmark.py list_comprehension 10000000\n6.214286791\n$ ./benchmark.py map 10000000\n3.063598874\n$ ./benchmark.py"
  },
  {
    "id": "2d2d706f-3079-4a33-8c91-14df5aa01415",
    "source_file": "README_DS_Bootcamp.Day04.ID_886514-2.md",
    "section": "Exercise 03 : Reduce",
    "content": "Exercise 03\n\nReduce\n\nTurn-in directory : ex03/\n\nFiles to turn in : benchmark.py\n\nAllowed functions : import timeit, import sys, from functools import reduce\n\nBesides map() and filter() there is another function that might be useful for you in\nthe future ‚Äì reduce(). You can also use it instead of loops and, in most cases, it will be\nmore efficient when you need to calculate a sum. In this exercise, you need to calculate\nthe sum of squares up to the number given as an argument. For example, if 5 was given,\nthe sum will be 1 + 4 + 9 + 16 + 25 = 55\n\nIn your script create two functions:\n\n in the first ‚Äì you need to implement the usual approach with a loop and sum = sum + ii\n* in the second ‚Äì you use a reduce() instead\n* Let us create a script that takes as an argument the name of the function (loop or\n  reduce), the number of calls it should perform for the benchmark, and the number for\n  the sum of the calculation of squares. In return, it should give the time spent to make\n  that number of calls of the function.\n\nThe example:\n\n\n$ ./benchmark.py loop 10000000 5\n6.230267604\n$ ./benchmark.py reduce 10000000 5\n3.063598874"
  },
  {
    "id": "c7a375dc-6fcd-407b-9cdd-f458fb607086",
    "source_file": "README_DS_Bootcamp.Day04.ID_886514-2.md",
    "section": "Exercise 04 : Counter",
    "content": "Exercise 04\n\nCounter\n\nTurn-in directory : ex04/\n\nFiles to turn in : benchmark.py\n\nAllowed functions : import timeit, import random, from collections import\nCounter\n\n‚ÄúKnow the built-in functions‚Äù is one of the most vital commandments for a Python\ncoder. Here we are going to use the collections module that is shipped with Python.\nIt contains a number of container data types - we will use Counter. It is very handy,\nfor example, when you need to count unique values in a list. And it is faster than any\nfunction that you can write by yourself. But don‚Äôt take our word for it, check it out for\nyourself!\n\n* generate a list with 1 000 000 random values from 0 to 100 (remember list compre-\n  hensions?)\n* write a function that creates a dict out of the list where the keys are the numbers\n  from 0 to 100 and the values are their counts\n* write a function that returns the top 10 most common numbers where the keys are\n  the numbers and the values are the counts, the input is the list\n* solve 2 and 3 using Counter\n* make a comparison: your script should display the time spent for 2 and 3 with\n  Counter and without it\n\nExample:\n\n\n$ ./benchmark.py\nmy function: 0.4501532\nCounter: 0.0432341\nmy top: 0.1032348\nCounter's top: 0.017573"
  },
  {
    "id": "283cadc3-a84d-4dfa-9105-5215ae936820",
    "source_file": "README_DS_Bootcamp.Day04.ID_886514-2.md",
    "section": "Exercise 05 : Generator",
    "content": "Exercise 05\n\nGenerator\n\nTurn-in directory : ex05/\n\nFiles to turn in : ordinary.py, generator.py\n\nAllowed functions : import sys, import resource; for Windows: import sys, import os, import\npsutil\n\nCode efficiency is not only about the time spent, but also about the RAM used. This\nis quite important if you work with big data. Or maybe smaller-scale data can also cause\nyou trouble? You have already got used to making experiments. Let us do yet another\none.\n\n* Download the MovieLens dataset.\n* Unzip it. You will need the file ratings.csv (678.3 MB is not that big, right?).\n* Create the first script, ordinary.py. It should have only one function: it reads all\n  the file lines into a list and then returns it. In the main program, write a loop that\n  iterates through the list and calls pass. You should give the path to the file as an\n  argument to the script\n* Create the second script, generator.py. It does exactly the same thing, but in your\n  function, you must use a generator. It uses the keyword yield to read one line at a\n  time and returns it to the caller. In the main program, write a loop that iterates\n  through the generator and calls pass. You should give the path to the file as an\n  argument to the script.\n* Both scripts should display Peak memory usage in GB and User mode time +\n  System mode time in seconds. If you have Windows OS, use the corresponding\n  functions to get the same metrics.\n\nExample:\n\n\n$ ./ordinary.py ratings.csv\nPeak Memory Usage = 2.114 GB\nUser Mode Time + System Mode Time = 5.77s\n$ ./generator.py ratings.csv\nPeak Memory Usage = 0.005 GB\nUser Mode Time + System Mode Time = 9.04s"
  },
  {
    "id": "e3216bee-a32c-4f2d-90ca-f8977fd59acd",
    "source_file": "README_DS_Bootcamp.Day05.ID_886517-1.md",
    "section": "Pandas: working with Dataframes",
    "content": "Summary: Today we will help you acquire skills with Pandas.\n\nüí° Tap here to leave your feedback on the project. It's anonymous and will help our team make your educational experience better. We recommend completing the survey immediately after the project."
  },
  {
    "id": "07b6a87b-8817-4fc7-82ab-22d6a85e85fd",
    "source_file": "README_DS_Bootcamp.Day05.ID_886517-1.md",
    "section": "Contents",
    "content": "1. Chapter I 1.1. Foreword\n2. Chapter II 2.1. Instructions\n3. Chapter III 3.1. Specific instructions for the day\n4. Chapter IV 4.1. Exercise 00 : Load and save\n5. Chapter V 5.1. Exercise 01 : Basic operations\n6. Chapter VI 6.1. Exercise 02 : Preprocessing\n7. Chapter VII 7.1. Exercise 03 : Selects and aggregations\n8. Chapter VIII 8.1. Exercise 04 : Enrichment and transformations\n9. Chapter IX \n   9.1. Exercise 05 : Pandas optimizations"
  },
  {
    "id": "4f3b00c0-93c3-4a91-a50f-d1a465b46d4b",
    "source_file": "README_DS_Bootcamp.Day05.ID_886517-1.md",
    "section": "Foreword",
    "content": "Fun facts about pandas:\n\n* Pandas are big eaters ‚Äì every day they fill their tummies for up to 12 hours, consuming up to 12 kilograms of bamboo\n* Unlike most other bears, pandas do not hibernate. When winter approaches, they\n  head lower down their mountain homes to warmer temperatures, where they continue to chomp away on bamboo\n* Sadly, these beautiful bears are endangered, and it‚Äôs estimated that only around\n  1,000 remain in the wild\n* On average, pandas poo 40 times a day\n* According to legend, the panda was once an all-white bear. When a small girl tried\n  to save a panda cub from being attacked by a leopard, the leopard killed the girl\n  instead. Pandas came to her funeral wearing armbands of black ashes. As they\n  wiped their eyes, hugged each other, and covered the ears, they smudged the black\n  ashes into their fur.\n* A panda‚Äôs entire mating process takes about two or three days. Once they have\n  mated, the females chase the males out of their territory and raise their cubs on\n  their own\n* A giant panda usually gives birth to a single cub. Sometimes twins are born, but\n  when this happens, the mother typically ignores the weaker cub. She does not have\n  enough energy to care for two cubs\n* A giant panda‚Äôs face is cute, but it is not chubby. It gets its shape from massive\n  cheek muscles\n* Keeping even a single panda in a zoo is expensive. A panda costs five times more\n  to keep than the next most expensive animal, an elephant\n* If you think that any of this is relevant to the library Pandas, you needn‚Äôt. The\n  name is derived from the term \"panel data\", an econometrics term for data sets that\n  include observations over multiple time periods for the same individuals"
  },
  {
    "id": "96dad7f2-a77c-4389-aaf9-2064f83f1628",
    "source_file": "README_DS_Bootcamp.Day05.ID_886517-1.md",
    "section": "Instructions",
    "content": "* Use this page as your only reference. Do not listen to any rumors or speculations\n  about how to prepare your solution.\n* Here and further on we use Python 3 as the only correct version of Python.\n* The solutions for python exercises (d01, d02, d03) must have the following block in\n  the end: if __name__ == ‚Äò__main__‚Äô.\n* Pay attention to the permissions of your files and directories.\n* To be assessed your solution must be in your GIT repository.\n* Your solutions will be evaluated by your piscine peers.\n* You should not leave any additional files in your directory other than those explicitly\n  specified in the subject. It is recommended that you modify your .gitignore to avoid\n  any accidents.\n* Your solution must be in your GIT repository for evaluation. Always push only to the develop branch! The master branch will be ignored. Work in the src directory.\n* When you need to get precise output in your programs, it is forbidden to display a\n  precalculated output instead of performing the exercise correctly.\n* Have a question? Ask your neighbor on the right. If that fails, try your neighbor\n  on the left.\n* Your reference material: peers / Internet / Google.\n* You can ask questions in Slack.\n* Read the examples carefully. They may require things that are not otherwise specified in the subject.\n* And may the Force be with you!"
  },
  {
    "id": "8d4e1f45-2264-43bb-981d-2f97278490e6",
    "source_file": "README_DS_Bootcamp.Day05.ID_886517-1.md",
    "section": "Specific instructions for the day",
    "content": "* Use Jupyter Notebook to work with your code\n* For each major subtask in the list of any exercise (black bullets), your ipynb file\n  should have an h2 heading to help your peer easily navigate in your code\n* No imports are allowed, except those explicitly mentioned in the ‚ÄúAuthorized functions‚Äù section of the title block of each exercise\n* You can use any built-in function, if it is not prohibited in the exercise\n* Save and load all the required data in the subfolder data/"
  },
  {
    "id": "45b41e7b-bd14-4c76-9197-20b4ae79b80a",
    "source_file": "README_DS_Bootcamp.Day05.ID_886517-1.md",
    "section": "Exercise 00 : Load and save",
    "content": "Exercise 00\n\nLoad and save\n\nTurn-in directory : ex00/\n\nFiles to turn in : load_and_save.ipynb\n\nAllowed functions : import pandas as pd\n\nCongratulations! Five days and one rush are behind you. They were dedicated to\nbuilding good fundamental skills in working with Python. Now you know all the basic\ndata types, useful built-in functions, how to work with a virtual environment, how to use\nOOP, how to use logging, how to parse data from websites, and how to send messages in\na Slack channel. In the following week, we will be more focused on data science. It will\nbe a week full of Pandas exercises. Pandas is one of the most popular and useful libraries\nin the field. You will love it too!\n\nIn this exercise, you will need to load the log file (put it in the directory data in the\nsrc directory of the day) into a dataframe, change the delimiter, and save it to another\nfile.\n\nThe task is:\n\n* read_csv:\n  * filter the rows with index 2 and 3 using the argument skiprows, we know that\n    these observations were fake\n  * filter the last 2 rows from the footer using the argument skipfooter, we know\n    that these observations were fake too\n  * assign the following names to the column: datetime, user\n  * use datetime as the index column\n* rename datetime to date_time\n* to_csv:\n  * use ‚Äô;‚Äô as the delimiter\n  * save it to a file with the name feed-views-semicolon.log\n\nAs the result of read_csv, you need to achieve the following:\n\n\nIn [3]: df.head()\nOut[3]:\nuser\ndatetime\n2020-04-17 12:01:08.463179 artem\n2020-04-17 12:01:23.743946 artem\n2020-04-17 12:35:52.735016 artem\n2020-04-17 12:36:21.401412 oksana\n2020-04-17 12:36:22.023355 oksana\n\nIn [4]: df.tail()\nOut[4]:\nuser\ndatetime\n2020-05-21 16:36:40.915488 ekaterina\n2020-05-21 17:49:36.429237 maxim\n2020-05-21 18:45:20.441142 valentina\n2020-05-21 23:03:06.457819 maxim\n2020-05-21 23:23:49.995349 pavel\n\n\nThink about how many lines of code you would have needed to write if you had had\nto do it without Pandas"
  },
  {
    "id": "e790a240-8ed2-4e20-b708-8bfb8cde5302",
    "source_file": "README_DS_Bootcamp.Day05.ID_886517-1.md",
    "section": "Exercise 01 : Basic operations",
    "content": "Exercise 01\n\nBasic operations\n\nTurn-in directory : ex01/\n\nFiles to turn in : basic_operations.ipynb\n\nAllowed functions : import pandas as pd\n\nWe are confident that you understand that this is not everything that Pandas can do\nfor you. Let us go deeper and wider.\n\nIn this exercise, you will work with a single log of users who visited a page, including\ntheir timestamps.\n\n* create a dataframe views with two columns: datetime and user by reading feed-views.log\n  * convert the datetime to the datetime64[ns] Dtype\n  * extract the year, month, day, hour, minute, and second from the values of that\n    column to the new columns\n* create the new column daytime\n  * you need to assign the particular time of day value if an hour is within a\n    particular interval, for example, afternoon if the hour is larger than 11 and\n    less or equal to 17\n  * 0 ‚Äì 3.59 night, 4 ‚Äì 6.59 early morning, 7 ‚Äì 10.59 morning, 11 ‚Äì 16.59 afternoon, 17 ‚Äì 19.59 early evening, 20 ‚Äì 23.59 evening\n  * use the method cut to solve this subtask\n  * assign the column user as the index\n* calculate the number of elements in your dataframe\n  * use the method count()\n  * calculate the number of elements in each time of day category using the method\n    value_counts()\n* sort values in your dataframe by hour, minute, and second in ascending order\n  (simultaneously and not one by one)\n* calculate the minimum and maximum for the hours and the mode for the daytime\n  categories\n  * calculate the maximum of hour for the rows where the time of day is night\n  * calculate the minimum of hour for the rows where the time of day is morning\n  * In addition to this, find out who visited the page at those hours (make one\n    example from that)\n  * calculate the mode for the hour and daytime\n* show the 3 earliest hours in the morning and the corresponding usernames and the\n  3 latest hours and the usernames using nsmallest() and nlargest()\n* use the method describe() to get the basic statistics for the columns\n  * to find out what the most popular interval for visiting the page is, calculate\n    the interquartile range for the hour by extracting values from the result of the\n    describe() method and store it in the variable iqr"
  },
  {
    "id": "6bcc2a99-9dac-44f5-add5-136560c7f4d4",
    "source_file": "README_DS_Bootcamp.Day05.ID_886517-1.md",
    "section": "Exercise 02 : Preprocessing",
    "content": "Exercise 02\n\nPreprocessing\n\nTurn-in directory : ex02/\n\nFiles to turn in : preprocessing.ipynb\n\nAllowed functions : import pandas as pd\n\nOne day you will train machine learning models (no later than this week), but most\nof them require the data to be clean and enriched: without duplicates or missing values.\nPandas is a great tool to do this. It gives you the tools not only to perform descriptive\nanalysis and understand your data better but to preprocess it too. That is what you are\ngoing to do in this exercise.\n\n* download and read the CSV file and make ID the index column\n* count the number of observations using the method count()\n* drop the duplicates, taking into account only the following columns: CarNumber,\n  Make_n_model, Fines\n  * between the two equal observations, you need to choose the last\n  * check the number of observations again\n* work with missing values\n  * check how many values are missing from each column\n  * drop all the columns with over 500 missing values using the argument thresh,\n    check how many missing values are in each column\n  * replace all the missing values in the Refund column with the previous value in\n    that column for that cell, use the argument method, check how many values\n    are missing from each column\n  * replace all the missing values in the Fines column with the mean value of this\n    column (exclude NA/null values when computing the mean value), check how\n    many values are missing from each column\n* split and parse the make and model\n  * use the method apply both for splitting and for extracting the values to the\n    new columns Make and Model\n  * drop the column Make_n_model\n  * save the dataframe in the JSON file auto.json in the format below:\n\n    \n    [{\"CarNumber\":\"Y163O8161RUS\",\"Refund\":2.0,\"Fines\":3200.0,\"Make\":\"Ford\",\n    \"Model\":\"Focus\"},\n    {\"CarNumber\":\"E432XX77RUS\",\"Refund\":1.0,\"Fines\":6500.0,\"Make\":\"Toyota\",\n    \"Model\":\"Camry\"}]"
  },
  {
    "id": "9a9bcdc7-ae21-4367-a068-a9e27e23dcdd",
    "source_file": "README_DS_Bootcamp.Day05.ID_886517-1.md",
    "section": "Exercise 03 : Selects and aggregations",
    "content": "Exercise 03\n\nSelects and aggregations\n\nTurn-in directory : ex03/\n\nFiles to turn in : selects_n_aggs.ipynb\n\nAllowed functions : import pandas as pd\n\nOk, great. Now we have cleaned our data: all the duplicates have been dropped, all\nthe missing values have been deleted, and our columns have been reorganized to be more\nconvenient for analysis. Now we can go further. We have a lot of questions that need to\nbe answered.\n\n* load the JSON file that you created in the previous exercise into a dataframe\n  * set CarNumber as the index column\n* make the following selects\n  * display the rows only where the fines are more than 2,100\n  * display the rows only where the fines are more than 2,100 and the refund\n    equals 2\n  * display the rows only where the models are from the list: [‚ÄôFocus‚Äô, ‚ÄôCorolla‚Äô]\n  * display the rows only where the car number is from the list:\n    [‚ÄôY7689C197RUS‚Äô, ‚Äô92928M178RUS‚Äô, ‚Äô7788KT197RUS‚Äô, ‚ÄôH115YO163RUS‚Äô, ‚ÄôX758HY197RUS‚Äô]\n* make the aggregations with the make and the model\n  * display the median fines grouped by the make\n  * display the median fines grouped by the make and the model\n  * display the number of fines grouped by the make and the model in order to\n    understand if we can trust the median values\n  * display the minimum and the maximum fines grouped by the make and the\n    model in order to better understand the variance\n  * display the standard deviation of the fines grouped by the make and the model\n    in order to better understand the variance\n* make the aggregations with the car number\n  * display the car numbers grouped by the number of the fines in descending\n    order, we want to find those who most often violated the law\n  * select from the initial dataframe all the rows corresponding to the top-1 car\n    number, we want to zoom in a little bit\n  * display the car numbers grouped by the sum of the fines in descending order,\n    we want to find those who paid the most\n  * select from the initial dataframe all the rows corresponding to the top-1 car\n    number, we want to zoom in a little bit\n  * display a table that answers the question: are there any car numbers that were connected to different models?"
  },
  {
    "id": "1e154441-5a7f-49e7-8276-01ed76af7971",
    "source_file": "README_DS_Bootcamp.Day05.ID_886517-1.md",
    "section": "Exercise 04 : Enrichment and transformations",
    "content": "Exercise 04\n\nEnrichment and transformations\n\nTurn-in directory : ex04/\n\nFiles to turn in : enrichment.ipynb\n\nAllowed functions : import pandas as pd, import numpy as np, import requests\n\nCool. But the more data you have the better the analysis you can conduct. Let us\nenrich our initial dataset.\n\n* read the JSON file that you saved in ex02\n\n  * one of the columns has the float type, so let us define the format of it in\n    pandas using pd.options.display.float_format: floats should be displayed with\n    two decimals\n  * there are values missing from the Model, do not do anything with them\n* enrich the dataframe using a sample from that dataframe\n\n  * create a sample with 200 new observations with random_state = 21\n    * the sample should not have new combinations of the car number,\n      make and model, so the whole dataset will be consistent in these terms\n    * there are no restrictions on the refund and fines, you can take\n      any value\n      from these columns at random and use it towards any car number\n  * concatenate the sample with the initial dataframe to a new dataframe concat_rows\n* enrich the dataframe concat_rows by a new column with the data generated\n\n  * create a series with the name Year using random integers from 1980 to 2019\n  * use np.random.seed(21) before generating the years\n  * concatenate the series with the dataframe and name it fines\n* enrich the dataframe with the data from another dataframe\n\n  * create a new dataframe with the car numbers and their owners\n    * get the most popular surnames (you can find the file surname.json in the attachments) in the US\n    * create a new series with the surnames (they should not have\n      special characters like commas, brackets, etc.) from the data you gathered, the count\n      should be equal to the number of unique car numbers using the sample\n      (use random_state = 21)\n    * create the dataframe owners with 2 columns: CarNumber and\n      SURNAME\n  * append 5 more observations to the fines dataframe (come up with your own\n    ideas of CarNumber, etc.)\n  * delete the dataframe last 20 observations from the owners and add 3 new\n    observations (they are not the same as those you add to the fines dataframe)\n  * join both dataframes:\n    * the new dataframe should have only the car numbers that exist in both dataframes\n    * the new dataframe should have all the car numbers that exist in both dataframes\n    * the new dataframe should have only the car numbers from the fines dataframe\n    * the new dataframe should have only the car numbers from the owners dataframe\n* create a pivot table from the fines dataframe, it should look like this (the values are\n  the sums of the fines), but with all the years (the values may be different for you):\n\n  !pivot-table\n* save both the fines and owners dataframes to CSV files without an index"
  },
  {
    "id": "4de280f1-a084-4bdb-b313-7d1e6866a1ab",
    "source_file": "README_DS_Bootcamp.Day05.ID_886517-1.md",
    "section": "Exercise 05 : Pandas optimizations",
    "content": "Exercise 05\n\nPandas optimizations\n\nTurn-in directory : ex05/\n\nFiles to turn in : optimizations.ipynb\n\nAllowed functions : import pandas as pd, import gc\n\nWe are returning to the idea of code efficiency. By now you know the basics of Pandas.\nIt is time to get to know some cool stuff that most Pandas users neither use nor know\nabout.\n\n* read the fines.csv that you saved in the previous exercise\n iterations: in all the following subtasks, you need to calculate fines/refundyear for\n  each row and create a new column with the calculated data and measure the time\n  using the magic command %%timeit in the cell\n  * loop: write a function that iterates through the dataframe using for i in range(0, len(df)), iloc and append() to a list, assign the result of the function to a new column in the dataframe\n  * do it using iterrows()\n  * do it using apply() and lambda function\n  * do it using Series objects from the dataframe\n  * do it as in the previous subtask but with the method .values\n* indexing: measure the time using the magic command %%timeit in the cell\n  * get a row for a specific CarNumber, for example, ‚ÄôO136HO197RUS‚Äô\n  * set the index in your dataframe with CarNumber\n  * again, get a row for the same CarNumber\n* downcasting:\n  * run df.info(memory_usage=‚Äôdeep‚Äô), pay attention to the Dtype and the memory usage\n  * make a copy() of your initial dataframe into another dataframe optimized\n  * downcast from float64 to float32 for all the columns\n  * downcast from int64 to the smallest numerical dtype possible\n  * run info(memory_usage='deep') for your new dataframe, pay attention to the Dtype and the memory usage\n* categories:\n  * change the object type columns to the type category\n  * This time, check the memory usage, it probably has a decrease of 2‚Äì3 times compared to the initial dataframe\n* memory clean\n  * using %reset_selective and the library gc clean the memory of your initial dataframe only"
  },
  {
    "id": "b879c671-6e84-454e-9061-24c9e6e6baf5",
    "source_file": "README_DS_Bootcamp.Day06.ID_886518-1.md",
    "section": "SQL and Pandas",
    "content": "Summary: Today we will help you acquire skills with SQL.\n\nüí° Tap here to leave your feedback on the project. It's anonymous and will help our team make your educational experience better. We recommend completing the survey immediately after the project."
  },
  {
    "id": "3f8f01f4-f689-4d7f-b4dc-c92e65fd7a09",
    "source_file": "README_DS_Bootcamp.Day06.ID_886518-1.md",
    "section": "Contents",
    "content": "1. Chapter I 1.1. Foreword\n2. Chapter II 2.1. Instructions\n3. Chapter III 3.1. Specific instructions for the day\n4. Chapter IV 4.1. Exercise 00 : Select\n5. Chapter V 5.1. Exercise 01 : Subquery\n6. Chapter VI 6.1. Exercise 02 : Join\n7. Chapter VII 7.1. Exercise 03 : Aggregations\n8. Chapter VIII \n   8.1. Exercise 04 : A/B-testing"
  },
  {
    "id": "0bbcb621-f5f9-4c8d-848a-5b70fcb889e5",
    "source_file": "README_DS_Bootcamp.Day06.ID_886518-1.md",
    "section": "Foreword",
    "content": "Sequel or Ess QueKyew Ell? How to pronounce SQL correctly? Some interviewers even\nreject interviewees if they fail of pronounce it the ‚Äúright‚Äù way. Apparently, it is really\nimportant to know which is correct.\n\nSQL was originally spelled SEQUEL (Structured English Query Language), but it\nturned out later that this was the registered trademark of an aircraft company. The\nauthors had to change it. Since then, it has been SQL (Structure Query Language). One\nof the authors was asked which pronunciation is correct. He answered:\n\n\nSince the language was originally named SEQUEL, many people continued to pronounce\nthe name that way after it was shortened to SQL. Both pronunciations are widely\nused and recognized. As to which is more ‚Äúofficial‚Äù, I guess the authority\nwould be the ISO Standard, which is spelled (and presumably pronounced) S-Q-L. \n\nThanks for your interest,\n\nDon Chamberlin\n\n\nSo one of the authors said that you can use both ways. S-Q-L is a more official way\nof doing it (presumably, huh?). What do other ‚Äúauthority figures‚Äù think?\n\nIt is said that the official way to pronounce ‚ÄúMySQL‚Äù is ‚ÄúMy Ess Kyew Ell‚Äù (not ‚Äúmy\nsequel‚Äù). At the same time, the official Oracle documentation says that the right way to\npronounce it is ‚Äúsequel‚Äù.\n\nBefore diving into the exercises you should make an important choice are you going\nto pronounce Sequel or S-Q-L? More informal or more formal? Where does your heart\nlie?"
  },
  {
    "id": "5b684610-c80a-4b5f-8d53-4d23bfc49900",
    "source_file": "README_DS_Bootcamp.Day06.ID_886518-1.md",
    "section": "Instructions",
    "content": "* Use this page as your only reference. Do not listen to any rumors or speculations\n  about how to prepare your solution.\n* Here and further on we use Python 3 as the only correct version of Python.\n* The solutions for python exercises (d01, d02, d03) must have the following block in\n  the end: if __name__ == ‚Äò__main__‚Äô.\n* Pay attention to the permissions of your files and directories.\n* To be assessed your solution must be in your GIT repository.\n* Your solutions will be evaluated by your piscine peers.\n* You should not leave any additional files in your directory other than those explicitly\n  specified in the subject. It is recommended that you modify your .gitignore to avoid\n  any accidents.\n* Your solution must be in your GIT repository for evaluation. Always push only to the develop branch! The master branch will be ignored. Work in the src directory.\n* When you need to get precise output in your programs, it is forbidden to display a\n  precalculated output instead of performing the exercise correctly.\n* Have a question? Ask your neighbor on the right. If that fails, try your neighbor\n  on the left.\n* Your reference material: peers / Internet / Google.\n* You can ask questions in Slack.\n* Read the examples carefully. They may require things that are not otherwise specified in the subject.\n* And may the Force be with you!"
  },
  {
    "id": "b773f8e1-8686-4b4a-ad08-a501bffd50cf",
    "source_file": "README_DS_Bootcamp.Day06.ID_886518-1.md",
    "section": "Specific instructions for the day",
    "content": "* Use Jupyter Notebook to work with your code\n* For each major subtask in the list of any exercise (black bullets), your ipynb file\n  should have an h2 heading to help your peer navigate easily within your code\n* No imports allowed, except those explicitly mentioned in the section ‚ÄúAuthorized\n  functions‚Äù of the title block of each exercise\n* You can use any built-in function, as long as it is not prohibited in the exercise\n* Today, you can use only the following methods from Pandas: io.sql.read_sql and\n  to_sql, unless otherwise explicitly prescribed in the exercise.\n* Save and load all the required data in the subfolder data/"
  },
  {
    "id": "602433d8-6e2f-4000-9f36-f7f157491f00",
    "source_file": "README_DS_Bootcamp.Day06.ID_886518-1.md",
    "section": "Exercise 00 : Select",
    "content": "Exercise 00\n\nSelect\n\nTurn-in directory : ex00/\n\nFiles to turn in : ex00_first_select.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3\n\nSometimes only having Python in your toolbox can be limiting. Remember that\nduring the first day of Piscine, you were working with command-line tools because they\ncan be more efficient for some tasks. Today you will work with SQL. Why can it be useful\nfor you? Sometimes your data might be not in convenient CSVs or JSONs but stored in\na database, and you have to extract it from there somehow. Also, SQL can be used in\nApache Spark and in Hive (but with HQL) tools that are used for processing big data.\n\nDownload the SQLite database. Over the course of the day, you will work with\ndifferent tables from it using Pandas. They are all connected and refer to the same\nproject. It comprises a real dataset from an educational company. They have their own\nplatform where every student can check if their solution is correct and receive some other\nfeedback. The table checker stores the logs of when and which labs the users checked.\n\n!lada\n\nThe company decided to create a new page on the platform, Newsfeed, where those\nlogs are visible to all the students in the program. The logs of the page visits are stored in\nanother table ‚Äì pageviews. The hypothesis was that the page would create peer pressure\nand the students would start working on the labs earlier. That could be good because\nthey could make more iterations and try different approaches. In this series of exercises,\nyou will try to figure out if this hypothesis is correct.\n\n!lenta\n\nBut let us start with something super simple. In this exercise, you will need to get\nthe filtered data from a table in the database. Why is it important to filter the data in\nthe query but not afterward in Pandas? Because tables can be enormous. If you try to\nget the whole table, you will not be able to process it. Always keep this in mind.\n\nThe first method of filtering is to only choose those columns that you really need.\n\nThe second is to choose the rows that you really need.\n\nIn more detail:\n\n* put the database in the subfolder data in the src directory of the day\n* create a connection to the database using the library sqlite3\n* get the schema of the table pageviews using pd.io.sql.read_sql and the query\n  \"PRAGMA table_info(pageviews);\"\n* get only the first 10 rows of the table pageviews to check what the table looks like\n* get the subtable using only one query where:\n  * only uid and datetime are used\n   only user data (user_) is used and not admin data\n  * it is sorted by uid in ascending order\n  * the index column is datetime\n  * datetime is converted to DatetimeIndex\n  * the name of the dataframe is pageviews\n* close the connection to the database"
  },
  {
    "id": "1caf2d37-8edd-466d-bf48-33177b5da192",
    "source_file": "README_DS_Bootcamp.Day06.ID_886518-1.md",
    "section": "Exercise 01 : Subquery",
    "content": "Exercise 01\n\nSubquery\n\nTurn-in directory : ex01/\n\nFiles to turn in : ex01_subquery.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3\n\nOk, let us make something more complicated. Have you heard about subqueries?\nLike a query inside a query. Why can it be useful to you? In general, you might want\nto make some aggregations over a select that you had made before. Beware though that\nnested queries run first and alone, then the main query runs.\n\nHere is what you need to do:\n\n* create a connection to the database using the library sqlite3\n* get the schema of the table checker\n* get only the first 10 rows of the table checker to check what the table looks like\n* count how many rows satisfy the following conditions using only one query with\n  any number of subqueries:\n  * count the rows from the pageviews table but only with users from the checker\n    table with:\n    * status = ‚Äôready‚Äô, we do not want to analyze the logs that are in\n      status\n      checking\n    * numTrials = 1, we want to analyze only the first commits,\n      because only\n      they can tell us when a student started working on a lab\n    * labnames should be from the list: ‚Äôlaba04‚Äô, ‚Äôlaba04s‚Äô, ‚Äôlaba05‚Äô,\n      ‚Äôlaba06‚Äô,\n      ‚Äôlaba06s‚Äô, ‚Äôproject1‚Äô. Only they were active during the experiment\n  * store in the dataframe checkers with the column cnt\n* close the connection"
  },
  {
    "id": "9aa98309-b03d-438a-ba83-4393feda38b6",
    "source_file": "README_DS_Bootcamp.Day06.ID_886518-1.md",
    "section": "Exercise 02 : Join",
    "content": "Exercise 02\n\nJoin\n\nTurn-in directory : ex02/\n\nFiles to turn in : ex02_joins.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3\n\nIn this exercise, you will create a so-called datamart. It is a table that can be used\nfor analytics purposes. Usually, it is created by joining different tables together. In this\nexercise, we will collect various bits of data about our users: when they did their first\ncommits, when they visited the newsfeed for the first time, etc. This will help us analyze\nit later.\n\nWhat you need to do in this exercise (read the full task):\n\n* create a connection to the database using the library sqlite3\n* create a new table datamart in the database by joining the tables pageviews and\n  checker using only one query\n  * the table should have the following columns: uid, labname, first_commit_ts,\n    first_view_ts\n  * first_commit_ts is just a new name of the column timestamp from the checker\n    table, it shows the first commit from a particular lab and from a particular\n    user\n  * first_view_ts is the first visit of a user to the table pageviews, timestamp\n    when a user visited the newsfeed\n  * status = ‚Äôready‚Äô should still be a filter\n  * numTrials = 1 should still be a filter\n  * labnames should still be from the list: ‚Äôlaba04‚Äô, ‚Äôlaba04s‚Äô, ‚Äôlaba05‚Äô, ‚Äôlaba06‚Äô,\n    ‚Äôlaba06s‚Äô, ‚Äôproject1‚Äô\n   the table should contain only the users (uids with user_) and not the admins\n  * first_commit_ts and first_view_ts should be parsed as datetime64[ns]\n* using Pandas methods, create two dataframes: test and control\n  * test should have the users that have the values in first_view_ts\n  * control should have the users that have missing values in first_view_ts\n  * replace the missing values in the control with the average first_view_ts of the\n    test users, we will use this value for the future analysis\n  * save both tables into the database, you will use them in the next exercises\n* close the connection\n\nA small piece of advice ‚Äì do this step by step, from simple to more complex. It will\nhelp you to debug your queries."
  },
  {
    "id": "c282543a-be9e-4fe1-987e-0462e42a3f79",
    "source_file": "README_DS_Bootcamp.Day06.ID_886518-1.md",
    "section": "Exercise 03 : Aggregations",
    "content": "Exercise 03\n\nAggregations\n\nTurn-in directory : ex03/\n\nFiles to turn in : ex03_aggs.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3\n\nWhat we did before was just data preparation. We have not gotten any insights into\nthe data. It is time to change that. Remember how we had the hypothesis that the users\nwould start working on the labs earlier if they saw the newsfeed? It means that the key\nmetric for us is a delta between when a user started working on a lab (their first commit)\nand the deadline of the lab.\n\nWhat you need to do in this exercise:\n\n* create a connection to the database using the library sqlite3\n* get the schema of the table test\n* get only the first 10 rows of the table test to check what the table looks like\n* find among all the users the minimum value of the delta between the first commit\n  of the user and the deadline of the corresponding lab using only one query\n  * do this by joining the table with the table deadlines\n  * the difference should be displayed in hours\n  * do not take the lab ‚Äôproject1‚Äô into account, it has longer deadlines and will be\n    an outlier\n  * the value should be stored in the dataframe df_min with the corresponding\n    uid\n* do the same thing, but for the maximum, using only one query, the dataframe name is\n  df_max\n* do the same thing but for the average, using only one query, this time your dataframe\n  should not include the uid column, and the dataframe name is df_avg\n* we want to test the hypothesis that the users who visited the newsfeed just a few\n  times have the lower delta between the first commit and the deadline. To do this,\n  you need to calculate the correlation coefficient between the number of pageviews\n  and the difference\n  * using only one query, create a table with the columns: uid, avg_diff, pageviews\n  * uid is the uids that exist in the test\n  * avg_diff is the average delta between the first commit and the lab deadline per user\n  * pageviews is the number of Newsfeed visits per user\n  * do not take the lab ‚Äôproject1‚Äô into account\n  * store it to the dataframe views_diff\n  * use the Pandas method corr() to calculate the correlation coefficient between\n    the number of pageviews and the difference\n* close the connection"
  },
  {
    "id": "13617ef0-d458-40a3-abd3-14f273457f0f",
    "source_file": "README_DS_Bootcamp.Day06.ID_886518-1.md",
    "section": "Exercise 04 : A/B-testing",
    "content": "Exercise 04\n\nA/B-testing\n\nTurn-in directory : ex04/\n\nFiles to turn in : ex04_ab-test.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3\n\nSo... let us finally find out if the Newsfeed affected the behavior of the students. Did\nthey start to work on the labs earlier? Remember that we have two prepared tables in the\ndatabase test and control. We are going to conduct something similar to an A/B-test.\nWe need to calculate what the delta between the first commit and the deadline was before\nthey visited the page for the first time and afterward. We need to do the same thing for\nthe control group too.\n\nIn other words, each user in the test has their own timestamp for their first newsfeed\nvisit. We want to calculate the average delta (first commit - deadline) before that times-\ntamp and after that timestamp. We will do the same thing for the users in the control\ngroup. You may say: ‚Äúbut they did not visit the newsfeed at all‚Äù. That is correct, and\nwe decided earlier to use the average timestamp of the first view from the test group for\nthe users in the control group.\n\nIf the delta before the first Newsfeed visit is significantly different compared to the\ndelta afterward in the test group, and we do not see the same effect in the control group,\nthen creating the page was a great idea. We can roll it out to the whole group.\n\nIn more detail:\n\n* create a connection to the database using the library sqlite3\n* using only one query for each of the groups, create two dataframes: test_results\n  and control_results with the columns time and avg_diff and only two rows\n  * time should have the values: after and before\n  * avg_diff contains the average delta among all the users for the time period\n    before each of them made their first visit to the page and afterward\n  * only take into account the users that have observations before and after\n* we still are not using the lab ‚Äôproject1‚Äô\n* close the connection\n* have the answer: did the hypothesis turn out to be true and the page does affect\n  the students‚Äô behavior?"
  },
  {
    "id": "6a59567c-a49e-437a-8fe5-b6fbd1d32d35",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Pandas, SQL and Data Visualization",
    "content": "Summary: Today we will help you with data visualization in Matplotlib, Seaborn, and Plotly.\n\nüí° Tap here to leave your feedback on the project. It's anonymous and will help our team make your educational experience better. We recommend completing the survey immediately after the project."
  },
  {
    "id": "e5a589c6-87d1-4c9b-ac35-133caec76088",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Contents",
    "content": "1. Chapter I 1.1. Foreword\n2. Chapter II 2.1. Instructions\n3. Chapter III 3.1. Specific instructions for the day\n4. Chapter IV Mandatory part 4.1. Exercise 00 : Line chart\n5. Chapter V 5.1. Exercise 01 : Line chart with styles\n6. Chapter VI 6.1. Exercise 02 : Bar\n7. Chapter VII 7.1. Exercise 03 : Bar charts\n8. Chapter VIII 8.1. Exercise 04 : Histogram\n9. Chapter IX 9.1. Exercise 05 : Boxplot\n10. Chapter X 10.1. Part 1\n11. Chapter XI Bonus part 11.1. Exercise 07 : Heatmap\n12. Chapter XII 12.1. Exercise 08 : Seaborn\n13. Chapter XIII \n    13.1. Exercise 09 : Plotly"
  },
  {
    "id": "22a78efb-5221-449b-8b3b-d72648c40b32",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Foreword",
    "content": "Visualization is good for two reasons. The First, it is very useful when you need to com-\nmunicate your results to somebody: your employer, colleagues, customers, etc. Second, it\nis useful building for a better understanding of the data. Here is an example that shows\nwhy it is important.\n\nTry to imagine or use a piece of paper to graph the distribution of two variables with the following characteristics.\n\n!1\n\nDo you think that there is only one way to place the dots?\n\nNo, there are several. It is called Anscombe‚Äôs quartet.\n\n!2\n\nAll of the graphs above have the same characteristics. Can you believe it?\n\nLooking at the characteristics alone can be misleading. Use graphs to understand the\ndata better."
  },
  {
    "id": "da7962cd-245d-4d5e-8d30-69719c3f0886",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Instructions",
    "content": "* Use this page as your only reference. Do not listen to any rumors or speculations\n  about how to prepare your solution.\n* Here and further on we use Python 3 as the only correct version of Python.\n* The solutions for python exercises (d01, d02, d03) must have the following block in\n  the end: if __name__ == ‚Äò__main__‚Äô.\n* Pay attention to the permissions of your files and directories.\n* To be assessed your solution must be in your GIT repository.\n* Your solutions will be evaluated by your piscine peers.\n* You should not leave any additional files in your directory other than those explicitly\n  specified in the subject. It is recommended that you modify your .gitignore to avoid\n  any accidents.\n* Your solution must be in your GIT repository for evaluation. Always push only to the develop branch! The master branch will be ignored. Work in the src directory.\n* When you need to get precise output in your programs, it is forbidden to display a\n  precalculated output instead of performing the exercise correctly.\n* Have a question? Ask your neighbor on the right. If that fails, try your neighbor\n  on the left.\n* Your reference material: peers / Internet / Google.\n* You can ask questions in Slack.\n* Read the examples carefully. They may require things that are not otherwise specified in the subject.\n* And may the Force be with you!"
  },
  {
    "id": "f67bff4e-db2a-4905-84a9-34272c255fe6",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Specific instructions for the day",
    "content": "* Use Jupyter Notebook to work with your code\n* No imports are allowed, except those explicitly mentioned in the section ‚ÄúAutho-\n  rized functions‚Äù of the title block of each exercise\n* You can use any built-in function, as long as it is not prohibited within the exercise\n* Save and load all the required data in the subfolder data/"
  },
  {
    "id": "86afce28-5f57-408e-b7e8-cc42d839c466",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Exercise 00 : Line chart",
    "content": "Exercise 00\n\nLine chart\n\nTurn-in directory : ex00/\n\nFiles to turn in : 00_line_chart.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3\n\nToday, you will work with the same datasets that you used on the previous day.\n\nWe will try to understand the data about how the students of the educational company\nbehave. You will use Pandas and SQL again to sharpen your skills and use various\nlibraries for data visualization in Python: Matplotlib, Seaborn, and Plotly.\n\nAs usual, let us start with something simple. If you have not drawn a graph in Python,\nit is time to do it for the first time.\n\nRemember how we analyzed the newsfeed page? Did you wonder how often the page\nwas visited in time?\n\n* make a connection to the database (it is the same as the previous day)\n* run a query that gets the datetime from the pageviews table, selecting only the\n  users and not the admins\n* using Pandas, create a new dataframe where the visits are counted and grouped by\n  date\n* using Pandas method .plot(), create a graph\n  * the size of the font should be 8\n  * the size of the figure is (15,8)\n  * the graph must have the title Views per day\n  * notice the rotation of xticks on the graph below\n* close the connection to the database\n\n!3"
  },
  {
    "id": "a6827cc6-9e10-4086-aaec-6d1b27ddc930",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Exercise 01 : Line chart with styles",
    "content": "Exercise 01\n\nLine chart with styles\n\nTurn-in directory : ex01/\n\nFiles to turn in : 01_line_chart_styles.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3\n\nCool! Remember that we have the data about the commits? Wouldn‚Äôt it be cool to\ndraw both of the metrics in time on the same graph? What if we will see some patterns?\n\nYou need to create exactly the same graph as below (both values and style):\n\n!4\n\n* analyze only the users and not the admins\n* analyze only the dates when there were both views and checker commits\n* use size of the font should be 8\n* the size of the figure is (15,8)\n* at the end of your Jupyter Notebook create a markdown cell and insert the question:\n  ‚ÄúHow many times was the number of views larger than 150?‚Äù Insert: ‚ÄúThe answer\n  is ___‚Äù. Put the number in the text instead of the underline."
  },
  {
    "id": "6b595ad6-df5b-4e25-ae15-4a9f3b707810",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Exercise 02 : Bar",
    "content": "Exercise 02\n\nBar\n\nTurn-in directory : ex02/\n\nFiles to turn in : 02_bar_chart.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3\n\nWe have another question for you to answer: when do our users usually commit the\nlabs: in the night, morning, afternoon, or evening? And how has it changed over time?\n\nDo what you need to do to create a graph like this:\n\n!5\n\n* analyze only the users and not the admins\n* the fontsize and the figsize are still the same\n* night is from 0:00:00 to 03:59:59, morning is from 04:00:00 to 09:59:59, afternoon\n  is from 10:00:00 to 16:59:59, evening is from 17:00:00 to 23:59:59\n* choose a palette that you really enjoy, you do not have to replicate it from the graph\n  above\n* at the end of your Jupyter Notebook, create a markdown cell and insert the ques-\n  tions:\n  * ‚ÄúWhen do our users usually commit the labs: in the night, morning, afternoon,\n    or evening?‚Äù, the answer is the two most common periods.\n  * Which day has:\n    * the most number of commits\n    * and at the same time, the number of commits in the evening is higher than in the afternoon?\n\nThe answer is the date of that day."
  },
  {
    "id": "9ee73207-22c8-45d9-bb07-3c7ac39ec1b8",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Exercise 03 : Bar charts",
    "content": "Exercise 03\n\nBar charts\n\nTurn-in directory : ex03/\n\nFiles to turn in : 03_bar_charts.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3\n\nWhat if the average number of commits is different when it is a working day or\nweekend?\n\nDo what you need to do to create a graph like this:\n\n!6\n\n* analyze only the users and not the admins\n* the fontsize and the figsize remain the same\n* for each hour, calculate the average number of commits on working days and on\n  weekends (if there were no commits in an hour, do not use it to calculate the\n  average) use these values for your graph, for example: Mon, 17-18: 5 commits, Tue,\n  17-18: 6 commits, Wed, 17-18: 7 commits\n* choose a palette that you really enjoy, you do not have to replicate it from the graph\n  above\n* at the end of your Jupyter Notebook, create a markdown cell and insert the question\n  * ‚ÄúIs the dynamic different on working days and weekends?‚Äù, for the answer\n    include the hour when the number of commits is the largest during working days and the hour when it is the largest during the weekend."
  },
  {
    "id": "29271a7b-479e-4443-a827-9055b80faa59",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Exercise 04 : Histogram",
    "content": "Exercise 04\n\nHistogram\n\nTurn-in directory : ex04/\n\nFiles to turn in : 04_histogram.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3, import matplotlib.pyplot as plt\n\nIn the previous exercise, you had to draw a distribution grouping the values using\nPandas. Wouldn‚Äôt it be nice if we could draw it in a more automatic way? Well, we can.\n\nBut we have to use another type of visualization ‚Äì histograms. This time, we will not\nuse the averages. We will use the absolute numbers of commits and will compare them\nduring working days and weekends.\n\nDo what you need to do to create a graph like this:\n\n!7\n\n* analyze only the users and not the admins\n* create two lists of values (for working days and for weekends) for the histogram\n  input\n* the figsize is still the same, you can choose the fontsize as well as the color palette\n* use a level of transparency for the histogram in front equal to 0.7\n* at the end of your Jupyter Notebook, create a markdown cell and insert the question:\n  ‚ÄúAre there hours when the total number of commits was higher on weekends than\n  on working days?‚Äù In your answer, put the top-4 examples."
  },
  {
    "id": "34e2f899-b40d-4c5f-a13c-aae4f9ad6693",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Exercise 05 : Boxplot",
    "content": "Exercise 05\n\nBoxplot\n\nTurn-in directory : ex05/\n\nFiles to turn in : 05_boxplot.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3, import matplotlib.pyplot as plt\n\nRemember how we tried to figure out if the newsfeed affected the behavior of the test\nand control users? Last time, we just calculated the average values. But do we know\nsomething about the variances? What if it changed too? What if we had some outliers?\n\nTo answer those questions it may be handy to draw a boxplot.\n\nDo what you need to do to create a graph like this:\n\n!8\n\n* use the data from the file, read it to a dataframe and make any modification that\n  you may find useful to solve the task\n* the figsize is still the same, you can choose whatever fontsize you like\n* the color palette should be the same as in the example\n* the fontsize of the title is 15\n* the width of the box lines is 3, the width of the median lines is 2\n* at the end of your Jupyter Notebook, create a markdown cell and insert the question:\n  ‚ÄúWhat was the IQR of the control group before the newsfeed?‚Äù In your answer, put\n  the approximate value that you can get just by looking at the graph, round it to\n  the nearest 10"
  },
  {
    "id": "55709cf1-72f5-4060-bbb1-7b93656d1d24",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Exercise 06 : Scatter Matrix",
    "content": "Exercise 06\n\nScatter Matrix\n\nTurn-in directory : ex06/\n\nFiles to turn in : 06_scatter_matrix.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3, from pandas.plotting import\nscatter_matrix\n\nRemember how we tried to find out if there was a correlation between the number of\nvisits to the Newsfeed and the average difference between the first commit and the lab\ndeadline? The problem is that the correlation coefficient shows whether there is a linear\nrelationship between the two variables. But what if it is not linear? How can we see\nthat? That‚Äôs right ‚Äì by drawing graphs!\n\nDo what you need to do to create a graph like this:\n\n!9\n\n* create a dataframe where each user of the test group has the average difference,\n  number of pageviews and number of commits\n* do not take project1 into account for calculations of the average difference and the\n  number of commits\n* take the number of commits from the checker table\n* the figsize is still the same, you can choose whatever fontsize you like as well as the\n  color palette\n* the size of the dots should be 200\n* the width of the lines of the diagonal graphs (kde) should be 3\n* at the end of your Jupyter Notebook, create a markdown cell and insert the questions:\n  * ‚ÄúCan we say that if a user has a low number of pageviews then they likely\n    have a low number of commits?‚Äù The answer: yes or no.\n  * ‚ÄúCan we say that if a user has a low number of pageviews then they likely have\n    a small average difference between the first commit and the lab deadline?‚Äù The\n    answer: yes or no.\n  * ‚ÄúCan we say that there are many users with a low number of commits and a\n    few with a high number of commits‚Äù? The answer: yes or no.\n  * ‚ÄúCan we say that there are many users with a small average difference and a\n    few with a large average difference‚Äù? The answer: yes or no."
  },
  {
    "id": "091cec3d-0770-4f87-90aa-700fbc301f2d",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Exercise 07 : Heatmap",
    "content": "Exercise 07\n\nHeatmap\n\nTurn-in directory : ex07/\n\nFiles to turn in : 07_heatmap.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3, import matplotlib.pyplot as plt, from\nmpl_toolkits.axes_grid1 import make_axes_locatable\n\nSeveral exercises back, we wanted to see if there are different patterns for users during\nworking days and weekends. In this exercise, let us find out if there are different patterns\nfor users between different weekdays and between different hours.\n\n* analyze only the users and not the admins\n* you can choose the color palette that you like for both of the graphs that you will\n  need to draw in this exercise\n* use the table checker for your query\n* use absolute values of the commits, not the averages\n* sort the dataframes by the total number of commits made by a user\n* at the end of your Jupyter Notebook create a markdown cell and insert the questions\n  (answer them looking only at the graphs):\n   ‚ó¶ ‚ÄúWhich user has the most commits on Tue?‚Äù The answer: user_.\n   ‚ÄúWhich user has the most commits on Thu?‚Äù The answer: user_.\n  * ‚ÄúOn which weekday do the users not like making a lot of commits?‚Äù The\n    answer, for example: Mon.\n  * ‚ÄúWhich user at which hour made the largest number of commits?‚Äù The answer,\n    for example: user_1, 15\n\nDo what you need to do to create two graphs like this:\n\n!10"
  },
  {
    "id": "1399832b-95d7-4f68-ba6b-36fb4c56ee49",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Exercise 08 : Seaborn",
    "content": "Exercise 08\n\nSeaborn\n\nTurn-in directory : ex08/\n\nFiles to turn in : 08_seaborn.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3, import matplotlib.pyplot as plt, import\nseaborn as sns\n\nOk, sometimes in the previous exercises we ignored project1 in our calculations. The\nproject was a competition. It had longer deadlines and much more commits than ordinary\nlabs had. Let us see the dynamic of commits in this project per user. This time we will\nuse another library for data visualization in Python ‚Äì Seaborn. In general, it is much\neasier to create something beautiful in that library.\n\nDo what you need to do to create a graph like this:\n\n!11\n\n* analyze only the users and not the admins\n* take into account only logs from the table checker where the status is ready\n* you can choose the palette that you enjoy\n* the linewidth should be 3\n* the background of the graph is gray\n* the height should be 10, and the width should 1.5x in relation to the height\n* the fontsize of the title should be 30\n* the fontsize of the axises labels is 15\n* at the end of your Jupyter Notebook create a markdown cell and insert the questions\n  (answer them looking only at the graphs):\n  * ‚ÄúWhich user was the leader in the number of commits almost all of the time?‚Äù\n    The answer: user_*.\n  * ‚ÄúWhich user was the leader for only a short period of time?‚Äù The answer:\n    user_*."
  },
  {
    "id": "75c17558-15c8-4111-8b23-7132ff5e86cc",
    "source_file": "README_DS_Bootcamp.Day07.ID_886520-1.md",
    "section": "Exercise 09 : Plotly",
    "content": "Exercise 09\n\nPlotly\n\nTurn-in directory : ex09/\n\nFiles to turn in : 09_plotly.ipynb\n\nAllowed functions : import pandas as pd, import sqlite3, import plotly.graph_objects as go,\nimport numpy as np\n\n* Matplotlib and Seaborn are really powerful libraries and you can use them for most\n  of the tasks that you may have related to DataViz. But they do not offer you the\n  functionality of creating interactive charts and animations. And Plotly can help\n  you with that. In this exercise, you will need to create almost the same graph as\n  in the previous exercise but in an animation.\n\nDo what you need to do to create a graph like this:\n\n!12\n\nIt is not an easy task, and it is hard to find good and clear tutorials, so use this link\nas a reference."
  },
  {
    "id": "72a6f2b5-8ebf-4e02-b702-b74c0df9b620",
    "source_file": "README_DS_Bootcamp.Day08.ID_886521-1.md",
    "section": "Intro to Machine Learning",
    "content": "Summary: Today we will help you with basic tasks involved in machine learning in\nPython.\n\nüí° Tap here to leave your feedback on the project. It's anonymous and will help our team make your educational experience better. We recommend completing the survey immediately after the project."
  },
  {
    "id": "83511260-e537-4e54-aabb-1b3a5f363ac2",
    "source_file": "README_DS_Bootcamp.Day08.ID_886521-1.md",
    "section": "Contents",
    "content": "1. Chapter I 1.1. Foreword\n2. Chapter II 2.1. Instructions\n3. Chapter III 3.1. Specific instructions for the day\n4. Chapter IV 4.1. Exercise 00 : Binary classifier\n5. Chapter V 5.1. Exercise 01 : Decision boundaries\n6. Chapter VI 6.1. Exercise 02 : Multiclass\n7. Chapter VII 7.1. Exercise 03 : Overfitting\n8. Chapter VIII 8.1. Exercise 04 : Regression\n9. Chapter IX \n   9.1. Exercise 05 : Clustering"
  },
  {
    "id": "6cb53840-b796-4a20-aa4c-dc584ef77020",
    "source_file": "README_DS_Bootcamp.Day08.ID_886521-1.md",
    "section": "Foreword",
    "content": "* There are a lot of different terms that are connected to the data field: artificial\n  intelligence, machine learning, neural nets, and deep learning. But do you know\n  the difference between them?\n* Each item of the list is a subset of the previous item. The broadest term is artificial\n  intelligence includes any techniques that mimic human cognitive behavior. It can\n  use machine learning algorithms in order to do this, or any other techniques like\n  just writing a program with many ‚Äúif-then-else‚Äù rules.\n* Machine learning includes statistical algorithms that automate the process of creating the rules. The machine can find correlations and use them for different tasks\n  by ‚Äúlooking‚Äù at the data.\n* Neural nets are a subset of machine learning algorithms. They were created through\n  the inspiration of how the human brain works (but they are still a far cry away from\n  it). And deep learning algorithms are a subset of neural nets. They usually have\n  many layers. That is why they are called ‚Äúdeep‚Äù.\n* Remember that none of these algorithms are limitless. They can help you only if\n  you have the data. Simple algorithms can be satisfied with small amounts of data,\n  and deep learning algorithms require large amounts of data. At the same time,\n  if your data is garbage, the knowledge that you get from the algorithms will be\n  garbage too. No surprise, huh?"
  },
  {
    "id": "c62739ea-a2c7-4039-8f2d-369d9a864529",
    "source_file": "README_DS_Bootcamp.Day08.ID_886521-1.md",
    "section": "Instructions",
    "content": "* Use this page as your only reference. Do not listen to any rumors or speculations\n  about how to prepare your solution.\n* Here and further on we use Python 3 as the only correct version of Python.\n* The solutions for python exercises (d01, d02, d03) must have the following block in\n  the end: if __name__ == ‚Äò__main__‚Äô.\n* Pay attention to the permissions of your files and directories.\n* To be assessed your solution must be in your GIT repository.\n* Your solutions will be evaluated by your piscine peers.\n* You should not leave any additional files in your directory other than those explicitly\n  specified in the subject. It is recommended that you modify your .gitignore to avoid\n  any accidents.\n* Your solution must be in your GIT repository for evaluation. Always push only to the develop branch! The master branch will be ignored. Work in the src directory.\n* When you need to get precise output in your programs, it is forbidden to display a\n  precalculated output instead of performing the exercise correctly.\n* Have a question? Ask your neighbor on the right. If that fails, try your neighbor\n  on the left.\n* Your reference material: peers / Internet / Google.\n* You can ask questions in Slack.\n* Read the examples carefully. They may require things that are not otherwise specified in the subject.\n* And may the Force be with you!"
  },
  {
    "id": "dcfd4d51-ed01-48a6-b584-7688071e89f7",
    "source_file": "README_DS_Bootcamp.Day08.ID_886521-1.md",
    "section": "Specific instructions for the day",
    "content": "* Use Jupyter Notebook to work with your code\n* For each major subtask in the list of any exercise (black bullets), your ipynb file\n  should have an h2 heading to help your peer easily navigate within your code\n* No imports are allowed, except those explicitly mentioned in the section ‚ÄúAuthorized functions‚Äù of the title block of each exercise\n* You can use any built-in function, as long as it is not prohibited in the exercise\n* Save and load all the required data to the subfolder data/\n* scikit-learn (0.23.1) is the library that you need for all the machine learning tasks."
  },
  {
    "id": "85756022-8e2b-427c-b442-06edf7b9f578",
    "source_file": "README_DS_Bootcamp.Day08.ID_886521-1.md",
    "section": "Exercise 00 : Binary classifier",
    "content": "Exercise 00\n\nBinary classifier\n\nTurn-in directory : ex00/\n\nFiles to turn in : 00_binary_classifier_logreg.ipynb\n\nAllowed functions : no restrictions\n\nYou will work with machine learning today and the following day. Today we will cover\nthe basics necessary to not to get overwhelmed by too much information. The following\nday, will cover some more sophisticated techniques. So stay tuned!\n\nFirst of all, machine learning can be divided into supervised and unsupervised. In\nsupervised learning, you want to predict something. In order to do that, you give the\nmachine examples: a bunch of features and a target variable. Imagine that you want\nto predict whether a user would like or dislike a given movie. The features (X) can\nbe: genre, year of creation, budget, cast, director, and so on. The target (y) will be\nlike/dislike. That kind of task is a classification task. In classification problems, y is\nalways categorical. If your target variable is continuous (for instance, a movie rating), it\nis called a regression problem.\n\nUnsupervised learning does not require labels (target variable). It does not forecast\nanything. Usually, it helps you to understand your data better. For example, clustering\nalgorithms help you identify homogeneous groups of observations. You may find that you\ncan divide your users into 6 groups. And for each of these groups create a special offer or\na recommendation. Do not confuse this with classification. You are not trying to predict\nanything. You are just looking at your data.\n\nBesides clustering algorithms, unsupervised learning includes dimensionality reduction algorithms. They help you to reduce the number of features or observations. It may\nbe helpful if you have a lot of them, but you do not have sufficient resources. Also, they\nmay help you to find some latent features and improve the quality of your algorithms in\nsupervised learning.\n\nBut enough theory! Let us try to train our first classifier. It will be a binary classifier\nwhich means that the target variable has only two unique values. You will work with\nthe dataset from the previous days. It is absolutely normal. Actually, that is how data\nscience works. You start from the descriptive analysis and proceed by analyzing some\nbasic statistics. Then you go further and do explorative analysis by drawing different\nplots and, as a result, get a better understanding of your data. Only then do you move\non to predictive analysis to forecast something.\n\nIn this exercise imagine the following situation (which is, by the way, quite common).\nFrom some moment in the past, you realized that the more data you collect, the better.\n\nAnd you started saving more fields in the logs. Before, you had been collecting only the\ntime of the commit. But from that point in time, you started collecting the date too.\n\nNow you need to train a classifier that can predict whether any given commit was\nmade during working days or during weekends. Then you will be able to use the classifier\nto label the commits in the past when you had not been collecting the data.\n\nEvery supervised machine learning algorithm requires at least two arguments: X and\ny. X is the list of features and y is the target column. But what are the features?\n\nAs you no doubt recall, we only have logs like this 2020-04-17 05:19:02.744528. How\ncan we use this to predict the type of weekday? That is the creative part of the work.\nIt is called feature engineering. You need to extract these features from the logs. What\ncould it be? Remember that the observation in this task is a day? So, we need to\nextract something that can somehow characterize days. What could it be? It may be,\nfor example, the number of commits during the day. It may be the number of commits\nbefore midday and afterward. Or it may be also the percentage of commits made before\nmidday. You are only limited by your imagination!\n\nIn this exercise, we will try a simple approach with only two features: the number of\ncommits before midday and the number of commits after midday.\n\n* What you need to do is described in full details in the notebook."
  },
  {
    "id": "6ffcd7d7-1a91-4904-9e65-8cf1b360e50f",
    "source_file": "README_DS_Bootcamp.Day08.ID_886521-1.md",
    "section": "Exercise 01 : Decision boundaries",
    "content": "Exercise 01\n\nDecision boundaries\n\nTurn-in directory : ex01/\n\nFiles to turn in : 01_binary_classifier_svm_tree.ipynb\n\nAllowed functions : no restrictions\n\nOk, you trained your first classifier! Now it seems probably like magic to you. Let us\nlook under the hood, try to increase the quality of your classifier, and try other algorithms.\n\nIn this exercise you will see how logistic regression works. Also, you will try two more\nmachine learning algorithms: SVM and decision tree. You will visualize them too.\n\n* What you need to do is described in full detail in the notebook."
  },
  {
    "id": "b29f37ea-57bb-47fe-bf01-4435cf1f3d2a",
    "source_file": "README_DS_Bootcamp.Day08.ID_886521-1.md",
    "section": "Exercise 02 : Multiclass",
    "content": "Exercise 02\n\nMulticlass\n\nTurn-in directory : ex02/\n\nFiles to turn in : 02_multiclassi_one-hot.ipynb\n\nAllowed functions : no restrictions\n\nOk, now you understand more or less how different algorithms make classifications.\nIt is time to get closer to a real life scenario. In real life, your target column may contain\nmore than two values. In such cases, you will need to train not a binary classifier,\nbut a multiclass classifier (do not confuse it with multilabel ‚Äì we‚Äôre talking when your\nobservations can belong to several classes at the same time).\n\nAlso, you may have not only continuous features but categorical as well. You need to\ndeal with them somehow. Algorithms understand numbers, they do not know what to\ndo with text.\n\nIn this exercise, you will work with both problems. Also, you will find out which\nfeatures seem the most important for different algorithms. You will also try one more\nalgorithm random forest.\n\nWhat you need to do:\n\n* What you need to do is described in full detail in the notebook.\n\nAin‚Äôt it cool that we can predict the weekday of any commit with high accuracy\nknowing who made it, at what time, for which lab and how many tries they had already\nmade?"
  },
  {
    "id": "874cfff0-51cf-418b-a15f-81a4bbf00ef3",
    "source_file": "README_DS_Bootcamp.Day08.ID_886521-1.md",
    "section": "Exercise 03 : Overfitting",
    "content": "Exercise 03\n\nOverfitting\n\nTurn-in directory : ex03/\n\nFiles to turn in : 03_split_crossval.ipynb\n\nAllowed functions : no restrictions\n\nWe are sure that you managed to achieve pretty high values of accuracy. But those\nnumbers are kind of unfair. Why? You were making predictions on the same data that\nyou had used for training. Your models could just memorize all the observations. In\ntheory, you could achieve 100% accuracy, but would your model still be any good if it\ntried to make predictions for data that it had not seen? We highly doubt it. That is\ncalled overfitting.\n\nOne of the techniques to prevent it is to make a train/test split. You get a portion of\ndata that you use for training, and another portion you use to check the final quality of\nyour model. The second is cross-validation. In this technique, we do not make a constant\nsplit, but we try different splits and see what quality of predictions we get.\n\n* What you need to do is described in full detail in the notebook."
  },
  {
    "id": "7625eb17-9bd9-4253-82b9-16a462d8f27f",
    "source_file": "README_DS_Bootcamp.Day08.ID_886521-1.md",
    "section": "Exercise 04 : Regression",
    "content": "Exercise 04\n\nRegression\n\nTurn-in directory : ex04/\n\nFiles to turn in : 04_regression.ipynb\n\nAllowed functions : no restrictions\n\nYou now know a thing or two about classification tasks. Let us work on a regression\nproblem in this exercise. You will need to predict the average delta between the deadlines\nand the first commit for every user with data about their views of the newsfeed and the\nnumber of commits they made during the program.\n\n* What you need to do is described in full detail in the notebook."
  },
  {
    "id": "8b6b52d7-95ba-4d6f-be3c-075c7309d447",
    "source_file": "README_DS_Bootcamp.Day08.ID_886521-1.md",
    "section": "Exercise 05 : Clustering",
    "content": "Exercise 05\n\nClustering\n\nTurn-in directory : ex05/\n\nFiles to turn in : 05_clustering.ipynb\n\nAllowed functions : no restrictions\n\nIt is time to try using unsupervised machine learning. This time we will work with\nclustering algorithms. We will try to understand whether we can divide our users into\nsome homogenous groups for future analysis. Maybe we can add some more triggers or\nengaging mechanics for them. But the triggers and mechanics may differ depending on\nthe users‚Äô existing behavior.\n\n* What you need to do is described in full detail in the notebook."
  },
  {
    "id": "6156fe53-7f84-4992-b1e7-3b78af774c97",
    "source_file": "README_DS_Bootcamp.Day09.ID_886524-1.md",
    "section": "Machine Learning: Advanced",
    "content": "Summary: Today we will help you master advanced tasks involved in machine learning\nin Python.\n\nüí° Tap here to leave your feedback on the project. It's anonymous and will help our team make your educational experience better. We recommend completing the survey immediately after the project."
  },
  {
    "id": "c02a0cbf-f69d-4ae9-9c54-1e15e51a60d3",
    "source_file": "README_DS_Bootcamp.Day09.ID_886524-1.md",
    "section": "Contents",
    "content": "1. Chapter I 1.1. Foreword\n2. Chapter II 2.1. Instructions\n3. Chapter III 3.1. Specific instructions for the day\n4. Chapter IV 4.1. Exercise 00 : Regularization\n5. Chapter V 5.1. Exercise 01 : Gridsearch\n6. Chapter VI 6.1. Exercise 02 : Metrics\n7. Chapter VII 7.1. Exercise 03 : Ensembles\n8. Chapter VIII \n   8.1. Exercise 04 : Pipelines and OOP"
  },
  {
    "id": "b712f43b-c991-49d8-828c-3cac10105d44",
    "source_file": "README_DS_Bootcamp.Day09.ID_886524-1.md",
    "section": "Foreword",
    "content": "There is real data science and data science for competitions. The difference is the same as\nbetween a porter and weightlifter. A porter can be bad at heavy lifting competitions and\na weightlifter can underperform on a real job. The same is true regarding data science:\nin companies, you should have a broader skill set including, for example, soft skills.\nYou need to understand the business, and to be focused on profit or the organization‚Äôs\nother goals. But in competitions, you simply need to be really good at achieving the\ncompetition‚Äôs target metrics. You may create a super heavy machine learning model that\ncan be 0.00001 better than the model of your next competitor and nobody cares how long\nit takes to make predictions, how interpretable the model is, or how many computational\nresources it requires. In business, of course, all these criteria matter.\n\nNevertheless, you may use competitions for improving your skills. The most popular\nplatform is Kaggle. There are lots of public datasets and competitions. You may even\ntry to win a prize, but most likely, you will only earn experience, which is not bad at all.\nIt can be good for building your portfolio. You may organize a team and learn from each\nother. You can improve your collaboration skills. The platform allows you to pursue the\nmachine learning track as well as the data exploration track: whatever you find more\nattractive.\n\nSo think about it as a great tool for continued growing in the field, but keep in mind\nthat there are lots of things that are needed in real life besides building machine learning\nmodels and optimizaing hyperparameters."
  },
  {
    "id": "87ced410-d30a-4009-828e-8b026ccdac1a",
    "source_file": "README_DS_Bootcamp.Day09.ID_886524-1.md",
    "section": "Instructions",
    "content": "* Use this page as your only reference. Do not listen to any rumors or speculations\n  about how to prepare your solution.\n* Here and further on we use Python 3 as the only correct version of Python.\n* The python files for python exercises (module01, module02, module03) must have\n  the following block in the end: if __name__ == ‚Äò__main__‚Äô.\n* Pay attention to the permissions of your files and directories.\n* To be assessed your solution must be in your GIT repository.\n* Your solutions will be evaluated by your piscine mates.\n* You should not leave in your directory any other file than those explicitly specified\n  by the exercise instructions. It is recommended that you modify your .gitignore to\n  avoid accidents.\n* Your solution must be in your GIT repository for evaluation. Always push only to the develop branch! The master branch will be ignored. Work in the src directory.\n* When you need to get precise output in your programs, it is forbidden to display a\n  precalculated output instead of performing the exercise correctly.\n* Have a question? Ask your neighbor on the right. If that fails, try your neighbor\n  on the left.\n* Your reference material: mates / Internet / Google.\n* You can ask questions in Slack.\n* Read the examples carefully. They may require things that are not otherwise specified in the subject.\n* And may the Force be with you!"
  },
  {
    "id": "bf882c21-f8a9-4efb-9c08-b8aeee2196ec",
    "source_file": "README_DS_Bootcamp.Day09.ID_886524-1.md",
    "section": "Specific instructions for the day",
    "content": "* Use Jupyter Notebook to work with your code\n* For each major subtask in the list of any exercise (black bullets), your ipynb file\n  should have an h2 heading to help your peer easily navigate within your code\n* No imports are allowed, except for those explicitly mentioned in the section ‚ÄúAuthorized functions‚Äù of the title block of each exercise\n* You can use any built-in function as long as it is not prohibited in the exercise\n* Save and load all the required data to the subfolder data/\n* scikit-learn (0.23.1) is the library that you need for all the machine learning tasks.\n* tqdm (4.46.1) is the library that you need for tracking progress"
  },
  {
    "id": "6b0e144a-396e-4972-8d7e-a66dc79196e5",
    "source_file": "README_DS_Bootcamp.Day09.ID_886524-1.md",
    "section": "Exercise 00 : Regularization",
    "content": "Exercise 00\n\nRegularization\n\nTurn-in directory : ex00/\n\nFiles to turn in : regularization.ipynb\n\nAllowed functions : no restrictions\n\nIn the previous day, you tried to solve different kinds of machine learning problems\nusing different algorithms and gained an understanding of the basics. Today, you will try\nusing more advanced techniques.\n\nLet us start with regularization. Regularization in its broader sense is a technique\nthat prevents a model from overfitting. As regards logistic regression, we have a formula\nwith different Xs (features) and coefficients. Regularization penalizes coefficients that are\ntoo big making the formula more robust and more ready for the unknown data that it\nwill have to work with in the future. L1 regularization makes some coefficients equal to\nzero. So this mode may be helpful for feature selection if there are lots of them and you\nneed to reduce the number. L2 regularization does not make the weights equal to zero\nbut may make them smaller. We cannot say: use only L2 regularization or L1. In the\nfield of machine learning, there are not many things that are silver bullets. Usually, you\nneed to try many different things on your dataset to find what suits it best.\n\nIf we talk about trees and forests, regularization is connected to the parameters that\naffect the number of cases in the leaves. If your tree is so thick that each leaf includes\nonly one sample, the chances are that your tree has overfitted to the training dataset.\n\nTo prevent that, you can play with such parameters as max_depth, min_samples_split,\nmin_samples_leaf, max_leaf_nodes, etc.\n\nMany different algorithms have many different parameters of regularization. Our goal\nis not to cover them all. You should just know that they exist, and if you need them,\nyou will understand how they work for a specific algorithm.\n\nIn this exercise, you will play with some of them. The dataset will be the same and the\ntask is still to predict the weekday for each commit with data: uid, labname, numTrials,\nand hour of the commit.\n\nWhat you need to do is fully described in the notebook."
  },
  {
    "id": "dd6271f7-afb6-424a-a0cb-77adfe12dfd5",
    "source_file": "README_DS_Bootcamp.Day09.ID_886524-1.md",
    "section": "Exercise 01 : Gridsearch",
    "content": "Exercise 01\n\nGridsearch\n\nTurn-in directory : ex01/\n\nFiles to turn in : gridsearch.ipynb\n\nAllowed functions : no restrictions\n\nWe are sure that you got tired of iterating through the different parameters of various\nmodels manually. You probably think that there should be a way to automate it. Yes,\nthere is GridSearch.\n\nYou can specify the range of values for the parameters that you want to optimize and\nput it to GridSearchCV. It will try all of them, calculate the metrics on cross-validation,\nand give you the best combination of parameters as well as the overall results of its\nmini-research. That is cool, right?\n\nWhat you need to do describe in the notebook."
  },
  {
    "id": "58286881-9af5-4c72-9d71-20f7af940386",
    "source_file": "README_DS_Bootcamp.Day09.ID_886524-1.md",
    "section": "Exercise 02 : Metrics",
    "content": "Exercise 02\n\nMetrics\n\nTurn-in directory : ex02/\n\nFiles to turn in : metrics.ipynb\n\nAllowed functions : no restrictions\n\nIs 90% accuracy is a good result or not? Actually, it is not easy to say. Imagine a\nsituation in which you have two classes that are unbalanced: 95% of the samples belong\nto the first class and 5% to the second. The accuracy will be worse than a naive classifier\nwhen we make predictions using the most popular class. And this is no fantasy. This\ncase is quite popular for anti-fraud tasks, for example. The number of fraud cases is\nsignificantly lower than the number of normal cases. Is it a bad metric? What we are\ntrying to say is that it is simple to understand and you can use it to compare different\nmodels within a task, but this metric can be misleading when you need to compare the\nresults to a model from another task. Also, it does not say much about the errors. You\njust know how many of them there are. But of what kind?\n\nThere are some other metrics that can answer this question. They all come from the\nconfusion matrix. The first is precision. It is the number of correctly predicted samples\nof one class divided by the number of predictions of that class. Imagine that we predicted\n10 days as a weekend, but only 7 of them were really weekends. The precision is 0.7.\n\nThe second is recall. This is the number of correctly predicted samples of one class\ndivided by the true number of that class. Imagine again that we predicted 10 days as\na weekend but only 7 of them were really weekends and in the dataset there were 20\nweekends. The recall is 0.35 (7/20).\n\nPrecision can be good when we want to show an ad that includes some 16+ content.\nWe want to be precise in our prediction. Recall can be good for identifying terrorists. We\nmay want to find them all no matter how many civilians experience some inconvenience\nalong the way. There is also a metric that combines both of them in the harmonic mean\nF1 score. You can use it when you need to optimize both of them.\n\nAlso, there is the ROC-curve. When you make predictions, you usually you have\nprobabilities. And the final classification is ade by comparing them to the threshold. For\nexample, if we see that, for that given day, the probability of being a weekend is 0.2 and\nthe threshold is 0.5, we can say that it is not a weekend. But if you change the threshold\nto 0.1, the same sample will get the prediction ‚Äúweekend‚Äù. Imagine now, that for each\nthreshold we calculate recall and also the number of how many working days we predicted\nas weekends divided by the real number of working days. We can put both those values\non a plot and we will get the ROC-curve. The higher it is, the better. Comparing curves\ncan be rather inconvenient. That is why we can use another metric AUC (area under the\ncurve). Precision, recall, and AUC are useful when we want to compare the performance\nof different models from different tasks. And they tell us something about the errors.\nEverything that we told you here was connected to binary classification. But it can be\nused with some adjustments for multiclass and multilabel classification. You can read\nabout it here, for example.\n\nWhat you need to do is fully described in the notebook."
  },
  {
    "id": "98bfa7bc-e855-4e33-afac-8011e7bb5763",
    "source_file": "README_DS_Bootcamp.Day09.ID_886524-1.md",
    "section": "Exercise 03 : Ensembles",
    "content": "Exercise 03\n\nEnsembles\n\nTurn-in directory : ex03/\n\nFiles to turn in : ensembles.ipynb\n\nAllowed functions : no restrictions\n\nYou already know that a random forest is an ensemble of many different trees. But\nactually you can create an ensemble from any type of model. In this exercise, you will\ntry several approaches: voting classifier, bagging classifier, and stacking classifier. Who\nknows, maybe it will help you increase the quality of your predictions.\n\nWhat you need to do is fully described in the notebook."
  },
  {
    "id": "da07681b-ec9c-474d-a0d3-1b90365eb322",
    "source_file": "README_DS_Bootcamp.Day09.ID_886524-1.md",
    "section": "Exercise 04 : Pipelines and OOP",
    "content": "Exercise 04\n\nPipelines and OOP\n\nTurn-in directory : ex04/\n\nFiles to turn in : pipelines.ipynb\n\nAllowed functions : no restrictions\n\nWhile trying to solve the problem you executed a lot of different actions: prepared\nthe data, tried different models, tried different metrics, optimized their hyperparameters,\nand tried different kinds of ensembles. Now it probably looks a bit chaotic: your code is\nin different notebooks that require a lot of scrolling. In this exercise, the last of the day,\nyou will make it look a bit cleaner, more organized. Why can this be important? In real\nlife, you may want to share it with your colleagues, you may want to make it a part of\nyour portfolio or it may be for your own future convenience. The chances are that if you\nget back to that code in several months, you will think: who made that mess?\n\nIn this exercise, you will try to apply the OOP approach to data analysis. The first\npart of your notebook will contain only the imports, classes and methods. The second\npart will be your ‚Äúmain program‚Äù. You will work with the initial data and you will go\nthrough most of the steps that you executed before.\n\nWhat you need to do is fully described in the notebook."
  },
  {
    "id": "1fa7c05e-639b-4f5c-9dc3-44f795e0322a",
    "source_file": "README_ML1.md",
    "section": "Machine learning introduction",
    "content": "Summary: This project is an introduction to machine learning and especially to primary data analysis with some practical basics.\n\nüí° Tap here to leave your feedback on the project. It's anonymous and will help our team make your educational experience better. We recommend completing the survey immediately after the project."
  },
  {
    "id": "d9e02943-1fc0-4526-b98b-cadb0f9d5205",
    "source_file": "README_ML1.md",
    "section": "Contents",
    "content": "1. Chapter I. Preamble\n2. Chapter II. Introduction \\\n    2.1. Steps to build a model \\\n    2.2. ML algorithms \\\n        2.2.1. Supervised learning \\\n        2.2.2. Unsupervised learning\n3. Chapter III. Goal \n4. Chapter IV. Instructions\n5. Chapter V. Task"
  },
  {
    "id": "2490418b-54fc-450e-899e-384e3be9ec85",
    "source_file": "README_ML1.md",
    "section": "Chapter I. Preamble",
    "content": "\"With the ever-increasing amount of data in electronic form, the need for automated methods of data analysis continues to grow. The goal of machine learning is to develop methods that can automatically detect patterns in data, and then use the discovered patterns to predict future data or other outcomes of interest\" ‚Äî we start our course with the definition of machine learning from one of the widely known books ‚Äî \"Machine Learning A Probabilistic Perspective\" by Kevin P. Murphy. \n\nThere are a lot of problems solved by ML methods:\n* The problem of predicting housing prices. We try to define a cost of an object with a set of features such as quality of repair, footage and area.\n* What disease does the patient have if we observe a certain set of symptoms?\n* Will the customer of the bank pay back the loan if his income is X and he has a good credit history?\n* What products are suitable to show to the user on the main page of the online store to speed up his/her successful search?\n\nIn most cases we can answer all these questions. But it is much better to have a machine that can do this work without bias and many times faster. Data requires automated methods of analysis, which is what machine learning provides. We define machine learning as a set of methods that can automatically discover patterns in data and then use the discovered patterns to predict future data.\n\nIn summary, this course will show you what machine learning is. After reading all the materials and doing the labs, you will master all the basic approaches to building models and learning how to predict the future."
  },
  {
    "id": "42ce5f23-d1a7-49f7-9dc2-6cb635950350",
    "source_file": "README_ML1.md",
    "section": "Steps to build a model",
    "content": "!day_1_scheme\n\nSuppose you are a very smart home seller. You know all about the real estate market (data and features) and understand how the price depends on various factors (algorithm). For example, you know that the more bedrooms an apartment has, the more expensive it is. But how do you get a machine to learn such dependencies? And how to understand who predicts better, the very smart real estate agent or the machine? \n\nFirst, you divide the houses into two groups: train and test data. The first is used to determine the relationship between features and price. The second predicts the price for new houses that are not in the first group. Thus, building a model is a sequence of methods you use to prepare and analyze data, find relations, and then predict new prices. \n\nThe first step of capturing patterns from train data is called fitting or training the model. The data used to fit the model is called the training data. All the characteristics that you base your decision on are called features. For example, the number of bedrooms or bathrooms are features. And the price is the target. Your simple algorithm in the above case might be: \"If a house has more than 2 bedrooms, then its price is $188000, otherwise its price is $178000\".\n\nThe details of how to fit the model are complex enough, and we will discuss them later. After fitting the model, you can apply it to new or test data to predict prices of new homes. This will allow you to understand how well the model performs on unseen data, i.e., evaluate the performance of our model. In most (though not all) applications, the relevant measure of model quality is predictive accuracy. In other words, are the model's predictions close to what actually happens? There will be more theory on metrics later.\n\nTherefore, we follow the next steps to build ML model:\n1. Collect training data;\n2. Get features and target;\n3. Train (fit) model;\n4. Get predictions on new features from unseen part of data (test data);\n5. Evaluate the quality of the model."
  },
  {
    "id": "b0b7242a-4bbd-4d83-b02f-7fc8d0505613",
    "source_file": "README_ML1.md",
    "section": "ML Algorithms",
    "content": "Now let's talk about classifying algorithms. \nBut first, let's look at Tom Mitchell's definition of machine learning:\n\nA computer program is said to learn from experience E with respect to some class of tasks T, and a performance measure P, if its performance on tasks in T, as measured by P, improves with experience E.\n\nThis definition is close to the experience E of children in school. From time to time, the set of children learns and then repeats a multiplication table (task T) and receive marks (performance measure P) for their knowledge. The more times children repeat a multiplication table, the better their knowledge becomes and the better grades they get.\n\nThus, there are many types of machine learning, depending on the type of the tasks T we want the system to learn, the type of performance measure P we use to evaluate the system, and the type of training signal or experience E we give it. There is a wide variety of ML methods. Let's give some examples.\n\n|  | Task T | Performance measure P | Experience E |\n| ----- | ------ | ------ | ----- |\n| 1 | Predict house price | How close to the price we are | Description of every house in a city with fixed characteristics and price |\n| 2 | Predict whether a client returns a loan | Is our prediction correct or not  Or the amount of money bank lost if provided a loan but the client has not return it | Salary of clients and their credit history |\n| 3 | Predict when a patient needs to take medicine | Whether the medicine helps to recover | Current patient medical records. Performance of randomized control trial with this medicine. Plus the medical records of other patients. |\n| 4 | Choose what medicine out of available a patient should take | Whether the medicine helps to recover | Current patient medical records. Performance of randomized control trials with these medicines. Plus the medical records of other patients |\n| 5 | Choose segment of clients for a promo communication | Open rate of communication  Or increase in profit | The information of what items was included in the promo. Clients purchase history. Characteristics of products |\n| 6 | Recognition of defective products on the production line (based on photo scans) | The amount of skipped defects | Photos of defective and non-defective products |\n| 7 | Decide how to place products on a shelf in a store | The amount of products selled  Or  increase in profit | History of how we placed products before. Orders with products‚Äô amounts. |\n| 8 | Search sites for input text query | The ratio of successful searches  The mean rank of successful answer | Search queries of other users. Text description of every site |\n| 9 | Split customers of a store into segments to understand differences of their behavior | How well you can interpret splits | Customers‚Äô characteristics and purchase history |\n| 10 | Detect anomaly in site traffic | The amount of prevented DDoS attacks | Stream of requests to your servers |\n\nAnd these examples could easily be extended with many more tasks. Furthermore, we can slightly change the incoming conditions of the task and it may require a completely different solution. \n\nFor example, imagine that in the 5th example we have to do the promotion for absolutely new products of a new brand, which have no purchase history. Usually when a scientific field has a large variety in the tasks it tries to solve, then some classification is used to make it easier to navigate the tasks within it. ML is no exception. The main classification is into supervised learning and unsupervised learning."
  },
  {
    "id": "628a2449-ed48-4bcf-8542-12527a7ecc33",
    "source_file": "README_ML1.md",
    "section": "Supervised Learning",
    "content": "Supervised learning is when you have some input variables (X) and an output variable (y) and you use an algorithm to learn the mapping function from the input to the output. The problem of predicting house prices is an example of supervised learning. \n\nIt is called supervised learning because the process of an algorithm learning from the training dataset can be thought of as a teacher supervising the learning process. We know the correct answers, the algorithm iteratively makes predictions on the training data, and is corrected by the teacher. Learning stops when the algorithm reaches an acceptable level of performance.\n\nSupervised learning problems can be further divided into regression and classification problems.\n\nClassification. In classification problems, the output space is a set of _C_ unordered and mutually exclusive labels known as classes, $$Y = {1,2,...,C}$$. The problem of predicting the class label given an input is also called pattern recognition. (If there are just two classes, often denoted by $$y\\in\\{0,1\\}$$ or $$y\\in\\{‚àí1, +1\\}$$, it is called _binary classification_.) A classification problem with multiple classes (greater than 2) is called _multiclass._ There are also a variety of multilabel problems.\n\nFor example, we use _binary classification_ to answer the question: does the patient have heart disease? _Multiclass classification_ is used in cases where each sample is assigned to one and only one label: a fruit can be either an apple or a pear or a banana, but not both at the same time.\n\nRegression. Suppose we want to predict a real-valued quantity $$y ‚àà R$$ instead of a class label $$y \\in\\{1,...,C\\}$$; this is known as regression. See the house price prediction example above.\n\nThink about which cases from the table above could also be formulated as a classification and regression task. Provide an answer in the project notebook."
  },
  {
    "id": "846c301b-b6ba-4994-84d2-58766002a4bc",
    "source_file": "README_ML1.md",
    "section": "Unsupervised Learning",
    "content": "In supervised learning, we assume that each input example _x_ in the training set has an associated set of output targets _y_, and our goal is to learn the input-output mapping.\n\nA much more interesting task is to try to \"make sense\" of the data, as opposed to just learning a mapping. That is, we just get observed inputs $$D = \\{x_i:i \\in \\{1, \\dots, N\\}$$ without any corresponding outputs $$y\\_i $$. This is called unsupervised learning. In other words, unsupervised learning is when you have only input data (X) and no corresponding output variables.\n\nUnsupervised learning problems can be further classified into clustering, association, and dimensionality reduction problems.\n\nClustering: A clustering problem is where you want to discover the inherent groupings in the data, such as grouping customers by purchasing behavior. \n\nAssociation: An association rule learning problem is where you want to discover rules that describe large portions of your data, such as people who buy A also tend to buy B.\n\nDimensionality reduction (or generalization): The goal of dimensionality reduction is to discover some common properties in our dataset while understanding which features are very different. If we have too many features, we can use this information to compress the features into smaller sets without losing the important information in them. This trick is very useful when we need to visualize our dataset that has many features in it.\n\nThink about which cases from the table above could be formulated as a clustering, association, and dimensionality reduction task. Provide an answer in the project solution. Please note that the boundary between unsupervised learning classes is not so clear in practice, and sometimes all these tasks are combined. So feel free to share your opinion on how you can use these methods.\n\nNow you know the basics of ML theory. The next step is the practice."
  },
  {
    "id": "bbba907a-3cf8-4366-9b21-4bea6acbaab9",
    "source_file": "README_ML1.md",
    "section": "Chapter III. Goal",
    "content": "The goal of this project is to give you a basic understanding of how to build the simplest models. We will use the most common methods of data analysis and processing, learn some methods of visualization. The result is a simple regression model to predict the popularity of an apartment rental listing based on listing content such as text description, photos, number of bedrooms, price, etc."
  },
  {
    "id": "88f5b142-9c33-4ab7-94a8-704b7d9c8f8c",
    "source_file": "README_ML1.md",
    "section": "Chapter IV. Instructions",
    "content": "* This project will be judged by humans only. You are free to organize and name your files as you wish. \n* We recommend that you push your local code to the develop branch.\n* Here and throughout, we use Python 3 as the only correct version of Python, and recommend that you use JupyterNotebook.\n* There are no strict rules for coding in this project. However, you are asked to be clear and structured in the conception of your code.\n* Please respect the code culture: store data in the data folder, move imports and functions to the top of the notebook, add plot labels, leave comments, and make your code clear."
  },
  {
    "id": "b15a40c1-ed3d-4621-b43c-39fa729441d3",
    "source_file": "README_ML1.md",
    "section": "Chapter V. Task",
    "content": "We will practice using a problem from Kaggle.com. You will predict the price of an apartment rental listing based on the listing content such as text description, photos, number of bedrooms, price, etc. The data comes from renthop.com, an apartment listing website. \n\nFollow the instructions, answer the questions and get your final score!\n\n1. Introduction. Write your answers in the Intro section of your notebook. \n   1. To get started, please write 5 examples of the application of ML methods in life. What is the benefit of using machine learning methods in each of your examples? \n   2. Use the classification of tasks in the introduction to decide which class you can assign to the tasks from the table above and to the 5 examples you provided. \n   3. Think about what the difference is between multiclass and multilabel.\n   4. Is an example case with house prices from the theory a classification of a regression problem? Is it possible to reduce the regression problem to classification?\n2. Introduction to Data Analysis\n   1. Import the libraries pandas, numpy, sklearn, lightgbm, scipy, statsmodels, matplotlib, seaborn. Use pip install if necessary.\n   2. Load data from kaggle using pandas. You only need the table data, which is in train.json.\n   3. What is the size (the number of rows and columns) of your data? \n   4. Print the list of columns. Which column is a target? \n   5. Make a quick analysis of the data: use the methods info(), describe(), corr(). Explain the results of the outputs. Are there any empty columns? \n   6. We'll work with only 3 features: 'bathrooms', 'bedrooms', 'interest_level' and with the target column 'price'. Create a dataframe with only these columns.\n3. Statistical Data Analysis\n   1. To get started with statistical data analysis, we recommend that you refresh your basic knowledge of statistics, such as Mean / Median / Mode / Variance / Standard Deviation. Also you are welcome to be free with distributions (Discrete uniform Distribution, Bernoulli Distribution, Binomial Distribution, Poisson Distribution, Normal Distribution, Exponential Distribution). Please make sure that you know the definitions of outliers, percentiles, confidential intervals. The article will be presented later. \n   2. Have a quick look at this article. Please pay attention to such aspects as distributions and histograms, boxplots, outliers, kernel density function.\n   3. Target analysis\n      1. Plot a histogram to understand the distribution of the target. Is it all clear? \n      2. The next step is boxplot(). What can you say about the target? Are there any outliers? \n      3. Drop the rows that are outside the 1 and 99 percentiles from the target column. \n      4. Plot another histogram for price. Explain the result.\n   4. Characteristics Analysis\n      1. What is the type of column 'interest_level'? \n      2. Print the values in this column. How many entries does each value contain? \n      3. Encode these values. For example, you can replace each value with 0, 1, or 2.\n      4. Plot histograms for the features 'bathrooms', 'bedrooms'. Are there any outliers?\n   5. Complex analysis\n      1. Plot a correlation matrix to understand the correlation between features and target. Plot a heat map for the correlation matrix. Is there a correlation? \n      2. Plot a scatterplot to visualize the correlation between the features and the target. You should return 3 plots where the X-axis is the target and the Y-axis is a feature.\n4. Creating Features\n   1. This step is very broad. You can create as many features as you want. For example, you can add 3 new features that are squared: 'bathrooms_squared', 'bedrooms_squared', ''interest_level_squared'. Plot a correlation matrix with the new features. Are the new features more correlated with the target than the basic features? \n   2. To train the model here, we will not use your new features. Remember this example and use it in Lecture 2. To train the model, we will only consider the features 'bathrooms' and 'bedrooms'.\n   3. Read this Sklearn info about PolynomialFeatures.\n   4. To use PolynomialFeatures, we first need to split the data into training and test samples. We have already done this for you, please read the training and test data. \n   5. Initialize PolynomialFeatures() with a degree of 10. \n   6. Apply PolynomialFeatures() to fit and transform your training and test data.\n5. Now you need to train 3 models: linear regression, decision tree and naive model. We will use them as black boxes without deep understanding. \n   1. Results table \n      1. Create two empty Pandas DataFrames with columns 'model', 'train', 'test'. Let's call the first one result_MAE and the second one result_RMSE. We will fill these tables with the results of the models.\n   2. Linear Regression \n      1. Initialize linear regression from sklearn with no parameters. \n      2. Fit your model and make predictions on training and test features. Save it as new columns in data.\n      3. Compute MAE (Mean Absolute Error) on training and test targets.\n      4. Calculate RMSE (Root Mean Square Error) on training and test objectives.\n      5. Insert your metrics into tables result_MAE and result_RMSE with model name 'linear_regression'.\n   3. Decision Tree\n      1. Initialize decision tree regressor from sklearn with fixed random_state=21.\n      2. Fit it to train features and train target and make prediction on train and test features. Save it as a new column in data. \n      3. Compute MAE (Mean Absolute Error) on train and test targets.\n      4. Compute RMSE (Root Mean Square Error) on train and test targets.\n      5. Insert your metrics into tables result_MAE and result_RMSE with model name 'decision_tree'.\n   4. Naive Models\n      1. Calculate the mean and median of 'price' on the training and test data and create a column with these values. \n      2. Calculate the MAE on the training and test targets between your target and the calculated mean and median. \n      3. Calculate the RMSE on the training and test targets between your target and the calculated mean and median. \n      4. Insert your metrics into tables result_MAE and result_RMSE with model names 'naive_mean' and 'naive_median'.\n   5. Compare the results \n      1. Print your final result_MAE and result_RMSE tables. \n      2. Which is the best model?\n   6. Additional\n      1. You can practice with all the data in your starting dataset. Use and generate all the features you want."
  },
  {
    "id": "3b6981c9-ec31-4e80-8270-7927f6b6df8b",
    "source_file": "README_ML1.md",
    "section": "Submission",
    "content": "Save your code in Python JupyterNotebook. Your peer will load it and compare it to the basic solution. Your code should include answers to all mandatory questions. The additional task is up to you. \n\n\n>Please leave feedback on the project in the feedback form."
  },
  {
    "id": "51c6532d-8835-4499-8cbe-3a6bd61c0488",
    "source_file": "README_s21_decimal.md",
    "section": "s21_decimal",
    "content": "> –ü—Ä–∏ —Å—Ç–∞—Ä—Ç–µ —Ä–∞–±–æ—Ç—ã –Ω–∞–¥ –ø—Ä–æ–µ–∫—Ç–æ–º –ø—Ä–æ—Å–∏–º –≤–∞—Å –ø–æ—Å—Ç–∞—Ä–∞—Ç—å—Å—è —Ö—Ä–æ–Ω–æ–º–µ—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –Ω–∞–¥ –ø—Ä–æ–µ–∫—Ç–æ–º.\n> –ü–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã –Ω–∞–¥ –ø—Ä–æ–µ–∫—Ç–æ–º –ø—Ä–æ—Å–∏–º –≤–∞—Å –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –¥–≤–∞ –≤–æ–ø—Ä–æ—Å–∞ –≤ —ç—Ç–æ–º –æ–ø—Ä–æ—Å–µ\n\nImplementation of your own s21_decimal.h library.\n\nThe russian version of the task can be found in the repository."
  },
  {
    "id": "ba68ae4a-f14e-42fd-acc7-00de4a29cd73",
    "source_file": "README_s21_decimal.md",
    "section": "Contents",
    "content": "1. Chapter I \\\n   1.1. Introduction\n2. Chapter II \\\n   2.1. Information\n3. Chapter III \\\n   3.1. Part 1"
  },
  {
    "id": "7c0202f3-076d-4e80-8121-864e8e0344be",
    "source_file": "README_s21_decimal.md",
    "section": "Chapter I",
    "content": "!s21_decimal\n\nPlanet Earth, 1990s. \n\nThe world economy is growing exponentially, the stock exchange increases many times year after year, more and more companies go public and their shares start to be quoted. The number of users, the number of transactions, price, commission, interest, calculation of financial technical indicators... It's hard to overestimate the accuracy of all this data, and there are serious problems with the current obsolete data types used in the financial sector.\n\nDue to a calculation error in the usual IEEE 754 (float) millions of dollars are lost every year, which simply absorbed from the system, disappearing forever. \n\nTogether with the FIX (Financial Information eXchange) protocol, which is being developed for data processing in the transfer between the broker and the exchange, one more tool is needed for data transfer and storage. \\\nAt the follow-up meeting:\n\n-- So, gentlemen, please note that our group of specialists, who have already proven themselves in many successful projects, has been tasked by the government to develop a completely new type of data, code-named Decimal. Its task is to allow significantly minimise error for several decades, and in some cases remove it completely in the world's financial transactions. It is required to describe all the necessary logical and arithmetic operations, which would allow to make the necessary calculations quickly and conveniently.\n\n- Wow, that's quite an order we got, and from such a customer! We have to keep this client - it promises us big contracts in the future if we do well!\n\n-- Yes, you're right, that‚Äôs why we need to figure out what functions we need to implement... Any suggestions?\n\n-- Sum and difference....\n\n-- Multiplication and division...\n\n-- Agreed, but we need more!\n\n- Taking the remainder, comparison and conversion operations!\n\n-- Mathematical rounding in all directions!\n\n-- Yes, I think that‚Äôs enough, let‚Äôs get to work! We've got no more than a couple of days, don't let us down!"
  },
  {
    "id": "6af72930-e15f-43ba-a1fc-14d9730c6bcf",
    "source_file": "README_s21_decimal.md",
    "section": "Introduction",
    "content": "In this project you will implement the s21_decimal.h library in the C programming language. This library should add the ability to work with the \"decimal\" type, which is not in the language standard. Nevertheless, this type is critically important. For financial calculations, for example, where errors of calculations characteristic of types with floating point are unacceptable. As part of the project you will work with the tasks of processing financial information, dive into the issues of internal representation of different types of data, and solidify knowledge of structured programming."
  },
  {
    "id": "ba963956-a825-4069-9de5-318f5a2ccc40",
    "source_file": "README_s21_decimal.md",
    "section": "Information",
    "content": "The Decimal value type represents decimal numbers ranging from positive 79,228,162,514,264,337,593,543,950,335 to negative 79,228,162,514,264,337,593,543,950,335. The default value of a Decimal is 0. The Decimal value type is appropriate for financial calculations that require large numbers of significant integral and fractional digits and no round-off errors. The Decimal type does not eliminate the need for rounding. Rather, it minimizes errors due to rounding.\n\nWhen the result of the division and multiplication is passed to the Round method, the result suffers no loss of precision.\n\nA decimal number is a floating-point value that consists of a sign, a numeric value where each digit in the value ranges from 0 to 9, and a scaling factor that indicates the position of a floating decimal point that separates the integral and fractional parts of the numeric value.\n\nThe binary representation of a Decimal value consists of a 1-bit sign, a 96-bit integer number, and a scaling factor used to divide the 96-bit integer and specify what portion of it is a decimal fraction. The scaling factor is implicitly the number 10, raised to an exponent ranging from 0 to 28. Therefore, the binary representation of a Decimal value the form, ((-2^96 to 2^96) / 10^(0 to 28)), where -(2^96-1) is equal to MinValue, and 2^96-1 is equal to MaxValue.\n\nThe scaling factor also can preserve any trailing zeros in a Decimal number. Trailing zeros do not affect the value of a Decimal number in arithmetic or comparison operations."
  },
  {
    "id": "1b4c04f0-674f-44ff-9986-62ad6bcc68f2",
    "source_file": "README_s21_decimal.md",
    "section": "Binary representation",
    "content": "The binary representation of a Decimal number consists of a 1-bit sign, a 96-bit integer number, and a scaling factor used to divide the integer number and specify what portion of it is a decimal fraction. The scaling factor is implicitly the number 10, raised to an exponent ranging from 0 to 28.\n\nDecimal number can be implemented as a four-element array of 32-bit signed integers (int bits[4];).\n\nbits[0], bits[1], and bits[2] contain the low, middle, and high 32 bits of the 96-bit integer number accordingly.\n\nbits[3] contains the scale factor and sign, and consists of following parts:\n- Bits 0 to 15, the lower word, are unused and must be zero.\n- Bits 16 to 23 must contain an exponent between 0 and 28, which indicates the power of 10 to divide the integer number.\n- Bits 24 to 30 are unused and must be zero.\n- Bit 31 contains the sign; 0 meaning positive, and 1 meaning negative.\n\nNote that the bit representation differentiates between negative and positive zero. These values can be treated as being equal in all operations."
  },
  {
    "id": "3ec0e376-d21e-458a-87c7-c804354b9d64",
    "source_file": "README_s21_decimal.md",
    "section": "Arithmetic Operators",
    "content": "| Operator name | Operators  | Function                                                                           | \n| ------ | ------ |------------------------------------------------------------------------------------|\n| Addition | + | int s21_add(s21_decimal value_1, s21_decimal value_2, s21_decimal *result)         |\n| Subtraction | - | int s21_sub(s21_decimal value_1, s21_decimal value_2, s21_decimal *result) |\n| Multiplication |  | int s21_mul(s21_decimal value_1, s21_decimal value_2, s21_decimal result) | \n| Division | / | int s21_div(s21_decimal value_1, s21_decimal value_2, s21_decimal *result) |\n| Modulo | Mod | int s21_mod(s21_decimal value_1, s21_decimal value_2, s21_decimal *result) |\n\nThe functions return the error code:\n- 0 - OK\n- 1 - the number is too large or equal to infinity\n- 2 - the number is too small or equal to negative infinity\n- 3 - division by 0\n\nNote on the numbers that do not fit into the mantissa:\n- When getting numbers that do not fit into the mantissa during arithmetic operations, use bank rounding (for example, 79,228,162,514,264,337,593,543,950,335 - 0.6 = 79,228,162,514,264,337,593,543,950,334)\n\nNote on the mod operation:\n- If an overflow occurred as a result, discard the fractional part (for example, 70,000,000,000,000,000,000,000,000,000 % 0.001 = 0.000)"
  },
  {
    "id": "fad660e7-0246-47ee-81a4-ae1f76eafbc2",
    "source_file": "README_s21_decimal.md",
    "section": "Comparison Operators",
    "content": "| Operator name | Operators  | Function | \n| ------ | ------ | ------ |\n| Less than |  |  int s21_is_greater(s21_decimal, s21_decimal) |\n| Greater than or equal to | >= | int s21_is_greater_or_equal(s21_decimal, s21_decimal) | \n| Equal to | == |  int s21_is_equal(s21_decimal, s21_decimal) |\n| Not equal to | != |  int s21_is_not_equal(s21_decimal, s21_decimal) |\n\nReturn value:\n- 0 - FALSE\n- 1 - TRUE"
  },
  {
    "id": "f0cabdaf-56ac-4fbe-8c16-ee5edb59ff20",
    "source_file": "README_s21_decimal.md",
    "section": "Convertors and parsers",
    "content": "| Convertor/parser | Function | \n| ------ | ------ |\n| From int  | int s21_from_int_to_decimal(int src, s21_decimal *dst) |\n| From float  | int s21_from_float_to_decimal(float src, s21_decimal *dst) |\n| To int  | int s21_from_decimal_to_int(s21_decimal src, int *dst) |\n| To float  | int s21_from_decimal_to_float(s21_decimal src, float *dst) |\n\nReturn value - code error:\n- 0 - OK\n- 1 - convertation error\n\nNote on the conversion of a float type number:\n- If the numbers are too small (0  79,228,162,514,264,337,593,543,950,335) or are equal to infinity, return an error\n- When processing a number with the float type, convert all the significant decimal digits contained in it. If there are more than 7 such digits, the number is rounded to the closest one that does not have more than 7 significant decimal digits.\n\nNote on the conversion from decimal type to int:\n- If there is a fractional part in a decimal number, it should be discarded (for example, 0.9 is converted to 0)"
  },
  {
    "id": "0a6965c5-f6fe-4d88-85b1-35592be6c9b0",
    "source_file": "README_s21_decimal.md",
    "section": "Another functions",
    "content": "| Description | Function                                                         | \n| ------ |------------------------------------------------------------------|\n| Rounds a specified Decimal number to the closest integer toward negative infinity. | int s21_floor(s21_decimal value, s21_decimal *result)            |\t\n| Rounds a decimal value to the nearest integer. | int s21_round(s21_decimal value, s21_decimal *result)    |\n| Returns the integral digits of the specified Decimal; any fractional digits are discarded, including trailing zeroes. | int s21_truncate(s21_decimal value, s21_decimal *result) |\n| Returns the result of multiplying the specified Decimal value by negative one. | int s21_negate(s21_decimal value, s21_decimal *result)   |\n\nReturn value - code error:\n- 0 - OK\n- 1 - calculation error"
  },
  {
    "id": "7c529d26-ee8c-46c7-9614-4e0bd7da51ee",
    "source_file": "README_s21_decimal.md",
    "section": "Part 1. Implementation of the decimal.h library functions",
    "content": "The functions of the decimal.h library described above must be implemented:\n- The library must be developed in C language of C11 standard using gcc compiler\n- The library code must be located in the src folder on the develop branch   \n- Do not use outdated and legacy language constructions and library functions. Pay attention to the legacy and obsolete marks in the official documentation on the language and the libraries used. Use the POSIX.1-2017 standard.\n- When writing code it is necessary to follow the Google style\n- Make it as a static library (with the s21_decimal.h header file)\n- The library must be developed according to the principles of structured programming;\n- Use prefix s21_ before each function\n- Prepare full coverage of library functions code with unit-tests using the Check library\n- Unit tests must cover at least 80% of each function (checked using gcov)   \n- Provide a Makefile for building the library and tests (with targets all, clean, test, s21_decimal.a, gcov_report)  \n- The gcov_report target should generate a gcov report in the form of an html page. Unit tests must be run with gcov flags to do this\n- When implementing decimal, stick to the binary representation with the integer bits array as specified in the example above. Observe the position of the digits of a number in the bits array\n- It is forbidden to use the __int128 type\n- Trailing zeros can be as preserved as deleted (except for the s21_truncate function)\n- The defined type must support numbers from -79,228,162,514,264,337,593,543,950,335 to +79,228,162,514,264,337,593,543,950,335."
  },
  {
    "id": "a9165345-454a-464e-8423-f9fe0fffc83a",
    "source_file": "README_s21_string_plus.md",
    "section": "s21_string+",
    "content": "Implementation of the string.h library with additions.\n\nThe russian version of the task can be found in the repository."
  },
  {
    "id": "f03fe94f-9598-459d-8f47-9af8d6a65069",
    "source_file": "README_s21_string_plus.md",
    "section": "Contents",
    "content": "0. Preamble\n1. Chapter I \\\n    1.1. Introduction\n2. Chapter II \\\n    2.1. Information\n3. Chapter III \\\n    3.1. Part 1  \n    3.2. Part 2  \n    3.3. Part 3  \n    3.4. Part 4  \n    3.5. Part 5"
  },
  {
    "id": "9c04a6a8-a1e8-4460-b059-6aaf9430111e",
    "source_file": "README_s21_string_plus.md",
    "section": "Preamble",
    "content": "!s21_string+\n\n1942, late evening, Bletchley Park, Alan Turing's desk. For almost a year, a group of smartest mathematicians, linguists, and crossword puzzle enthusiasts has been trying to solve the most difficult problem of deciphering the German Enigma encryption machine, the codes for which change every day, and the number of possible combinations is about two to the power of 64. The group often had to come up with different algorithms, and they even developed a special set of keywords and their syntax for the convenience of communication and logging and it‚Äôs exactly like the well-known C language in our universe. What a remarkable coincidence! But there was one difficulty ‚Äì the Bletchley Park workers had to keep the entire sequence of actions described in this language in their heads. \n\nAs you walk past Turing's desk, you notice a sheet that says \"For letters, punctuation marks, words, and sentences processing\".\n\n- \"What is this, Alan?\" you said to the thoughtful young man standing at the window.\n\n-- \"These are the functions that will make our lives easier! You know, deciphering Enigma by brute force‚Ä¶I'd rather marry Joan than we do that. Therefore, it seems that we need to keep analysing texts, looking for patterns and coincidences. And so, we‚Äôll have to come up with various algorithms related to the processing of that very text and describe them. That is why we need a number of functions to help us with that. I'm working on them now.\"\n\n- \"And you do that using our new unified algorithms representing tool?\"\n\n-- \"Yes, this is exactly how I do it. Where else could we use these functions?\" having said that, Turing looked at you as if you were a narrow minded person. You realised it and decided to show off your knowledge of the question:\n\n- \"You know I think we really need this. I just recently learned this \"specific language of algorithms transmission\".\"\n\n-- \"Seriously?\" Alan asked with some interest.\n\n- \"Well, yes.\"\n\nAfter a few seconds, Turing came to a logical conclusion to entrust the job to you:\n\n*-- \"Listen, do you want to do it yourself? Get some not-so-busy \npeople and go ahead. And I'll keep working on my mechanical code-breaking machine.\"*\n\nAfter thinking about it for a few seconds, you decide it's a great idea:\n\n- \"Yes, we‚Äôll do everything in a best possible way!\""
  },
  {
    "id": "794389f0-1716-43ee-abdc-0f2603a2ae17",
    "source_file": "README_s21_string_plus.md",
    "section": "Introduction",
    "content": "In this project you will develop your own implementation of the string.h library in C programming language with some additions (with your own implementation of sprintf and sscanf functions). The string.h library is the main C library for string processing. As part of the project you‚Äôll work on tasks with string data and consolidate the structured approach."
  },
  {
    "id": "b17e132a-e273-4035-9306-2171dc231266",
    "source_file": "README_s21_string_plus.md",
    "section": "Information",
    "content": "The C programming language has a set of functions implementing operations on strings (character strings and byte strings) in its standard library. Various operations, such as copying, concatenation, tokenization and searching are supported. For character strings, the standard library uses the convention that strings are null-terminated: a string of n characters is represented as an array of n + 1 elements, the last of which is a \"NULL\" character. \\\nThe only support for strings in the programming language proper is that the compiler translates quoted string constants into null-terminated strings."
  },
  {
    "id": "7e7dea4c-4e46-432a-9f63-a4106123faad",
    "source_file": "README_s21_string_plus.md",
    "section": "string.h Types",
    "content": "| No. | Variable | Description |\n| ------ | ------ | ------ |\n| 1 | size_t | This is the unsigned integral type and is the result of the sizeof keyword. |"
  },
  {
    "id": "f026398e-8cf8-413f-b747-5960b3515a35",
    "source_file": "README_s21_string_plus.md",
    "section": "string.h Macro",
    "content": "| No. | Macro | Description |\n| ------ | ------ | ------ |\n| 1 | NULL | This macro is the value of a null pointer constant. |"
  },
  {
    "id": "d543b627-da44-42ab-a291-212e54592e0a",
    "source_file": "README_s21_string_plus.md",
    "section": "string.h Functions",
    "content": "| No. | Function | Description |\n| ------ | ------ | ------ |\n| 1 | void memchr(const void str, int c, size_t n) | Searches for the first occurrence of the character c (an unsigned char) in the first n bytes of the string pointed to, by the argument str. |\n| 2 | int memcmp(const void str1, const void str2, size_t n) | Compares the first n bytes of str1 and str2. |\n| 3 | void memcpy(void dest, const void *src, size_t n) | Copies n characters from src to dest. |\n| 4 | void memset(void str, int c, size_t n) | Copies the character c (an unsigned char) to the first n characters of the string pointed to, by the argument str. |\n| 5 | char strncat(char dest, const char *src, size_t n) | Appends the string pointed to, by src to the end of the string pointed to, by dest up to n characters long. |\n| 6\t| char strchr(const char str, int c) | Searches for the first occurrence of the character c (an unsigned char) in the string pointed to, by the argument str. |\n| 7 | int strncmp(const char str1, const char str2, size_t n) | Compares at most the first n bytes of str1 and str2. |\n| 8 | char strncpy(char dest, const char *src, size_t n) | Copies up to n characters from the string pointed to, by src to dest. |\n| 9 | size_t strcspn(const char str1, const char str2) | Calculates the length of the initial segment of str1 which consists entirely of characters not in str2. |\n| 10 | char *strerror(int errnum) | Searches an internal array for the error number errnum and returns a pointer to an error message string. You need to declare macros containing arrays of error messages for mac and linux operating systems. Error descriptions are available in the original library. Checking the current OS is carried out using directives. |\n| 11 | size_t strlen(const char *str) | Computes the length of the string str up to but not including the terminating null character. |\n| 12 | char strpbrk(const char str1, const char *str2) | Finds the first character in the string str1 that matches any character specified in str2. |\n| 13 | char strrchr(const char str, int c) | Searches for the last occurrence of the character c (an unsigned char) in the string pointed to by the argument str. |\n| 14 | char strstr(const char haystack, const char *needle) | Finds the first occurrence of the entire string needle (not including the terminating null character) which appears in the string haystack. |\n| 15 | char strtok(char str, const char *delim) | Breaks string str into a series of tokens separated by delim. |"
  },
  {
    "id": "7e9d7c91-f3e4-4b65-9cc0-62404f53a49f",
    "source_file": "README_s21_string_plus.md",
    "section": "sprintf and sscanf",
    "content": "- int sscanf(const char str, const char format, ...) - reads formatted input from a string.\n- int sprintf(char str, const char format, ...) - sends formatted output to a string pointed to, by str.\n\nwhere:\n- str ‚àí This is the C string that the function processes as its source to retrieve the data;\n- format ‚àí This is the C string that contains one or more of the following items: Whitespace character, Non-whitespace character and Format specifiers. A format specifier for print functions follows this prototype: %[flags][width][.precision][length]specifier. A format specifier for scan functions follows this prototype: %[*][width][length]specifier."
  },
  {
    "id": "7084f8c5-7b5d-4cf6-a0c4-f12e1896c328",
    "source_file": "README_s21_string_plus.md",
    "section": "sprintf And sscanf Specifiers",
    "content": "| No. | Specifier | sprintf output | sscanf output |\n| --- | --- | --- | --- |\n| 1 | c | Character | Character |\n| 2 | d | Signed decimal integer | Signed decimal integer |\n| 3 | i | Signed decimal integer | Signed integer (may be decimal, octal or hexadecimal) |\n| 4 | e | Scientific notation (mantissa/exponent) using e character (the output of the numbers must match up to e-6) | Decimal floating point or scientific notation (mantissa/exponent) |\n| 5 | E | Scientific notation (mantissa/exponent) using E character | Decimal floating point or scientific notation (mantissa/exponent) |\n| 6 | f | Decimal floating point | Decimal floating point or scientific notation (mantissa/exponent) |\n| 7 | g | Uses the shortest representation of decimal floating point | Decimal floating point or scientific notation (mantissa/exponent) |\n| 8 | G | Uses the shortest representation of decimal floating point | Decimal floating point or scientific notation (mantissa/exponent) |\n| 9 | o | Unsigned octal | Unsigned octal |\n| 10 | s | String of characters | String of characters |\n| 11 | u | Unsigned decimal integer | Unsigned decimal integer |\n| 12 | x | Unsigned hexadecimal integer | Unsigned hexadecimal integer (any letters) |\n| 13 | X | Unsigned hexadecimal integer (capital letters) | Unsigned hexadecimal integer (any letters) |\n| 14 | p | Pointer address | Pointer address |\n| 15 | n | Number of characters printed until %n occurs | Number of characters scanned until %n occurs |\n| 16 | % | Character % | Character % |"
  },
  {
    "id": "4cc30dcd-e8bc-4fba-b25f-70c2d3584038",
    "source_file": "README_s21_string_plus.md",
    "section": "sprintf Flags",
    "content": "| No. | Flags | Description |\n| --- | --- | --- |\n| 1 | - | Left-justify within the given field width; Right justification is the default (see width sub-specifier). |\n| 2 | + | Forces to precede the result with a plus or minus sign (+ or -) even for positive numbers. By default, only negative numbers are preceded with a -ve sign. |\n| 3 | (space) | If no sign is going to be written, a blank space is inserted before the value. |\n| 4 | # | Used with o, x or X specifiers the value is preceded with 0, 0x or 0X respectively for values different than zero. Used with e, E and f, it forces the written output to contain a decimal point even if no digits would follow. By default, if no digits follow, no decimal point is written. Used with g or G the result is the same as with e or E but trailing zeros are not removed. |\n| 5 | 0 | Left-pads the number with zeroes (0) instead of spaces, where padding is specified (see width sub-specifier). |"
  },
  {
    "id": "ffc40369-8ac4-4831-b307-e35765b8c797",
    "source_file": "README_s21_string_plus.md",
    "section": "sprintf And sscanf Width Description",
    "content": "| No. |\tWidth | Description |\n| --- | --- | --- |\n| 1\t| (number) | Minimum number of characters to be printed. If the value to be printed is shorter than this number, the result is padded with blank spaces. The value is not truncated even if the result is larger. |\n| 2 |  | In sprintf the  sign means, that the width is not specified in the format string, but as an additional integer value argument preceding the argument that has to be formatted. In sscanf the * sign placed after % and before the format specifier reads data of the specified type, but suppresses their assignment. |"
  },
  {
    "id": "156a1af2-d6a8-4878-a536-001b864f92c9",
    "source_file": "README_s21_string_plus.md",
    "section": "sprintf Precision Description",
    "content": "| No. |\t.precision | Description |\n| --- | --- | --- |\n| 1\t| .number | For integer specifiers (d, i, o, u, x, X) ‚àí precision specifies the minimum number of digits to be written. If the value to be written is shorter than this number, the result is padded with leading zeros. The value is not truncated even if the result is longer. A precision of 0 means that no character is written for the value 0. For e, E and f specifiers ‚àí this is the number of digits to be printed after the decimal point. For g and G specifiers ‚àí This is the maximum number of significant digits to be printed. For s ‚àí this is the maximum number of characters to be printed. By default all characters are printed until the ending null character is encountered. For c type ‚àí it has no effect. When no precision is specified for specifiers e, E, f, g and G, the default one is 6. When no precision is specified for all other kind of specifiers, the default is 1. If the period is specified without an explicit value for precision, 0 is assumed. |\n| 2\t| .* | The precision is not specified in the format string, but as an additional integer value argument preceding the argument that has to be formatted. |"
  },
  {
    "id": "864035f2-0559-4c70-ac6a-a36ad56f7577",
    "source_file": "README_s21_string_plus.md",
    "section": "sprintf And sscanf Length Description",
    "content": "| No. |\tLength | Description |\n| --- | --- | --- |\n| 1 | h | The argument is interpreted as a short int or unsigned short int (only applies to integer specifiers: i, d, o, u, x and X). |\n| 2 | l | The argument is interpreted as a long int or unsigned long int for integer specifiers (i, d, o, u, x and X), and as a wide character or wide character string for specifiers c and s. |\n| 3 | L | The argument is interpreted as a long double (only applies to floating point specifiers ‚àí e, E, f, g and G). |"
  },
  {
    "id": "c5751fad-a254-446d-842d-c3a2b7d33ee6",
    "source_file": "README_s21_string_plus.md",
    "section": "Special string processing functions (from the String class in C#)",
    "content": "| No. | Function | Description |\n| ------ | ------ | ------ |\n| 1 | void to_upper(const char str) | Returns a copy of string (str) converted to uppercase. In case of any error, return NULL |\n| 2 | void to_lower(const char str) | Returns a copy of string (str) converted to lowercase. In case of any error, return NULL |\n| 3 | void insert(const char src, const char *str, size_t start_index) | Returns a new string in which a specified string (str) is inserted at a specified index position (start_index) in the given string (src). In case of any error, return NULL |\n| 4 | void trim(const char src, const char *trim_chars) | Returns a new string in which all leading and trailing occurrences of a set of specified characters (trim_chars) from the given string (src) are removed. In case of any error, return NULL |"
  },
  {
    "id": "292b75cf-3cc8-4774-a7d5-63f2016b8495",
    "source_file": "README_s21_string_plus.md",
    "section": "Part 1. Implementation of the string.h library functions",
    "content": "It is necessary to implement the described above functions of the string.h library: \n - The library must be developed in C language of C11 standard using gcc compiler\n - The library's code, including headers, makefile and library itself must be located in the src folder on the develop branch    \n - Do not use outdated and legacy language constructions and library functions. Pay attention to the legacy and obsolete marks in the official documentation on the language and the libraries used. Use the POSIX.1-2017 standard. \n - When writing code it is necessary to follow the Google style\n - Make it as a static library (with the header file s21_string.h)\n - The library must be developed in accordance with the principles of structured programming, duplication in the code must be avoided\n - Prepare a full coverage of the library's functions by unit-tests using the Check library\n - Test's code and the executable file must be located in the src folder or its any subfolder\n - Unit-tests must check the results of your implementation by comparing them with the implementation of the standard string.h library\n - Unit tests must cover at least 80% of each function (checked using gcov)\n - Provide a Makefile for building the library and tests (with the targets all, clean, test, s21_string.a, gcov_report)\n - The gcov_report target should generate a gcov report in the form of an html page. Unit tests must be run with gcov flags to do this\n - Use prefix s21_ before each function\n - It is forbidden to copy the implementation of the standard string.h library and other string processing libraries and to use them anywhere, except unit-tests\n - It is forbidden to use system errors arrays, including those not specified in POSIX (sys_nerr, sys_errlist). Instead, you need to implement your own platform-specific errors arrays, as it was mentioned in the description of the strerror function  \n - You must follow the logic of the standard string.h library (in terms of checks, working with memory and behavior in emergency situations - tests will help you with that)\n - Functions must work with z-string made of single-byte characters in ASCII encoding."
  },
  {
    "id": "813b6333-0688-4e6f-ba76-ce9f7384c655",
    "source_file": "README_s21_string_plus.md",
    "section": "Part 2. Partial implementation of the sprintf function",
    "content": "It is necessary to implement the sprintf function from the stdio.h library:\n- The function must be placed in the s21_string.h library\n- All of the requirements outlined in the first part are applied to function implementation.\n- The next partial formatting must be supported:\n  - Specifiers: c, d, f, s, u, %\n  - Flags: -, +, (space)\n  - Width description: (number)\n  - Precision description: .(number)\n  - Length description: h, l"
  },
  {
    "id": "624ef0d2-f0df-4d04-9f0f-0ea28a72ce09",
    "source_file": "README_s21_string_plus.md",
    "section": "Part 3. Bonus. Implementation of some format modifiers of the sprintf function",
    "content": "Bonus assignment for extra points. It is necessary to implement some format modifiers of the sprintf function from the stdio.h library:\n- The function must be placed in the s21_string.h library\n- All of the requirements outlined in the first part are applied to function implementation.\n- The next additional format modifiers must be supported:\n  - Specifiers: g, G, e, E, x, X, o, p\n  - Flags: #, 0\n  - Width description: *\n  - Precision description: .*\n  - Length description: L"
  },
  {
    "id": "00a5e26f-6be5-442c-adc5-766745ed92cb",
    "source_file": "README_s21_string_plus.md",
    "section": "Part 4. Bonus. Implementation of the sscanf function",
    "content": "Bonus assignment for extra points. It is necessary to implement the sscanf function from the stdio.h library:\n- The function must be placed in the s21_string.h library\n- All of the requirements outlined in the first part are applied to function implementation.\n- Full formatting (including flags, widths, precision, modifiers and conversion types) must be supported."
  },
  {
    "id": "cee66a11-df5c-4bb5-85f3-e055bd53c697",
    "source_file": "README_s21_string_plus.md",
    "section": "Part 5. Bonus. Implementation of special string processing functions",
    "content": "Bonus assignment for extra points. You must implement some string processing functions from the String class (described here):\n- The functions must be placed in the s21_string.h library.\n- All of the requirements outlined in the first part are applied to functions implementation, \n  excluding the requirement to compare your implementation with the standard.\n\n\nüí° Tap here to leave your feedback on the project. Pedago Team really tries to make your educational experience better."
  },
  {
    "id": "e10347f0-ea14-4c01-883b-3af00e67ec1f",
    "source_file": "README_simple_bash.md",
    "section": "Simple Bash Utils",
    "content": "Development of Bash text utilities: cat, grep.\n\nThe russian version of the task can be found in the repository."
  },
  {
    "id": "986d48e0-9e1f-417a-80d4-fa62f6a427e6",
    "source_file": "README_simple_bash.md",
    "section": "Contents",
    "content": "0. Preamble\n1. Chapter I \\\n   1.1. Introduction\n2. Chapter II \\\n   2.1. Information\n3. Chapter III \\\n   3.1. Part 1  \n   3.2. Part 2  \n   3.3. Part 3  \n   3.4. Part 4"
  },
  {
    "id": "53e89dbc-c3b3-48e2-aefa-c10d726ef66f",
    "source_file": "README_simple_bash.md",
    "section": "Preamble",
    "content": "!simple_bash_utils\n\nIt was an ordinary grey autumn day in 1993. You came home from work at Hewlett-Packard, feeling a little tired. You had a small two-room apartment on the outskirts of N town. There was a low-alcohol drink in the refrigerator called \"pivo\". You took that drink and a bag of crackers then went to your little nook, to your computer made by Dell.\n\nClick - the power button was pressed. A couple of minutes of boot loading and... yeah, it feels good. You always get that feeling when you turn on a computer. A few seconds of undisturbed pleasure and you opened\nthe Mosaic browser. Then you went to your favorite forum, and while drinking pivo, you read some threads. Suddenly you came across a very interesting discussion, which began with the following message:\n\n> Hello everybody out there using minix -\n>\n>I'm doing a (free) operating system (just a hobby, won't be big and professional like gnu) for 386(486) AT clones. This has been brewing since april, and is starting to get ready. I'd like any feedback on things people like/dislike in minix, as my OS resembles it somewhat (same physical layout of the file-system (due to practical reasons) among other things).\n>\n>I've currently ported bash(1.08) and gcc(1.40), and things seem to work. This implies that I'll get something practical within a few months, and I'd like to know what features most people would want. Any suggestions are welcome, but I won't promise I'll implement them :-)\n>\n>Linus (torvalds@kruuna.helsinki.fi)\n>\n>PS. Yes - it's free of any minix code, and it has a multi-threaded fs. It is NOT portable (uses 386 task switching etc), and it probably never will support anything other than AT-harddisks, as that's all I have :-(.\n>\n>‚Äî Linus Torvalds\n\n\"Very interesting,\" you thought to yourself. As you scrolled down, you noticed that bash is not that well ported, and some functions didn't work. \nIn particular, there were problems with the utilities for word processing: cat and grep.\n\"Interesting task, and it would be great to help this Linus Torvalds,\" you said aloud and immediately wrote a message in the thread saying that you're already working on it. \nWell, let‚Äôs start!"
  },
  {
    "id": "e81d1d64-c5d3-4b30-b183-362516b683ea",
    "source_file": "README_simple_bash.md",
    "section": "Introduction",
    "content": "In this project you will learn and develop basic Bash utilities for working with C programming language texts. These utilities (cat and grep) are often used in the Linux terminal. As part of the project you‚Äôll learn the organization of the Bash utilities and solidify knowledge of structured programming."
  },
  {
    "id": "4a03c2a2-0859-482f-a48d-c80cb3d07546",
    "source_file": "README_simple_bash.md",
    "section": "cat History",
    "content": "> cat was part of the early versions of Unix, e.g., Version 1, and replaced pr, a PDP-7 and Multics utility for copying a single file to the screen."
  },
  {
    "id": "923ddaa5-a60e-44a8-bf86-8bf716c54ff1",
    "source_file": "README_simple_bash.md",
    "section": "cat Usage",
    "content": "Cat is one of the most frequently used commands on Unix-like operating systems. It has three related functions with regard to text files: displaying them, combining copies of them and creating new ones.\n\ncat [OPTION] [FILE]..."
  },
  {
    "id": "cf4b7c5a-c7e8-49d0-bfb9-eba61206a5e2",
    "source_file": "README_simple_bash.md",
    "section": "cat Options",
    "content": "| No. | Options | Description |\n| ------ | ------ | ------ |\n| 1 | -b (GNU: --number-nonblank) | numbers only non-empty lines |\n| 2 | -e implies -v (GNU only: -E the same, but without implying -v) | but also display end-of-line characters as $  |\n| 3 | -n (GNU: --number) | number all output lines |\n| 4 | -s (GNU: --squeeze-blank) | squeeze multiple adjacent blank lines |\n| 5 | -t implies -v (GNU: -T the same, but without implying -v) | but also display tabs as ^I  |"
  },
  {
    "id": "3d367f12-0367-4ff7-8503-3417ed3c0e42",
    "source_file": "README_simple_bash.md",
    "section": "grep History",
    "content": "> Thompson wrote the first version in PDP-11 assembly language to help Lee E. McMahon analyze the text of the Federalist Papers to determine authorship of the individual papers. The ed text editor (also authored by Thompson) had regular expression support but could not be used on such a large amount of text, so Thompson excerpted that code into a standalone tool. He chose the name because in ed, the command g/re/p would print all lines matching a specified pattern. grep was first included in Version 4 Unix. Stating that it is \"generally cited as the prototypical software tool\", McIlroy credited grep with \"irrevocably ingraining\" Thompson's tools philosophy in Unix."
  },
  {
    "id": "24bdc01c-c781-435d-9f81-8431d940ca8f",
    "source_file": "README_simple_bash.md",
    "section": "grep Options",
    "content": "| No. | Options | Description |\n| ------ | ------ | ------ |\n| 1 | -e | pattern |\n| 2 | -i | Ignore uppercase vs. lowercase.  |\n| 3 | -v | Invert match. |\n| 4 | -c | Output count of matching lines only. |\n| 5 | -l | Output matching files only.  |\n| 6 | -n | Precede each matching line with a line number. |\n| 7 | -h | Output matching lines without preceding them by file names. |\n| 8 | -s | Suppress error messages about nonexistent or unreadable files. |\n| 9 | -f file | Take regexes from a file. |\n| 10 | -o | Output the matched parts of a matching line. |"
  },
  {
    "id": "64ccd79f-e711-407d-a9dc-56195507e08e",
    "source_file": "README_simple_bash.md",
    "section": "Chapter III",
    "content": "- The programs must be developed in C language of C11 standard using gcc compiler.\n- The program code of the cat and grep must be located on the develop branch in the src/cat/ and src/grep/ folders, respectively  \n- Do not use outdated and legacy language constructions and library functions. Pay attention to the legacy and obsolete marks in the official documentation on the language and the libraries used. Use the POSIX.1-2017 standard.\n- When writing code it is necessary to follow the Google style\n- The programs must be executable files with command line arguments\n- The programs must be built with Makefile with appropriate targets: s21_cat, s21_grep\n- If third-party libraries are used, there must be build scripts in makefile to connect/load them\n- Integration tests must cover all flag variants and input values, based on a comparison with the behavior of real Bash utilities \n- The programs must be developed according to the principles of structured programming\n- Code duplication must be avoided, common modules must be reused between the utilities. Common modules can be moved to a separate folder src/common\n- You can use standard and non-standard C libraries, or you can use your own developed libraries from other projects\n- The statement of the message in the case of an error does not matter\n- Input via stdin is not required to be supported"
  },
  {
    "id": "293660b4-e404-4174-9595-57ee03c3ef8f",
    "source_file": "README_simple_bash.md",
    "section": "Part 1. Working with the cat utility",
    "content": "You need to develop a cat utility:\n- Support of all flags (including GNU versions) specified above\n- The source, header, and build files must be placed in the src/cat/ directory\n- The resulting executable file must be placed in the directory src/cat/ and named s21_cat"
  },
  {
    "id": "16350434-cac1-42ba-b39d-f09edab61467",
    "source_file": "README_simple_bash.md",
    "section": "Part 2. Working with grep utility",
    "content": "You need to develop the grep utility:\n- Support of the following flags: -e, -i, -v, -c, -l, -n\n- Only pcre or regex libraries can be used for regular expressions\n- The source, header and make files must be placed in the src/grep/ directory\n- The resulting executable file must be placed in the directory src/grep/ and named s21_grep"
  },
  {
    "id": "7558ee36-2c6c-4bbe-8b5e-4609ce4ea2cb",
    "source_file": "README_simple_bash.md",
    "section": "Part 3. Bonus. Implementation of some grep utility flags",
    "content": "Bonus assignment for extra points. You need to develop the grep utility:\n- Support of all flags, including: -h, -s, -f, -o\n- Only pcre or regex libraries can be used for regular expressions\n- The source, header and make files must be placed in the src/grep/ directory\n- The resulting executable file must be placed in the directory src/grep/ and named s21_grep"
  },
  {
    "id": "638b68f9-e536-4908-995e-8a648938e0aa",
    "source_file": "README_simple_bash.md",
    "section": "Part 4. Bonus. Implementation of grep utility flag combinations",
    "content": "Bonus assignment for extra points. You need to develop the grep utility:\n- Support of all flags, including their _pair_ combinations (e.g. -iv, -in)\n- Only pcre or regex libraries can be used for regular expressions\n- The source, header and make files must be placed in the src/grep/ directory\n- The resulting executable file must be placed in the directory src/grep/ and named s21_grep\n\n\n\nüí° Tap here to leave your feedback on the project. Pedago Team really tries to make your educational experience better."
  },
  {
    "id": "1f9b95fb-b4cf-4c48-bd75-ab834e5b82e8",
    "source_file": "about.txt",
    "section": "text file",
    "content": "–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è —à–∫–æ–ª–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –æ—Ç –°–±–µ—Ä–∞\n–°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π —Å–ø–æ—Å–æ–± –ø–æ–ø–∞—Å—Ç—å –≤ –ò–¢ ‚Äî –æ–∫–∞–∑–∞—Ç—å—Å—è –≤ –∫—Ä—É–≥—É –µ–¥–∏–Ω–æ–º—ã—à–ª–µ–Ω–Ω–∏–∫–æ–≤. –û—Å–≤–æ–π –Ω–æ–≤—É—é –ø—Ä–æ—Ñ–µ—Å—Å–∏—é, –ø–æ–∑–Ω–∞–∫–æ–º—å—Å—è —Å –±—É–¥—É—â–∏–º–∏ –∫–æ–ª–ª–µ–≥–∞–º–∏ –∏ –ø–æ–ª—É—á–∏ –æ–ø—ã—Ç —Ä–µ–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ —É–∂–µ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è.\n–ü–æ—Å—Ç—É–ø–∏—Ç—å\n–ë–ª–∏–∂–∞–π—à–∏–π –Ω–∞–±–æ—Ä\n–°–ø–∏—Å–æ–∫ –≥–æ—Ä–æ–¥–æ–≤\n–û–±—É—á–µ–Ω–∏–µ –æ—Ç 6 –º–µ—Å. –¥–æ 2 –ª–µ—Ç\n–°—Ä–æ–∫ –æ–±—É—á–µ–Ω–∏—è –±—É–¥–µ—Ç –∑–∞–≤–∏—Å–µ—Ç—å –æ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞ –∑–∞–π–º—ë—Ç –æ—Ç 1,5 –¥–æ 2 –ª–µ—Ç, –ø–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—è–º DevOps, SRE-–∏–Ω–∂–µ–Ω–µ—Ä, Data Scientist, —Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫ (QA-–∏–Ω–∂–µ–Ω–µ—Ä), –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫ (BA) –∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ (SA) –æ—Ç 6 –¥–æ 12 –º–µ—Å—è—Ü–µ–≤.\n–°—Ç–∞–∂–∏—Ä–æ–≤–∫–∞ –≤ –ò–¢-–∫–æ–º–ø–∞–Ω–∏–∏\n–ü–æ—Ä–∞–±–æ—Ç–∞–π –Ω–∞–¥ —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏ –∏ –ø–æ–ª—É—á–∏ —Ñ–∏–¥–±–µ–∫ –æ—Ç –ª–∏–¥–µ—Ä–æ–≤ –≤ –ò–¢. –ù–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ ¬´–®–∫–æ–ª—ã 21¬ª —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –∫–∞—Ä—å–µ—Ä–Ω—ã–π —Ç—Ä–µ–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å—Å—è –∫ —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–µ.\n–ü–æ–¥—Ö–æ–¥ ¬´—Ä–∞–≤–Ω—ã–π —Ä–∞–≤–Ω–æ–º—É¬ª\n–í—ã–ø–æ–ª–Ω—è–π –∑–∞–¥–∞–Ω–∏—è, –ø—Ä–æ–≤–µ—Ä—è–π –ø—Ä–æ–µ–∫—Ç—ã –¥—Ä—É–≥–∏—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏ –æ–±–º–µ–Ω–∏–≤–∞–π—Å—è –∑–Ω–∞–Ω–∏—è–º–∏. –û–±—É—á–∞–π—Å—è –±–µ–∑ –ª–µ–∫—Ü–∏–π –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π.\n–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–∞–º–ø—É—Å\n–ö–∞–º–ø—É—Å—ã ¬´–®–∫–æ–ª—ã 21¬ª –æ—Ç–∫—Ä—ã—Ç—ã 24/7 –∏ 365 –¥–Ω–µ–π –≤ –≥–æ–¥—É. –í –Ω–∏—Ö –µ—Å—Ç—å –≤—Å—ë –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è: —Ä–∞–±–æ—á–∏–µ –º–µ—Å—Ç–∞, –∫–æ–º–ø—å—é—Ç–µ—Ä—ã –∏ –∏–≥—Ä–æ–≤—ã–µ –∫–æ–º–Ω–∞—Ç—ã, —á—Ç–æ–±—ã –æ—Ç–¥–æ—Ö–Ω—É—Ç—å.\n–ü–æ–º–æ–≥–∞–µ–º —Ä–∞—Å–∫—Ä—ã—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –∏ –≥–æ—Ç–æ–≤–∏–º –∫ —É—Å–ø–µ—à–Ω–æ–π –∫–∞—Ä—å–µ—Ä–µ –≤ –ò–¢\n–í ¬´–®–∫–æ–ª–µ 21¬ª —É—á–∞—Å—Ç–Ω–∏–∫–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ —Ä–∞–∑–≤–∏–≤–∞—é—Ç –∂—ë—Å—Ç–∫–∏–µ –∏ –º—è–≥–∫–∏–µ –Ω–∞–≤—ã–∫–∏: –≤ –≥—Ä—É–ø–ø–∞—Ö –∏ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –≤—ã–ø–æ–ª–Ω—è—é—Ç –ø—Ä–æ–µ–∫—Ç—ã –∏–∑ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∫—Ä—É–ø–Ω—ã—Ö –ò–¢-–∫–æ–º–ø–∞–Ω–∏–π, –ø—Ä–æ–≤–æ–¥—è—Ç –≤–∑–∞–∏–º–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –∫–æ–¥-—Ä–µ–≤—å—é, —É—á–∞—Ç—Å—è –¥–∞–≤–∞—Ç—å –∏ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å.\n–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ —Ç—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ\n8 400\n–ê–∫—Ç–∏–≤–Ω—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –æ–±—É—á–µ–Ω–∏—è\n100%\n–£—Å–ø–µ—à–Ω–æ —Ç—Ä—É–¥–æ—É—Å—Ç—Ä–æ–µ–Ω–æ\n–ü—Ä–æ–≥—Ä–∞–º–º–∞ –æ–±—É—á–µ–Ω–∏—è\n–í—Å–µ —É—á–∞—Å—Ç–Ω–∏–∫–∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∞—é—Ç –±–∞–∑—É –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Ä–∞–º–∫–∞—Ö –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è\n\n \n\n–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –ü–û\nDevOps- –∏ SRE-–∏–Ω–∂–µ–Ω–µ—Ä—ã\nQA-–∏–Ω–∂–µ–Ω–µ—Ä\nData Scientist\n–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏\n–ë–∏–∑–Ω–µ—Å- –∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫\n\n\n–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n–ù–∞—É—á–∏–º—Å—è —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏, —Ä–∞–±–æ—Ç–∞—Ç—å —Å –æ—á–∏—Å—Ç–∫–æ–π –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–∏–º–µ–Ω—è—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –∏ —Å–æ–∑–¥–∞–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª–∏ –º–æ–¥–µ–ª–µ–π\nNLP\n–û–≤–ª–∞–¥–µ–µ–º –∫–ª—é—á–µ–≤—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π, —Å—Ç–µ–º–º–∏–Ω–≥–æ–º, –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π, —Ä–∞–±–æ—Ç–æ–π —Å–æ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞–º–∏, –º–æ–¥–µ–ª—è–º–∏ bag of words, word2vec –∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º TF-IDF\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã\n–†–∞–∑—Ä–∞–±–æ—Ç–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º: –Ω–µ–ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–µ –∏ —Å –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π. –ò–∑—É—á–∏–º –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –∏—Ö –∫–∞—á–µ—Å—Ç–≤–∞\n–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏\n–ü–æ–π–º—ë–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π (FCN), —Ä–∞–∑–±–µ—Ä—ë–º –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã —Å–∫—Ä—ã—Ç—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤, –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–∫–∏ (back-propagation) –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π\n–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã\n–ù–∞—É—á–∏–º—Å—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ —Å–ø—Ä–æ—Å –Ω–∞ —Ç–∞–∫—Å–∏ –≤ —Ä–∞–∑–Ω—ã—Ö –ª–æ–∫–∞—Ü–∏—è—Ö –≥–æ—Ä–æ–¥–∞. –ò–∑—É—á–∏–º –º–µ—Ç–æ–¥—ã —Ä–∞–±–æ—Ç—ã —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏: —Å—Ä–µ–¥–Ω–∏–µ, —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ, —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ, SARIMA –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n–ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ\n–ò–∑—É—á–∏–º —Ä–∞–∑–º–µ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö, –¥–µ—Ç–µ–∫—Ü–∏—é –æ–±—ä–µ–∫—Ç–æ–≤, –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, —Ä–∞–±–æ—Ç—É —Å –º–∞—Å–∫–∞–º–∏, –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö, –∞ —Ç–∞–∫–∂–µ –æ—Å–≤–æ–∏–º CNN –∏ Transfer Learning\n–ò –ø—Ä–æ—Ö–æ–¥—è—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –∫ —Ä–∞–±–æ—Ç–µ –≤ –ò–¢‚Äë–∫–æ–º–ø–∞–Ω–∏–∏\n\n–ö–∞—Ä—å–µ—Ä–Ω—ã–π —Ç—Ä–µ–∫\n–ö–∞—Ä—å–µ—Ä–Ω—ã–π —Ç—Ä–µ–∫ ‚Äî —ç—Ç–æ –Ω–∞–±–æ—Ä –ø—Ä–æ–µ–∫—Ç–æ–≤ –∫–æ—Ç–æ—Ä—ã–µ –≥–æ—Ç–æ–≤—è—Ç –∫ —É—Å–ø–µ—à–Ω–æ–º—É —Ç—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤—É. –í –ø—Ä–æ—Ü–µ—Å—Å–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–µ –∏ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç–µ —É—á–∞—Å—Ç–Ω–∏–∫–∏ —Ç—Ä–µ–Ω–∏—Ä—É—é—Ç—Å—è —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å —Ä–µ–∑—é–º–µ –∏ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è\n–°—Ç–∞–∂–∏—Ä–æ–≤–∫–∞\n–°—Ç–∞–∂–∏—Ä–æ–≤–∫–∞ ‚Äî –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —É—á–µ–±–Ω—ã–π –ø—Ä–æ–µ–∫—Ç. –£—á–∞—Å—Ç–Ω–∏–∫–∏ —Å–∞–º–∏ –∏—â—É—Ç –ò–¢-–∫–æ–º–ø–∞–Ω–∏—é –¥–ª—è –ø—Ä–∞–∫—Ç–∏–∫–∏ –Ω–∞ 3 –º–µ—Å—è—Ü–∞, –Ω–æ –µ—Å–ª–∏ –±—É–¥—É—Ç —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏, —à–∫–æ–ª–∞ –ø–æ–º–æ–∂–µ—Ç. –ò–º–µ–Ω–Ω–æ –≤ —ç—Ç–æ –≤—Ä–µ–º—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø–æ–ª—É—á–∞–µ—Ç –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ —Ä–∞–±–æ—Ç–µ\n–ü–æ—Å–ª–µ —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–∏ –∫–∞–∂–¥—ã–π —É—á–∞—Å—Ç–Ω–∏–∫ –º–æ–∂–µ—Ç –∏–∑—É—á–∏—Ç—å –≥–ª—É–±–∂–µ —Å–ª—É–¥—É—é—â–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è\n–ë–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ\n–ì–µ–æ–¥–∞–Ω–Ω—ã–µ\n–ê–Ω–∞–ª–∏–∑ –≥—Ä–∞—Ñ–æ–≤\n–í ¬´–®–∫–æ–ª—É 21¬ª –º–æ–∂–µ—Ç\n–ø–æ—Å—Ç—É–ø–∏—Ç—å –ª—é–±–æ–π –∂–µ–ª–∞—é—â–∏–π\n–ù–µ–≤–∞–∂–Ω–æ, —á—Ç–æ —Ç—ã –∑–Ω–∞–µ—à—å –æ–± –ò–¢ –∏ –∫–∞–∫–æ–µ —É —Ç–µ–±—è –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ. –ì–ª–∞–≤–Ω–æ–µ ‚Äî —Ç–≤–æ—ë –∂–µ–ª–∞–Ω–∏–µ –∏ –º–æ—Ç–∏–≤–∞—Ü–∏—è. –ú—ã –¥–∞—ë–º —à–∞–Ω—Å –≤—Å–µ–º –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–≤–æ–∏ —Å–∏–ª—ã –∏ –æ—Å–≤–æ–∏—Ç—å –Ω–æ–≤–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ.\n–ì–∏–±–∫–∏–π –≥—Ä–∞—Ñ–∏–∫\n–ö–∞–º–ø—É—Å—ã ¬´–®–∫–æ–ª—ã 21¬ª –æ—Ç–∫—Ä—ã—Ç—ã 24/7/365, –∞ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 20 —á–∞—Å–æ–≤ –≤ –Ω–µ–¥–µ–ª—é\n–ë–µ–∑ –¥–∏–ø–ª–æ–º–æ–≤ –∏ –ï–ì–≠\n–î–ª—è –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ–π—Ç–∏ –≤—Å—Ç—É–ø–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å–ø—ã—Ç–∞–Ω–∏—è\n–ë–µ–∑ –∑–Ω–∞–Ω–∏–π –≤ –ò–¢\n–û–±—É—á–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Å –Ω—É–ª–µ–≤—ã–º –æ–ø—ã—Ç–æ–º\n–û–±—É—á–µ–Ω–∏–µ —Å 18 –ª–µ—Ç –±–µ–∑ –≤–µ—Ä—Ö–Ω–µ–π –ø–ª–∞–Ω–∫–∏\n–°–∞–º–æ–º—É —Å—Ç–∞—Ä—à–µ–º—É —É—á–∞—Å—Ç–Ω–∏–∫—É 63 –≥–æ–¥–∞\n–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–∏\nimg\n50%\n—É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –ø—Ä–∏—à–ª–∏ –≤ —à–∫–æ–ª—É –±–µ–∑ –æ–ø—ã—Ç–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è\n–≠—Ç–∞–ø—ã –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è\n–í—Å—Ç—É–ø–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å–ø—ã—Ç–∞–Ω–∏–µ ‚Äî –∏–≥—Ä–∞, –ø—Ä–æ–π–¥–∏ –∏ –ø–æ–ø–∞–¥—ë—à—å –Ω–∞ –æ—Ç–±–æ—Ä–æ—á–Ω—ã–π –∏–Ω—Ç–µ–Ω—Å–∏–≤\n\n–ü–æ—Å—Ç—É–ø–∏—Ç—å\n1 —ç—Ç–∞–ø\n‚âà 60 –º–∏–Ω\n–ò–≥—Ä–∞\n–ü—Ä–æ–π–¥–∏ –ò–ì–†–£ –Ω–∞ –ø–∞–º—è—Ç—å –∏ –ª–æ–≥–∏–∫—É. –ü–æ–Ω—è—Ç—å –ø—Ä–∞–≤–∏–ª–∞ ‚Äî —Ç–æ–∂–µ —á–∞—Å—Ç—å –∑–∞–¥–∞–Ω–∏—è. –ó–∞—Ä–∞–±–æ—Ç–∞–π –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–ª–ª–æ–≤ –∏ –ø–æ–ª—É—á–∏ –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø.\n\n–û–Ω–ª–∞–π–Ω\n2 —ç—Ç–∞–ø\n‚âà 20 –º–∏–Ω\n–í–∏–¥–µ–æ –æ —à–∫–æ–ª–µ\n–ü–æ—Å–º–æ—Ç—Ä–∏ –≤–∏–¥–µ–æ –æ —à–∫–æ–ª–µ –≤ –ª–∏—á–Ω–æ–º –∫–∞–±–∏–Ω–µ—Ç–µ. –í –≤–∏–¥–µ–æ –º—ã —Ä–∞—Å—Å–∫–∞–∂–µ–º –≤—Å—ë –æ–± –æ–±—É—á–µ–Ω–∏–∏, —Ä–∞–∑–≤–µ–µ–º —Å–æ–º–Ω–µ–Ω–∏—è –∏ –¥–∞–¥–∏–º –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, —á—Ç–æ —Ç–µ–±—è –∂–¥—ë—Ç –≤ —à–∫–æ–ª–µ.\n\n–û–Ω–ª–∞–π–Ω\n3 —ç—Ç–∞–ø\n‚âà 26 –¥–Ω–µ–π\n–û—Ç–±–æ—Ä–æ—á–Ω—ã–π ¬´–±–∞—Å—Å–µ–π–Ω¬ª\n–ó–∞ 26 –¥–Ω–µ–π –∏–Ω—Ç–µ–Ω—Å–∏–≤–∞ —Ç—ã –æ–∫—É–Ω—ë—à—å—Å—è –≤ –º–∏—Ä –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –ø–æ–π–º—ë—à—å, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ç–µ–±–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø—Ä–æ—Ñ–µ—Å—Å–∏—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞. –≠—Ç–æ —Å–ª–æ–∂–Ω—ã–π —ç—Ç–∞–ø, –∫–æ—Ç–æ—Ä—ã–π —Ç—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ —É—Å–∏–ª–∏–π. –ß—Ç–æ–±—ã –µ–≥–æ –ø—Ä–æ–π—Ç–∏, —Å–æ–≤–µ—Ç—É–µ–º –≤–∑—è—Ç—å –ø–∞—É–∑—É –æ—Ç —É—á—ë–±—ã, —Ä–∞–±–æ—Ç—ã –∏ –¥—Ä—É–≥–∏—Ö –¥–µ–ª.\n\n–û—Ñ–ª–∞–π–Ω –≤ –∫–∞–º–ø—É—Å–µ —à–∫–æ–ª—ã\n–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è\n–ß–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–µ–¥–µ–ª—å –ø–æ—Å–ª–µ ¬´–±–∞—Å—Å–µ–π–Ω–∞¬ª –Ω–∞—á–Ω—ë—Ç—Å—è —É—á—ë–±–∞\n\n18 –º–µ—Å\n–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Å—Ä–æ–∫ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞\n6 –º–µ—Å\n–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Å—Ä–æ–∫ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º –¥—Ä—É–≥–∏—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π\nimg\n–ù–µ—Ç –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫–æ–≤ –∏ –ª–µ–∫—Ü–∏–π\n–£—á–∏—Å—å –≤ —Å–≤–æ—ë–º —Ç–µ–º–ø–µ: –≤—ã–ø–æ–ª–Ω—è–π –∑–∞–¥–∞–Ω–∏—è –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ —à–∫–æ–ª—ã, —Å–º–æ—Ç—Ä–∏ –≤–≤–æ–¥–Ω—ã–µ —Ä–æ–ª–∏–∫–∏ –∏ –æ–±–º–µ–Ω–∏–≤–∞–π—Å—è –∑–Ω–∞–Ω–∏—è–º–∏ —Å –¥—Ä—É–≥–∏–º–∏ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏.\nimg\n–ó–∞–¥–∞—á–∏ –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–∞–∫—Ç–∏–∫–∏\n–ü—Ä–æ–µ–∫—Ç—ã —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–∏–±–ª–∏–∂–µ–Ω—ã –∫ —Ä–µ–∞–ª—å–Ω—ã–º –∑–∞–¥–∞—á–∞–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–≤ –≤ –∫—Ä—É–ø–Ω—ã—Ö –ò–¢- –∫–æ–º–ø–∞–Ω–∏—è—Ö. –û—Å–∏–ª–∏—à—å –≤—Å–µ, –ø—Ä–æ–π–¥—ë—à—å —Å—Ç–∞–∂–∏—Ä–æ–≤–∫—É –∏ —Å—Ç–∞–Ω–µ—à—å —Å–∏–ª—å–Ω—ã–º —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–º —É—Ä–æ–≤–Ω—è –º–∏–¥–ª.\nimg\n¬´–†–∞–≤–Ω—ã–π —Ä–∞–≤–Ω–æ–º—É¬ª\n–í ¬´–®–∫–æ–ª–µ 21¬ª —É—á–∞—Å—Ç–Ω–∏–∫–∏ —É—á–∞—Ç—Å—è –≤ —Å–≤–æ—ë–º —Ç–µ–º–ø–µ –∏ –ø–æ–º–æ–≥–∞—é—Ç –¥—Ä—É–≥ –¥—Ä—É–≥—É: –ø—Ä–æ–≤–µ—Ä—è—é—Ç –ø—Ä–æ–µ–∫—Ç—ã, –æ–±—Å—É–∂–¥–∞—é—Ç –∑–∞–¥–∞—á–∏ –∏ –¥–µ–ª—è—Ç—Å—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é.\nimg\n–ì–µ–π–º–∏—Ñ–∏–∫–∞—Ü–∏—è\n–û–±—É—á–µ–Ω–∏–µ –ø–æ—Ö–æ–∂–µ –Ω–∞ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–π –∏–≥—Ä—ã. –° –∫–∞–∂–¥—ã–º –ø—Ä–æ–µ–∫—Ç–æ–º —Ç—ã –ø–æ–≤—ã—à–∞–µ—à—å —É—Ä–æ–≤–µ–Ω—å, –ø—Ä–∏–æ–±—Ä–µ—Ç–∞–µ—à—å –æ–ø—ã—Ç –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –≤–∞–ª—é—Ç—É. –ï—ë –º–æ–∂–Ω–æ –ø–æ—Ç—Ä–∞—Ç–∏—Ç—å –Ω–∞ –º–µ—Ä—á —à–∫–æ–ª—ã.\n–ü–æ—Å—Ç—É–ø–∏—Ç—å\n–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ–± –æ–±—É—á–µ–Ω–∏–∏\n\n\n–°—Ç–∞–∂–∏—Ä–æ–≤–∫–∞\n–û–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–∞ ‚Äî 3 –º–µ—Å—è—Ü–∞\n–î–ª—è ¬´–®–∫–æ–ª—ã 21¬ª –ø—Ä–∞–∫—Ç–∏–∫–∞ –≤ IT-–∫–æ–º–ø–∞–Ω–∏–∏ ‚Äî —Ç–∞–∫–æ–π –∂–µ —É—á–µ–±–Ω—ã–π –ø—Ä–æ–µ–∫—Ç, –∫–∞–∫ –∏ –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ. –≠—Ç–æ –∑–Ω–∞—á–∏—Ç, —á—Ç–æ —Ç—ã —Ç–æ—á–Ω–æ –Ω–∞–π–¥—ë—à—å —Å—Ç–∞–∂–∏—Ä–æ–≤–∫—É –∏ –ø—Ä–æ—è–≤–∏—à—å —Å–µ–±—è –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞—Ö. –¢—ã –º–æ–∂–µ—à—å –ø–æ–π—Ç–∏ –Ω–∞ —Å—Ç–∞–∂–∏—Ä–æ–≤–∫—É –≤ –ª—é–±–æ–π –º–æ–º–µ–Ω—Ç –æ–±—É—á–µ–Ω–∏—è, –∫–æ–≥–¥–∞ –ø–æ—á—É–≤—Å—Ç–≤—É–µ—à—å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å–µ–±–µ.\n\n–ü—Ä–∏–≥–æ—Ç–æ–≤—å—Å—è –∫ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ–π –ø—Ä–∞–∫—Ç–∏–∫–µ: —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–∞ ‚Äî —ç—Ç–æ —Ä–∞–±–æ—Ç–∞ –º–∏–Ω–∏–º—É–º 20 —á–∞—Å–æ–≤ –≤ –Ω–µ–¥–µ–ª—é.\n100%\n—Å—Ç–∞–∂—ë—Ä–æ–≤ –ø–æ–ª—É—á–∞—é—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ —Ä–∞–±–æ—Ç–µ\n–£—á–∞—Å—Ç–Ω–∏–∫–∏ –∏ –≤—ã–ø—É—Å–∫–Ω–∏–∫–∏ –æ ¬´–®–∫–æ–ª–µ 21¬ª\n–û—Ç–∑—ã–≤—ã —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ ¬´–®–∫–æ–ª—ã 21¬ª\n\n\n–ù–∞—Ç–∞–ª—å—è\n–≤—ã–ø—É—Å–∫–Ω–∏—Ü–∞\n\n–°—Ç–∞—Ä—à–∏–π –∏–Ω–∂–µ–Ω–µ—Ä –ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ, —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –≤ –°–±–µ—Ä–µ\n\n–ê–Ω–Ω–∞\n—É—á–∞—Å—Ç–Ω–∏—Ü–∞\n\n–°—Ç—É–¥–µ–Ω—Ç 2 –∫—É—Ä—Å–∞ –§–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ –ø—Ä–∏ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–µ –†–§\n\n–ò—Ä–∏–Ω–∞\n–≤—ã–ø—É—Å–∫–Ω–∏—Ü–∞\n\n–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ BIOS –≤ –∫–æ–º–ø–∞–Ω–∏–∏ ¬´–ê–∫–≤–∞—Ä–∏—É—Å¬ª \n\n–ê–Ω—Ç–æ–Ω\n–≤—ã–ø—É—Å–∫–Ω–∏–∫\n\nDevOps-–∏–Ω–∂–µ–Ω–µ—Ä\n\n–í–∞–¥–∏–º\n–≤—ã–ø—É—Å–∫–Ω–∏–∫\n\n–ì–ª–∞–≤–Ω—ã–π –∏–Ω–∂–µ–Ω–µ—Ä –ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –≤ –ü–ê–û –°–±–µ—Ä–±–∞–Ω–∫\n\n–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è\n–ü—Ä–æ–∫–∞—á–∏–≤–∞–µ–º –Ω–µ —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ, –Ω–æ –∏ –º—è–≥–∫–∏–µ –Ω–∞–≤—ã–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ü–µ–Ω—è—Ç—Å—è –Ω–∞ —Ä—ã–Ω–∫–µ –≤ –ò–¢\nicon–†–∞–±–æ—Ç–∞ –≤ –∫–æ–º–∞–Ω–¥–µ\nicon–ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤\nicon–°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞\niconScrum-–º—ã—à–ª–µ–Ω–∏–µ\nicon–ë—ã—Å—Ç—Ä–æ–µ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏–π\nicon–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–∞–º–∏\n–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ –º–µ—Ç–æ–¥–∏–∫–µ\nimg\n–ö–∞–º–ø—É—Å—ã\n–ö–∞–º–ø—É—Å—ã –ø–æ—Ö–æ–∂–∏ –Ω–∞ –æ—Ñ–∏—Å—ã –ò–¢-–∫–æ–º–ø–∞–Ω–∏–π: —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–æ—Ñ—Ç, –∏–≥—Ä–æ–≤—ã–µ –∏ –≤—Å—ë –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n–ú–æ—Å–∫–≤–∞\n–ú–æ—Å–∫–≤–∞\n—É–ª. –í—è—Ç—Å–∫–∞—è, –¥. 27, —Å—Ç—Ä. 42\n\n–ö–∞–∑–∞–Ω—å\n–ö–∞–∑–∞–Ω—å\n—É–ª. –°–ø–∞—Ä—Ç–∞–∫–æ–≤—Å–∫–∞—è, –¥. 2, –∫–æ—Ä–ø. 2\n\n–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫\n–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫\n–ø–ª. –ö–∞—Ä–ª–∞ –ú–∞—Ä–∫—Å–∞, –¥. 7\n\n–°—É—Ä–≥—É—Ç\n–°—É—Ä–≥—É—Ç\n—É–ª. –ò–æ—Å–∏—Ñ–∞ –ö–∞—Ä–æ–ª–∏–Ω—Å–∫–æ–≥–æ, –¥. 14/1\n\n–í–µ–ª–∏–∫–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥\n–í–µ–ª–∏–∫–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥\n—É–ª. –í–µ–ª–∏–∫–∞—è, –¥. 18–ê\n\n–Ø–∫—É—Ç—Å–∫\n–Ø–∫—É—Ç—Å–∫\n—É–ª. –û–π—É–Ω—Å–∫–æ–≥–æ, –¥. 35\n\n–Ø—Ä–æ—Å–ª–∞–≤–ª—å\n–Ø—Ä–æ—Å–ª–∞–≤–ª—å\n—É–ª. –ü–æ–±–µ–¥—ã, –¥. 14–ê\n\n–õ–∏–ø–µ—Ü–∫\n–õ–∏–ø–µ—Ü–∫\n—É–ª. –ó–µ–≥–µ–ª—è, –¥. 1\n\n–Æ–∂–Ω–æ-–°–∞—Ö–∞–ª–∏–Ω—Å–∫\n–Æ–∂–Ω–æ-–°–∞—Ö–∞–ª–∏–Ω—Å–∫\n—É–ª. –õ–µ–æ–Ω–æ–≤–∞ –¥. 38 (–ù–æ–≤—ã–π –ë–∏–∑–Ω–µ—Å-—Ü–µ–Ω—Ç—Ä)\n\n–ú–∞–≥–∞—Å\n–ú–∞–≥–∞—Å\n—É–ª. –ù–∏–∫–∏—Ç—ã –•—Ä—É—â–µ–≤–∞, –¥. 10\n\n–ß–µ–ª—è–±–∏–Ω—Å–∫\n–ß–µ–ª—è–±–∏–Ω—Å–∫\n–ø—Ä. –õ–µ–Ω–∏–Ω–∞, –¥. 76–∞\n\n–ú–∞–≥–∞–¥–∞–Ω\n–ú–∞–≥–∞–¥–∞–Ω\n–£–ª. –ö–æ–ª—å—Ü–µ–≤–∞—è 3/8\n\n–ë–µ–ª–≥–æ—Ä–æ–¥\n–ë–µ–ª–≥–æ—Ä–æ–¥\n–ø—Ä. –í–∞—Ç—É—Ç–∏–Ω–∞, –¥. 1–ì\n\n–ê–Ω–∞–¥—ã—Ä—å\n–ê–Ω–∞–¥—ã—Ä—å\n—É–ª. –°—Ç—É–¥–µ–Ω—á–µ—Å–∫–∞—è –¥.3\n\n–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥\n–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥\n—É–ª. –¢—É—Ä–≥–µ–Ω–µ–≤–∞, –¥. 30\n\n–£—Ñ–∞\n–£—Ñ–∞\n—É–ª. –ó–∞–∫–∏ –í–∞–ª–∏–¥–∏, –¥. 32/2–±"
  },
  {
    "id": "6dee0f35-7821-4ddd-9225-a6467bb7fae2",
    "source_file": "faq.txt",
    "section": "text file",
    "content": "–î–∞–Ω–Ω—ã–π FAQ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Ç–≤–µ—Ç—ã –Ω–∞ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –ø–æ–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ —Ä–µ–∂–∏–º–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏.\n\n–î–≤–∏–∂–µ–Ω–∏–µ –ø–æ –≥—Ä–∞—Ñ—É\na) –ö–∞–∫–∏–µ —ç—Ç–∞–ø—ã –º–Ω–µ –Ω—É–∂–Ω–æ –ø—Ä–æ–π—Ç–∏, —á—Ç–æ–±—ã –≤—ã–ø—É—Å—Ç–∏—Ç—å—Å—è?\n\n–ù–∞–±—Ä–∞—Ç—å 11-12 (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–æ–ª–Ω—ã) —É—Ä–æ–≤–µ–Ω—å –∑–∞ —Å—á–µ—Ç –ø—Ä–æ–µ–∫—Ç–æ–≤ –Ω–∞ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã—Ö –≤–µ—Ç–∫–∞—Ö;\n–°—Ç–∞—Ä—Ç–æ–≤–∞—Ç—å (–∑–∞–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å) 3-—Ö –º–µ—Å—è—á–Ω—É—é —Å—Ç–∞–∂–∏—Ä–æ–≤–∫—É.\n–ó–∞–≤–µ—Ä—à–∏—Ç—å Career Track. Project 08 (–¥–ª—è –≤–æ–ª–Ω 23_12 –∏ –ø–æ–∑–¥–Ω–µ–µ)\n–ü—Ä–æ–µ–∫—Ç—ã \"–ë–∞–∑—ã\" - –Ω–∞–±–æ—Ä –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ –¥–æ Career track\n–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ —É—Å–ª–æ–≤–∏—è –æ—Ç–∫—Ä—ã—Ç–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤ —É—á–∞—Å—Ç–Ω–∏–∫ –º–æ–∂–µ—Ç –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ –∫–∞—Ä—Ç–æ—á–∫–µ –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞.\n–í–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–µ –≤–µ—Ç–∫–∏ - –Ω–∞–±–æ—Ä—ã –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ—Å–ª–µ \"–ë–∞–∑—ã\". –û—Ç–∫—Ä—ã–≤–∞—é—Ç—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ –≤ \"–ë–∞–∑–µ\". –ú–æ–≥—É—Ç –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è —Ç—Ä–µ–±–æ–≤–∞—Ç—å —Å–¥–∞—á—É —ç–∫–∑–∞–º–µ–Ω–∞.\n–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã\n–ü—Ä–æ–µ–∫—Ç—ã C7, CPP3 –∏ AP2 –±—ã–ª–∏ –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ –Ω–æ–≤—É—é —Å–µ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ª–µ–≥–∞—Å–∏ - BrickGame.\n–ü—Ä–æ–µ–∫—Ç—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –∏–∑ —Å–µ–±—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—é –∏–≥—Ä—ã BrickGame –æ—Ç –ø—Ä–æ–µ–∫—Ç–∞ –∫ –ø—Ä–æ–µ–∫—Ç—É. –î–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –ª–µ–≥–∞—Å–∏ –∫–æ–¥ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞.\n\n\nb) –ï—Å–ª–∏ —è —Ä–∞–Ω–µ–µ –≤—ã–ø–æ–ª–Ω–∏–ª –ø—Ä–æ–µ–∫—Ç C7, –∞ —Ç–µ–ø–µ—Ä—å –≤ –≥—Ä–∞—Ñ–µ –ø–æ—è–≤–∏–ª–∞—Å—å –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è, –¥–æ–ª–∂–µ–Ω –ª–∏ —è –µ–≥–æ –ø–µ—Ä–µ—Å–¥–∞–≤–∞—Ç—å –∏–ª–∏ –æ–Ω –ø–µ—Ä–µ–∑–∞—á—Ç–µ—Ç—Å—è? –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ª–∏ –≤—ã–ø–æ–ª–Ω—è—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã?\n–°—Ç–∞—Ä—ã–µ –∏ –Ω–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏—à–ª–∏ –∏–º –Ω–∞ –∑–∞–º–µ–Ω—É –≤–∑–∞–∏–º–æ–∑–∞–º–µ–Ω—è–µ–º—ã–µ. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞ –Ω–∏–º–∏ –ø—Ä–æ–µ–∫—Ç–æ–≤ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ –Ω–µ—Ç —Ä–∞–∑–Ω–∏—Ü—ã –±—ã–ª –≤—ã–ø–æ–ª–Ω–µ–Ω —Å—Ç–∞—Ä—ã–π –ø—Ä–æ–µ–∫—Ç –ø–æ–¥ —ç—Ç–∏–º –∫–æ–¥–æ–º, –∏–ª–∏ –Ω–æ–≤—ã–π.\n–ù–∞–ø—Ä–∏–º–µ—Ä, –∏ —Å—Ç–∞—Ä—ã–π –ø—Ä–æ–µ–∫—Ç –°PP3 –∏ –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç –°PP3 BrickGame v2.0 –æ—Ç–∫—Ä—ã–≤–∞—é—Ç –¥–æ—Å—Ç—É–ø –∫ CPP4. –ò —Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è —ç–∫–∑–∞–º–µ–Ω–∞ DevOps, –∏ –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è —ç–∫–∑–∞–º–µ–Ω–∞ DO_Ex —Ä–∞–≤–Ω–æ–∑–Ω–∞—á–Ω—ã –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ Career track. –ü–æ—ç—Ç–æ–º—É –Ω–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Å–¥–∞–≤–∞—Ç—å –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –ø—Ä–æ–µ–∫—Ç–∞, –µ—Å–ª–∏ –±—ã–ª–∞ —É—Å–ø–µ—à–Ω–æ —Å–¥–∞–Ω–∞ —Å—Ç–∞—Ä–∞—è.\n–î–æ–π–¥—è –¥–æ –ø—Ä–æ–µ–∫—Ç–∞, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ –º—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∑–∞–º–µ–Ω—É, —É –≤–∞—Å –µ—Å—Ç—å –≤—ã–±–æ—Ä- —Å–¥–µ–ª–∞—Ç—å —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é –ø—Ä–æ–µ–∫—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä - –°–†–†3) –∏–ª–∏ –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é (BrickGame v2 -–°–†–†3). –ï—Å–ª–∏ –≤—ã –≤–∑—è–ª–∏—Å—å –≤—ã–ø–æ–ª–Ω—è—Ç—å –æ–¥–Ω—É –∏–∑ –≤–µ—Ä—Å–∏–π –ø—Ä–æ–µ–∫—Ç–∞, —Ç–æ –≤–∑—è—Ç—å –¥—Ä—É–≥—É—é –≤ —Ä–∞–±–æ—Ç—É –≤—ã —É–∂–µ –Ω–µ —Å–º–æ–∂–µ—Ç–µ. \n–ü—Ä–∏ —ç—Ç–æ–º –¥–æ–π–¥—è –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–æ–¥–æ–±–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä APP2, —É –≤–∞—Å –≤–Ω–æ–≤—å –±—É–¥–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤—ã–±—Ä–∞—Ç—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –∏–ª–∏ –Ω–æ–≤—ã–π BrickGame v3.0. \n(–¢—É—Ç —Å–ª–µ–¥—É–µ—Ç –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –ø—Ä–æ–µ–∫—Ç APP2 –¥–æ—Å—Ç—É–ø–µ–Ω –Ω–∞ —Ç–æ–º —è–∑—ã–∫–µ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –≤—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª–∏ APP1 Bootcamp).\n–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –≤—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –≤—ã–ø–æ–ª–Ω—è—Ç—å —Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ –ø—Ä–æ–µ–∫—Ç–æ–≤, –µ—Å–ª–∏ –æ–Ω–∏ –≤–∞–º –¥–æ—Å—Ç—É–ø–Ω—ã. (–î–ª—è –≤–æ–ª–Ω 23_10 –∏ 23_12 —Å—Ç–∞—Ä—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã).\n\n\nc) –Ø —É–∂–µ –≤—ã–ø–æ–ª–Ω–∏–ª –°7 (–°–†–†3/–ê–†2) –∏ –≤–µ—Ç–∫–∞ –≤ –≥—Ä–∞—Ñ–µ —Å–≤–µ—Ç–∏–ª–∞—Å—å –∑–µ–ª–µ–Ω—ã–º, –∫–∞–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–∞—è. –ê —Ç–µ–ø–µ—Ä—å –≤–º–µ—Å—Ç–æ —Å—Ç–∞—Ä–æ–≥–æ –°7 –ø–æ—è–≤–∏–ª—Å—è –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç –∏ –≤–µ—Ç–∫–∞ –ø–µ—Ä–µ—Å—Ç–∞–ª–∞ —Å–≤–µ—Ç–∏—Ç—å—Å—è –∑–µ–ª–µ–Ω—ã–º. –ù—É–∂–Ω–æ –ª–∏ –º–Ω–µ –≤—ã–ø–æ–ª–Ω—è—Ç—å –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç, —á—Ç–æ–±—ã —ç—Ç–∞ –≤–µ—Ç–∫–∞ –±—ã–ª–∞ –∑–∞—á—Ç–µ–Ω–∞, –µ—Å–ª–∏ –±—ã–ª –≤—ã–ø–æ–ª–Ω–µ–Ω —Å—Ç–∞—Ä—ã–π –ø—Ä–æ–µ–∫—Ç? –ù–µ—Ç, –Ω–µ –Ω—É–∂–Ω–æ.\n–ù–∞ –≤–∏–∑—É–∞–ª—å–Ω—ã–π –≥—Ä–∞—Ñ –¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã BrickGame –∏ –ê–ª–≥–æ—Ä–∏—Ç–º—ã –ê1 –∏ –ê2 –Ω–∞ 9 —è–∑—ã–∫–∞—Ö. –°—Ç–∞—Ä—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –º—ã –∏—Å–∫–ª—é—á–∏–ª–∏ –∏–∑ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∞, –Ω–æ –≤—ã –¥–æ —Å–∏—Ö –ø–æ—Ä –º–æ–∂–µ—Ç–µ –Ω–∞–π—Ç–∏ –∏—Ö –≤ —Ä–∞–∑–¥–µ–ª–µ Projects.\n–ï—Å–ª–∏ –≤—ã –≤—ã–ø–æ–ª–Ω–∏–ª–∏ –∫–∞–∫–∏–µ-–ª–∏–±–æ –∏–∑ —Å—Ç–∞—Ä—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤, —Ç–æ –±–ª–æ–∫–∏/–≤–µ—Ç–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ —è–∑—ã–∫–∞ –º–æ–≥—É—Ç –Ω–µ –ø–æ–¥—Å–≤–µ—á–∏–≤–∞—Ç—å—Å—è –≤ –≤–∏–∑—É–∞–ª—å–Ω–æ–º –≥—Ä–∞—Ñ–µ –∑–µ–ª–µ–Ω—ã–º, –ø–æ—Å–∫–æ–ª—å–∫—É —Å—Ç–∞—Ä—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –∏—Å–∫–ª—é—á–µ–Ω—ã –∏–∑ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∞. –û–¥–Ω–∞–∫–æ —ç—Ç–æ –ù–ï –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤—ã –ù–ï –∑–∞–≤–µ—Ä—à–∏–ª–∏ —Ä–∞–±–æ—Ç—É –Ω–∞–¥ —ç—Ç–æ–π –≤–µ—Ç–∫–æ–π. –ò —Å—Ç–∞—Ä—ã–µ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –≤—Ö–æ–¥—è—Ç –≤ –±–∞–∑—É.\n–ù–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–∫–∞–∑–∞–Ω—ã –≤ –≤–∏–∑—É–∞–ª—å–Ω–æ–º –≥—Ä–∞—Ñ–µ, –µ—Å–ª–∏ –≤—ã –≤—ã–ø–æ–ª–Ω–∏–ª–∏ —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é –ø—Ä–æ–µ–∫—Ç–∞ —Å —Ç–∞–∫–∏–º –∂–µ –∫–æ–¥–æ–º (–∏—Å–∫–ª—é—á–µ–Ω–∏–µ –≤–æ–ª–Ω—ã 23_10 –∏ 23_12, –∫–æ—Ç–æ—Ä—ã–º –¥–æ—Å—Ç—É–ø–Ω—ã —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã).\n\n\nd) –Ø —É–∂–µ –≤—ã–ø–æ–ª–Ω—è—é –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä. –°–º–æ–≥—É –ª–∏ —è –µ–≥–æ –ø–µ—Ä–µ—Å–¥–∞—Ç—å, –µ—Å–ª–∏ –∑–∞—Ñ–µ–π–ª—é –ø—Ä–∏ —Å–¥–∞—á–µ? –ö–ª–∞—Å—Å–∞–º, —Å—Ç–∞—Ä—Ç–æ–≤–∞–≤—à–∏–º –æ—Å–Ω–æ–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ –≤—Ç–æ—Ä–æ–π –ø–æ–ª–æ–≤–∏–Ω—ã 2023 –≥. (–≤–æ–ª–Ω—ã 23_10 , 23_12 –∏ –ø–æ–∑–∂–µ) –º—ã —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –Ω–æ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ BrickGame. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞ –¥–ª—è –≤–∞—Å –∑–∞–∫—Ä—ã—Ç–æ. –ï—Å–ª–∏ –≤—ã —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç–µ –ø—Ä–æ–µ–∫—Ç –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞, –∏ –ø—Ä–æ–µ–∫—Ç –±—ã–ª –∑–∞—Ñ–µ–π–ª–µ–Ω, —Ç–æ —É –≤–∞—Å –Ω–µ –±—É–¥–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–µ—Ä–µ—Å–¥–∞—Ç—å —ç—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç.\n–ö–ª–∞—Å—Å–∞–º, —Å—Ç–∞—Ä—Ç–æ–≤–∞–≤—à–∏–º –æ—Å–Ω–æ–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–æ –≤—Ç–æ—Ä–æ–π –ø–æ–ª–æ–≤–∏–Ω—ã 2023 –≥. –¥–æ—Å—Ç—É–ø–µ–Ω –≤—ã–±–æ—Ä: —Å—Ç–∞—Ä—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞ –∏–ª–∏ –Ω–æ–≤—ã–µ BrickGame. –ï—Å–ª–∏ —É—á–∞—Å—Ç–Ω–∏–∫–∏ —ç—Ç–∏—Ö –∫–ª–∞—Å—Å–æ–≤ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞ –∏ –∑–∞—Ñ–µ–π–ª—è—Ç –µ–≥–æ —Å–¥–∞—á—É, —É –Ω–∏—Ö –±—É–¥–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–µ—Ç—Ä–∞—è. –û–¥–Ω–∞–∫–æ, —Å–ª–µ–¥—É–µ—Ç –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ç–æ, —á—Ç–æ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—Ä–æ–µ–∫—Ç —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –∫–æ–¥–æ–º –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –≤—ã–±–æ—Ä–∞: –ª–∏–±–æ —Å—Ç–∞—Ä—ã–π –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä, –ª–∏–±–æ –Ω–æ–≤—ã–π BrickGame. –§–∞–∫—Ç–æ–º –≤—ã–±–æ—Ä–∞ —Å—á–∏—Ç–∞–µ—Ç—Å—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ –ø—Ä–æ–µ–∫—Ç. –•–æ—Ä–æ—à–æ –ø–æ–¥—É–º–∞–π—Ç–µ –ø–µ—Ä–µ–¥ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–µ–π –Ω–∞ –ø—Ä–æ–µ–∫—Ç. –ò–∑–º–µ–Ω–∏—Ç—å –≤—ã–±–æ—Ä –º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ –≤ —Å–ª—É—á–∞–µ –≥–∏–≤–∞–ø–∞ –ø—Ä–æ–µ–∫—Ç–∞ —Å –ø–æ—Å–ª–µ–¥—É—é—â–∏–º —Ä–µ—Ç—Ä–∞–µ–º, –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ –ø—Ä–æ–µ–∫—Ç –ø–µ—Ä–µ–π–¥–µ—Ç –≤ —Å—Ç–∞—Ç—É—Å –±–µ–∑ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏, –∏ —É –≤–∞—Å –ø–æ—è–≤–∏—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –Ω–∞ –¥—Ä—É–≥–æ–π –ø—Ä–æ–µ–∫—Ç.\n\n\ne) –ö–∞–∫ –≤—ã–ø–æ–ª–Ω—è—Ç—å BrickGame, –µ—Å–ª–∏ —è –Ω–µ –≤—ã–ø–æ–ª–Ω—è–ª –µ–≥–æ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –≤–µ—Ä—Å–∏–∏? –ó–¥–µ—Å—å –≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç –ø–æ—Ä–∞–±–æ—Ç–∞—Ç—å —Å –ª–µ–≥–∞—Å–∏ –∫–æ–¥–æ–º. –ü–æ—Å–∫–æ–ª—å–∫—É –≤—ã –º–æ–≥–ª–∏ —Å—Ç–æ–ª–∫–Ω—É—Ç—å—Å—è —Å —ç—Ç–∏–º –ø—Ä–æ–µ–∫—Ç–æ–º —É–∂–µ –∑–∞–≤–µ—Ä—à–∏–≤ –≤–µ—Ç–∫—É —Å–∏, –º—ã –¥–æ–ø—É—Å–∫–∞–µ–º, —á—Ç–æ –ª–µ–≥–∞—Å–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º, –Ω–æ –∏ —á—É–∂–∏–º. –≠—Ç–æ –æ–±—ã—á–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞ –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ —Ä–∞–±–æ—Ç–∞—Ç—å —Å —á—É–∂–∏–º –ª–µ–≥–∞—Å–∏ –∫–æ–¥–æ–º. –ù–æ –¥–ª—è —É—Å–ø–µ—à–Ω–æ–π —Å–¥–∞—á–∏ –ø—Ä–æ–µ–∫—Ç–∞ –≤ —á—É–∂–æ–º –ª–µ–≥–∞—Å–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è, —á—Ç–æ–±—ã –Ω–µ –ø–æ–ª—É—á–∏—Ç—å —á–∏—Ç –æ—Ç –ø—Ä–æ–≤–µ—Ä—è—é—â–µ–≥–æ. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–æ–≤ –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–æ–≤ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ BrickGame\n–û—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–ª—å –æ–¥–∏–Ω–∞–∫–æ–≤–∞—è - —Å–æ–∑–¥–∞—Ç—å –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –∞ —Ç–∞–∫–∂–µ –æ—Ç—Ä–∞–±–æ—Ç–∞—Ç—å –≤ —Ä–∞–º–∫–∞—Ö –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Ä–∞–±–æ—Ç—É —Å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º –∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫—É—é –∑–∞–¥–∞—á—É.\n–í—Ç–æ—Ä–∞—è –∑–∞–¥–∞—á–∞ - –ø–æ—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ —Å–≤–æ–∏–º –ª–µ–≥–∞—Å–∏ –∫–æ–¥–æ–º, —Ä–∞–∑–≤–∏–≤–∞—Ç—å —Å–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ.\n–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –º—ã –ø–æ–¥—Å–≤–µ—á–∏–≤–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ—é —Å–∏—Å—Ç–µ–º—É —Ç–∞–∫, —á—Ç–æ–±—ã –µ–µ –±—ã–ª–æ —É–¥–æ–±–Ω–æ —Ä–∞–∑–≤–∏–≤–∞—Ç—å –≤ –±—É–¥—É—â–µ–º. –¢–∞–∫–∂–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ –±—Ä–∏–∫–≥–µ–π–º–∞ –Ω—É–∂–Ω–æ –Ω–∞—É—á–∏—Ç—å—Å—è —Å–æ–µ–¥–∏–Ω—è—Ç—å —Ä–∞–∑–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏ (–∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞—Ö). –ï—â–µ –æ–¥–∏–Ω –≤–∞–∂–Ω—ã–π –º–æ–º–µ–Ω—Ç- –≤ —ç—Ç–∏—Ö –∑–∞–¥–∞—á–∞—Ö –Ω–µ—Ç –ë–î, –µ—Å—Ç—å —Ä–∞–±–æ—Ç–∞ —Ç–æ–ª—å–∫–æ —Å –∫–æ–¥–æ–º, —Å –ª–æ–≥–∏–∫–æ–π –∏ —Å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º.\n\n\n–ö–∞–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –±—ã–ª–∏ –≤ –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ—à–∏–ª–∏ –≤ –±—Ä–∏–∫–≥–µ–π–º–∞—Ö:\n\n–ë—ã–ª–æ –º–Ω–æ–≥–æ –¥–µ—Å–∫—Ç–æ–ø–Ω—ã—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤. –≠—Ç–æ –Ω–µ–º–Ω–æ–≥–æ —É—Å—Ç–∞—Ä–µ–≤—à–∏–π –ø–æ–¥—Ö–æ–¥, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ–¥–∫–æ —Å–µ–π—á–∞—Å –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è. –í –±—Ä–∏–∫–≥–µ–π–º–∞—Ö –æ–Ω —Ä–µ—à–µ–Ω —Ç–µ–º, —á—Ç–æ –≤ –∫–∞–∂–¥–æ–º –ø—Ä–æ–µ–∫—Ç–µ —Å–≤–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: –≤ –ø–µ—Ä–≤–æ–º- —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã–π, –Ω–∞ –°++ - –¥–µ—Å–∫—Ç–æ–ø–Ω—ã–π, –¥–∞–ª–µ–µ - –≤–µ–± –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≤ 3 –∏ 4 –±—Ä–∏–∫–≥–µ–π–º–µ.\n–í –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞—Ö –±—ã–ª–æ –ø–ª–æ—Ö–æ –ø—Ä–æ–ø–∏—Å–∞–Ω–æ —Ä–∞–∑–≤–∏—Ç–∏–µ –ª–µ–≥–∞—Å–∏. –í –±—Ä–∏–∫–≥–µ–π–º–∞—Ö —ç—Ç–æ–º—É —É–¥–µ–ª–µ–Ω–æ –æ—Ç–¥–µ–ª—å–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ, –∏ –ø—Ä–æ–ø–∏—Å–∞–Ω–æ —á—Ç–æ –∏ –∫–∞–∫ –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å. –í —á–∞—Å—Ç–Ω–æ—Å—Ç–∏ –±—ã–ª –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –æ–ø—ã—Ç —É —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∑–∞–∫–ª—é—á–∞–≤—à–∏–π—Å—è –≤ —Ç–æ–º, —á—Ç–æ –ø—Ä–∏—Ö–æ–¥–∏–ª–æ—Å—å –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞—Ç—å –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ. –í –±—Ä–∏–∫–≥–µ–π–º–∞—Ö —ç—Ç–æ —Å–≤–µ–ª–∏ –∫ –º–∏–Ω–∏–º—É–º—É. –ò–≥—Ä—ã –Ω–∞ –≤—Å–µ—Ö 4—Ö –±—Ä–∏–∫–≥–µ–π–º–∞—Ö —Ä–∞–∑–Ω—ã–µ, –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã –≤–µ–∑–¥–µ —Ä–∞–∑–Ω—ã–µ, –Ω–æ –µ–¥–∏–Ω—ã–π –¥–≤–∏–∂–æ–∫, –µ–¥–∏–Ω—ã–π –ø–æ–¥—Ö–æ–¥, –µ–¥–∏–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞. –°—Ç–∞—Ä—ã–µ –º–æ–¥—É–ª–∏ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∏ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞—Ç—å –Ω–µ –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç, –∏—Ö –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç —Ç–æ–ª—å–∫–æ –ø–æ–¥–∫–ª—é—á–∞—Ç—å.\n–ü–æ –∏—Ç–æ–≥—É –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤—Å–µ—Ö 4—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ –±—Ä–∏–∫–≥–µ–π–º–∞ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —Ö–æ—Ä–æ—à–∏–π –æ–ø—ã—Ç –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Ä–∞–∑–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π.\n–ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –ê–ª–≥–æ—Ä–∏—Ç–º–æ–≤\n–ó–∞–¥–∞–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –Ω–∞ 9 —è–∑—ã–∫–∞—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è: C, C++, Java, Python, Go, C#, Kotlin, Swift, JavaScipt –≤ –≤–∏–¥–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤.\n\n–î–æ—Å—Ç—É–ø –∫ –ø—Ä–æ–µ–∫—Ç–∞–º –ê1 –Ω–∞ —è–∑—ã–∫–∞—Ö Java, Python, Go, C#, Kotlin, Swift, JavaScipt –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω—Ç–µ–Ω—Å–∏–≤–∞ AP1 –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º —è–∑—ã–∫–µ. (–ù–∞–ø—Ä–∏–º–µ—Ä, AP1 –Ω–∞ —è–∑—ã–∫–µ JS –æ—Ç–∫—Ä–æ–µ—Ç –¥–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –∫ A1_Maze_JavaScript.\nA1 –Ω–∞ —è–∑—ã–∫–µ –°–∏ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –°7 (–Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç BrickGame v1.0 –∏–ª–∏ —Å—Ç–∞—Ä—ã–π –ø—Ä–æ–µ–∫—Ç –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä).\nA1 –Ω–∞ —è–∑—ã–∫–µ –°++ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ CPP4 (3DViewer_v2.0)\n–ü—Ä–æ–µ–∫—Ç A2 –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –¥–æ—Å—Ç—É–ø –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é —ç–∫–∑–∞–º–µ–Ω–∞ –ø–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º - –≥—Ä—É–ø–ø–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤ A_Ex.\n\nf) –ö–∞–∫ –º–Ω–µ –ø–æ–Ω—è—Ç—å –∫–∞–∫–∏–µ –ø—Ä–æ–µ–∫—Ç—ã –Ω—É–∂–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å?\n–£—Å–ª–æ–≤–∏–µ–º –≤—ã—Ö–æ–¥–∞ –∫ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–º –≤–µ—Ç–∫–∞–º —è–≤–ª—è–µ—Ç—Å—è —É—Å–ø–µ—à–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ Career track. –î–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–∞–∫–∏–µ –ø—Ä–æ–µ–∫—Ç—ã –±–ª–æ–∫–∏—Ä—É—é—Ç Career track –≤—ã –Ω–∞–π–¥–µ—Ç–µ –≤ –∫–∞—Ä—Ç–æ—á–∫–µ –ø—Ä–æ–µ–∫—Ç–∞.\n–í –æ–±—â–∏—Ö —á–µ—Ä—Ç–∞—Ö: –∫–ª–∞—Å—Å–∞–º –¥–æ 23_04 –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ, –Ω—É–∂–Ω–æ —Å–¥–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—Ä–æ–µ–∫—Ç –Ω–∞ –∫–∞–∂–¥–æ–π –≤–µ—Ç–∫–µ –ë–∞–∑—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–∞ –∫ Career track. \n–î–ª—è –∫–ª–∞—Å—Å–æ–≤ 23_10 –∏ 23_12 –∏ –ø–æ–∑–¥–Ω–µ–µ, –Ω—É–∂–Ω–æ —É—Å–ø–µ—à–Ω–æ —Å–¥–∞—Ç—å –º–∏–Ω–∏—ç–∫–∑–∞–º–µ–Ω—ã, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ Career track. –û–±—Ä–∞—â–∞—è—Å—å –∫ –∫–∞—Ä—Ç–æ—á–∫–µ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ –º–æ–∂–Ω–æ –ø–æ–Ω—è—Ç—å –∫–∞–∫–∏–µ –ø—Ä–æ–µ–∫—Ç—ã –±–ª–æ–∫–∏—Ä—É—é—Ç –¥–æ—Å—Ç—É–ø –∫ —ç—Ç–æ–º—É –ø—Ä–æ–µ–∫—Ç—É.\n\n\n\n–Ø–∑—ã–∫–æ–≤—ã–µ –∏–Ω—Ç–µ–Ω—Å–∏–≤—ã\n–í –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ –∏–Ω—Ç–µ–Ω—Å–∏–≤–æ–≤.\n–í –Ω–∏—Ö –æ—Ç–∫–ª—é—á–µ–Ω—ã –ø–µ—Ä–∏–æ–¥—ã, —Ç.–µ. —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –∏ –Ω–∞—á–∏–Ω–∞—Ç—å –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –º–æ–∂–Ω–æ –≤ –ª—é–±–æ–µ –≤—Ä–µ–º—è. –°–∞–º–∏ –ø—Ä–æ–µ–∫—Ç—ã —Ç–∞–∫–∂–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.\n–î–ª—è —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω—Ç–µ–Ω—Å–∏–≤–∞ –Ω—É–∂–Ω–æ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∏—Ç—å –ø–æ–ª–æ–≤–∏–Ω—É –ø—Ä–æ–µ–∫—Ç–æ–≤, —Ç.–µ. –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∏–Ω—Ç–µ–Ω—Å–∏–≤ –Ω–∞ 50%\n\ng) –ö–æ–≥–¥–∞ –ø–æ—è–≤—è—Ç—Å—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∏–Ω—Ç–µ–Ω—Å–∏–≤—ã AP1 –æ–Ω–∏ –ø–µ—Ä–µ–∑–∞—á—Ç—É—Ç—Å—è –∏–ª–∏ –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å –Ω–æ–≤—ã–µ?\n–ï—Å–ª–∏ –≤—ã —Ä–∞–Ω–µ–µ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—à–ª–∏ –∏–Ω—Ç–µ–Ω—Å–∏–≤, —Ç–æ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ–≤—ã–π (–ø–æ –¥–∞–Ω–Ω–æ–º—É —è–∑—ã–∫—É) –Ω–µ –Ω—É–∂–Ω–æ.\n\n\nh) –ö–æ–≥–¥–∞ –æ—Ç–∫—Ä–æ—é—Ç—Å—è –Ω–æ–≤—ã–µ –∏–Ω—Ç–µ–Ω—Å–∏–≤—ã? –°—Ç–æ–∏—Ç –ª–∏ –º–Ω–µ —Å–µ–π—á–∞—Å —Å—Ç–∞—Ä—Ç–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—ã–µ –∏–Ω—Ç–µ–Ω—Å–∏–≤—ã?\n–ú—ã –µ—â–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –Ω–∞–¥ —Ç–æ—Ç–∞–ª—å–Ω–æ–π –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–æ–π –∏–Ω—Ç–µ–Ω—Å–∏–≤–æ–≤, –ø–æ—ç—Ç–æ–º—É –ø–æ–∫–∞ –∑–∞–¥–µ—Ä–∂–∏–≤–∞–µ–º—Å—è —Å –∏—Ö —Ä–µ–ª–∏–∑–æ–º. –ú—ã –∑–∞–±–ª–∞–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏–º –æ —Ä–µ–ª–∏–∑–µ –Ω–æ–≤—ã—Ö –∏–Ω—Ç–µ–Ω—Å–∏–≤–æ–≤, –∏—Ö –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ —Å–¥–µ–ª–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –º—è–≥–∫–∏—Ö –∏ –±–µ–∑–±–æ–ª–µ–∑–Ω–µ–Ω–Ω—ã–º. –í–∞–º –Ω–µ –ø—Ä–∏–¥–µ—Ç—Å—è –±—Ä–æ—Å–∞—Ç—å –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –∏–Ω—Ç–µ–Ω—Å–∏–≤–∞, –µ—Å–ª–∏ –≤—ã –µ–≥–æ —É–∂–µ –Ω–∞—á–∞–ª–∏.\n\n\ni) –ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ–π –≤–µ—Ç–∫–µ?\n–î–æ—Å—Ç—É–ø –∫ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–º –≤–µ—Ç–∫–∞–º –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞ Career track - Project 08 + –±—É—Ç–∫–µ–º–ø (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ –≤ —É—Å–ª–æ–≤–∏—è—Ö —ç—Ç–æ–π –≤–µ—Ç–∫–∏). –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –º–∏–Ω–∏-—ç–∫–∑–∞–º–µ–Ω—ã –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –≤—Ö–æ–¥–Ω—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ–º –¥–ª—è 8-–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —Å—Ç–∞—Ä—ã–º –≤–æ–ª–Ω–∞–º (–¥–æ 23_10) –∏—Ö –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–µ –Ω—É–∂–Ω–æ.\n–ü—Ä–∏ —ç—Ç–æ–º –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–∞–Ω–∞–ª—É —Å—Ç–∞–∂–∏—Ä–æ–≤–æ–∫ –¥–µ–π—Å—Ç–≤—É—é—Ç –æ–±—â–∏–µ –ø—Ä–∞–≤–∏–ª–∞, –∏ –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –º–∏–Ω–∏-—ç–∫–∑–∞–º–µ–Ω–∞ –ø–æ –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–º—É —è–∑—ã–∫—É –∏–ª–∏ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –º–∏–Ω–∏-—ç–∫–∑–∞–º–µ–Ω–∞ –ø–æ SQL –∏ DevOps. –û –ø—Ä–∞–≤–∏–ª–∞—Ö –ø–æ–ø–∞–¥–∞–Ω–∏—è –≤ –∫–∞–Ω–∞–ª –æ–ø–∏—Å–∞–Ω–æ –Ω–∏–∂–µ.\n\n\n\n–≠–∫–∑–∞–º–µ–Ω—ã\n–ß—Ç–æ–±—ã —Å–∏—Å—Ç–µ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª—å –∑–Ω–∞–Ω–∏–π —Å –ø–æ–º–æ—â—å—é —ç–∫–∑–∞–º–µ–Ω–æ–≤, –≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–º –≥—Ä–∞—Ñ–µ –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω—ã —ç–∫–∑–∞–º–µ–Ω—ã –ø–æ –∫–∞–∂–¥–æ–π –≤–µ—Ç–∫–µ –ë–∞–∑—ã.\n–í—Å–µ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–¥–∞—Ç—å 6 –≥—Ä—É–ø–ø —ç–∫–∑–∞–º–µ–Ω–æ–≤: DevOps, C, C++, SQL, –ê–ª–≥–æ—Ä–∏—Ç–º—ã, –ü—Ä–∏–∫–ª–∞–¥–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ (–Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —è–∑—ã–∫–µ).\n\n\ng) –Ø –∏–∑ –∫–ª–∞—Å—Å–∞ –•, –Ω—É–∂–Ω–æ –ª–∏ –º–Ω–µ —Å–¥–∞–≤–∞—Ç—å —ç–∫–∑–∞–º–µ–Ω—ã? –£—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–∞–∂–¥–æ–º—É –ø—Ä–æ–µ–∫—Ç—É –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ –∫–∞—Ä—Ç–æ—á–∫–µ –ø—Ä–æ–µ–∫—Ç–∞.\n–û–±—â–∏–µ —É—Å–ª–æ–≤–∏—è —Ç–∞–∫–æ–≤—ã:\n\n–í–æ–ª–Ω–∞–º, —Å—Ç–∞—Ä—Ç–æ–≤–∞–≤—à–∏–º –ø–æ—Å–ª–µ —Å–µ—Ä–µ–¥–∏–Ω—ã 2023 –≥–æ–¥–∞ (23_10 –∏ 23_12), –Ω—É–∂–Ω–æ —Å–¥–∞—Ç—å –º–∏–Ω–∏—ç–∫–∑–∞–º–µ–Ω—ã, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ Career track, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –ø—É—Ç—å –∫ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–º –≤–µ—Ç–∫–∞–º. –í –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö –º—ã —Å–ª–æ–≤–∏–ª–∏ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: –µ—Å–ª–∏ —É—á–∞—Å—Ç–Ω–∏–∫–∏ –≤–æ–ª–Ω 23_10 –∏ 23_12 —É—Å–ø–µ–ª–∏ —Å–¥–∞—Ç—å –ø—Ä–æ–µ–∫—Ç –°7 –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä, —Ç–æ –Ω–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Å–¥–∞–≤–∞—Ç—å C_Ex –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–∞ –∫ Career track.\n–í–æ–ª–Ω–∞–º, —Å—Ç–∞—Ä—Ç–æ–≤–∞–≤—à–∏–º –¥–æ —Å–µ—Ä–µ–¥–∏–Ω—ã 2023 –≥–æ–¥–∞ (23_05, 23_04 –∏ —Ä–∞–Ω–µ–µ), Career track –æ—Ç–∫—Ä–æ–µ—Ç—Å—è –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ –Ω–∞ –≤–µ—Ç–∫–µ (—Å—Ç–∞—Ä–æ–π –∏–ª–∏ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞). –≠—Ç–∏–º –≤–æ–ª–Ω–∞–º –≤ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ —Å–¥–∞–≤–∞—Ç—å –Ω–æ–≤—ã–µ –º–∏–Ω–∏—ç–∫–∑–∞–º–µ–Ω—ã –Ω–µ –Ω—É–∂–Ω–æ. –î–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–º –≤–µ—Ç–∫–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–¥–∞—Ç—å 8-–π –ø—Ä–æ–µ–∫—Ç –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ + —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –≤–µ—Ç–∫–µ –±—É—Ç–∫—ç–º–ø (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ –≤ —É—Å–ª–æ–≤–∏—è—Ö).\n\nk) –ß—Ç–æ –µ—Å–ª–∏ —è —Ä–∞–Ω–µ–µ —É—Å–ø–µ—à–Ω–æ —Ä–µ—à–∏–ª –º–æ–¥—É–ª—å–Ω—ã–π –ø—Ä–æ–µ–∫—Ç —ç–∫–∑–∞–º–µ–Ω–∞ –ø–æ –°++ –∏–ª–∏ DevOps, —ç—Ç–æ –∑–∞—á—Ç–µ—Ç—Å—è?\n–î–∞, –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ —É—á–∏—Ç—ã–≤–∞—é—Ç —Å–¥–∞—á—É —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π —ç–∫–∑–∞–º–µ–Ω–æ–≤ –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é.\n\n\n\nCareer track (–ö–∞—Ä—å–µ—Ä–Ω—ã–π —Ç—Ä–µ–∫)\n–ö–∞—Ä—å–µ—Ä–Ω—ã–π —Ç—Ä–µ–∫ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∏–∑ —Å–µ–±—è –º–æ–¥—É–ª—å–Ω—ã–π –ø—Ä–æ–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ 8 –ø—Ä–æ–µ–∫—Ç–æ–≤:\n\n–°–∞–º–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n–†–∞–±–æ—Ç–∞ –º–µ—á—Ç—ã\nCV (–†–µ–∑—é–º–µ)\n–ò–Ω—Ç–µ—Ä–≤—å—é\n–†–∞–±–æ—Ç–∞ –≤ –∫–æ–º–∞–Ω–¥–µ (–≥—Ä—É–ø–ø–æ–≤–æ–π)\n–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –∫—É–ª—å—Ç—É—Ä–∞ –∏ —ç—Ç–∏–∫–∞ (–Ω–æ—Ä–º—ã) —Ä–∞–±–æ—Ç—ã\n–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è\n–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è\n–†–∞–Ω—å—à–µ –ö–∞—Ä—å–µ—Ä–Ω—ã–π —Ç—Ä–µ–∫ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–ª –∏–∑ —Å–µ–±—è –º–æ–¥—É–ª—å–Ω—ã–π –ø—Ä–æ–µ–∫—Ç, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã–π –≤ –∫–æ–Ω—Ü–µ –≤—Å–µ—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ –ë–∞–∑—ã: —á—Ç–æ–±—ã –ø–µ—Ä–µ–π—Ç–∏ –∫ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–º –≤–µ—Ç–∫–∞–º, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –±—ã–ª–æ –µ–≥–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ–π—Ç–∏, –Ω–æ –¥–ª—è –º–Ω–æ–≥–∏—Ö —ç—Ç–æ –±—ã–ª–æ —É–∂–µ –ø–æ–∑–¥–Ω–æ –∏ –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω–æ.\n\n\n–ß—Ç–æ –ø–æ–º–µ–Ω—è–ª–æ—Å—å?\n\n–ö–∞—Ä—å–µ—Ä–Ω–æ–µ —Ü–µ–ª–µ–ø–æ–ª–∞–≥–∞–Ω–∏–µ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ä—ã–Ω–∫–∞ —Ç—Ä—É–¥–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –∫–∞–∫ –º–æ–∂–Ω–æ —Ä–∞–Ω—å—à–µ, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –±–æ–ª–µ–µ –æ—Å–æ–∑–Ω–∞–Ω–Ω–æ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ—é —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é —Ä–∞–∑–≤–∏—Ç–∏—è –≤ —Ä–∞–º–∫–∞—Ö –æ–±—É—á–µ–Ω–∏—è. –ü–æ—ç—Ç–æ–º—É –ø–µ—Ä–≤—ã–µ –¥–≤–∞ –ø—Ä–æ–µ–∫—Ç–∞ –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ —Å—Ç–∞–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –ø–æ—Å–ª–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è C3. –ß—Ç–æ–±—ã –ø–µ—Ä–µ–π—Ç–∏ –∫ C5 –∏–ª–∏ DO1, —Ç–µ–ø–µ—Ä—å –Ω—É–∂–Ω–æ –∑–∞–≤–µ—Ä—à–∏—Ç—å —ç—Ç–∏ 2 –ø—Ä–æ–µ–∫—Ç–∞.\n–û—Å—Ç–∞–≤—à–∏–µ—Å—è –ø—Ä–æ–µ–∫—Ç—ã –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ —Ç–µ–ø–µ—Ä—å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è, —Ç–æ –µ—Å—Ç—å –Ω–µ –±–ª–æ–∫–∏—Ä—É—é—Ç –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–µ –ø–æ –≥—Ä–∞—Ñ—É, –æ–¥–Ω–∞–∫–æ —Å—Ç–∞–ª–∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º–∏ –¥–ª—è –ø–æ–ø–∞–¥–∞–Ω–∏—è –≤ –∫–∞–Ω–∞–ª internship —Å–≤–æ–µ–≥–æ –∫–∞–º–ø—É—Å–∞, –Ω–æ –æ–± —ç—Ç–æ–º –Ω–∏–∂–µ.\n–î–æ–±–∞–≤–ª–µ–Ω –µ—â–µ –æ–¥–∏–Ω 8-–π –ø—Ä–æ–µ–∫—Ç: –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è. –≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Å—Ç–∞–ª —Ç–µ–º —Å–∞–º—ã–º –∑–∞–≤–µ—Ä—à–∞—é—â–∏–º —ç–ª–µ–º–µ–Ω—Ç–æ–º –ë–∞–∑—ã. –í –Ω–µ–º –Ω—É–∂–Ω–æ –æ–≥–ª—è–Ω—É—Ç—å—Å—è –Ω–∞ –ø—Ä–æ–π–¥–µ–Ω–Ω—ã–π –ø—É—Ç—å, –æ—Ç—Ä–µ—Ñ–ª–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ, –≤—ã—è–≤–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ –∞–Ω—Ç–∏-–ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è —Å–µ–±—è —Ü–µ–ª–∏ –∏ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é –Ω–∞ –æ—Å—Ç–∞–≤—à—É—é—Å—è —á–∞—Å—Ç—å –≥—Ä–∞—Ñ–∞. –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–º —è–≤–ª—è–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–µ–∫—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∏ –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç –¥–æ—Å—Ç–∏—á—å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–≥–æ —É—Ä–æ–≤–Ω—è –¥–ª—è –≤—ã–ø—É—Å–∫–∞.\n–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥—É–ª—å–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ XP –Ω–∞—á–∏—Å–ª—è–µ—Ç—Å—è –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ, –∫–æ–≥–¥–∞ –æ–Ω —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø—Ä–æ–π–¥–µ–Ω. –í —Å–≤—è–∑–∏ —Å —Ç–µ–º, —á—Ç–æ –¥–≤–∞ –ø—Ä–æ–µ–∫—Ç–∞ –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ –º—ã –ø–µ—Ä–µ–Ω–µ—Å–ª–∏ –Ω–∞ –±–æ–ª–µ–µ —Ä–∞–Ω–Ω–∏–π —ç—Ç–∞–ø, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –æ–Ω–∏ –≤ –º–æ–º–µ–Ω—Ç–µ –Ω–µ –ø—Ä–∏–Ω–æ—Å—è—Ç XP, –º—ã –ø—Ä–æ–¥–ª–∏–ª–∏ –æ–±—â–∏–µ –¥–µ–¥–ª–∞–π–Ω—ã –Ω–∞ –Ω–∞–±–æ—Ä —É—Ä–æ–≤–Ω–µ–π –Ω–∞ 1 –Ω–µ–¥–µ–ª—é. –ï—Å–ª–∏ –ø–∏—Ä —Ä–µ—à–∞–µ—Ç –Ω–∞ —Ä–∞–Ω–Ω–∏—Ö —ç—Ç–∞–ø–∞—Ö –ø—Ä–æ–π—Ç–∏ –∏ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–µ–∫—Ç—ã –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞, —Ç–æ –¥–æ–ª–∂–µ–Ω —É—á–∏—Ç—ã–≤–∞—Ç—å, —á—Ç–æ –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è, –∞ XP –≤ –º–æ–º–µ–Ω—Ç–µ –Ω–µ –¥–æ–±—Ä–∞—Ç—å. –ù–∞ –¥–∞–Ω–Ω–æ–º —ç—Ç–∞–ø–µ –ø–æ –ª–æ–≥–∏–∫–µ –æ–±—É—á–µ–Ω–∏—è –ø–∏—Ä –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω –Ω–∞ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–µ.\n\nl) –ï—Å–ª–∏ —è —É–∂–µ –ø—Ä–æ—à–µ–ª C5 –∏–ª–∏ DO1, —Ç–æ –Ω—É–∂–Ω–æ –ª–∏ –º–Ω–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –ø–µ—Ä–≤—ã–µ –¥–≤–∞ –ø—Ä–æ–µ–∫—Ç–∞ –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞?\n–ï—Å–ª–∏ –ø—Ä–æ—à–ª–∏ –∏ C5, –∏ DO1, —Ç–æ –≤–∞–º –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –ø—Ä–æ–π—Ç–∏ –ø–µ—Ä–≤—ã–µ –¥–≤–∞ –ø—Ä–æ–µ–∫—Ç–∞ –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –Ω–æ–≤–æ–º—É 8-–º—É –ø—Ä–æ–µ–∫—Ç—É –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π —è–≤–ª—è–µ—Ç—Å—è —Ñ–∏–Ω–∞–ª—å–Ω—ã–º –¥–ª—è –ë–∞–∑—ã. –ï—Å–ª–∏ –ø—Ä–æ—à–ª–∏ —Ç–æ–ª—å–∫–æ C5 –∏–ª–∏ —Ç–æ–ª—å–∫–æ DO1, —Ç–æ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫–æ –≤—Ç–æ—Ä–æ–º—É –≤–∞–º –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –ø—Ä–æ–π—Ç–∏ —ç—Ç–∏ –ø—Ä–æ–µ–∫—Ç—ã –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞.\n\n\nm) –ï—Å–ª–∏ —è —É–∂–µ –ø—Ä–æ—à–µ–ª –∫–∞—Ä—å–µ—Ä–Ω—ã–π —Ç—Ä–µ–∫, –Ω—É–∂–Ω–æ –ª–∏ –º–Ω–µ —Å–Ω–æ–≤–∞ –µ–≥–æ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å?\n\n–í–µ—Å—å –∫–∞—Ä—å–µ—Ä–Ω—ã–π —Ç—Ä–µ–∫ –∑–∞–Ω–æ–≤–æ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–µ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è. –†–µ—á—å –º–æ–∂–µ—Ç –∏–¥—Ç–∏ —Ç–æ–ª—å–∫–æ –æ 8-–º –ø—Ä–æ–µ–∫—Ç–µ. –≠—Ç–æ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –≤ —Å–ª—É—á–∞–µ –ø–µ—Ä–µ—Ö–æ–¥–∞ —Å –æ–¥–Ω–æ–π –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ–π –≤–µ—Ç–∫–∏ –Ω–∞ –¥—Ä—É–≥—É—é, –ø–æ—Å–∫–æ–ª—å–∫—É —É—Å–ª–æ–≤–∏–µ–º –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–µ—Ä–≤–æ–º—É –ø—Ä–æ–µ–∫—Ç—É –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ–π –≤–µ—Ç–∫–∏ –±—É–¥–µ—Ç –∏–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞.\nn) –ï—Å–ª–∏ —è –Ω–∞—Ö–æ–∂—É—Å—å –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞, —Ç–æ —á—Ç–æ –º–µ–Ω—è–µ—Ç—Å—è?\n–ß–∞—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–æ–≤ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º–∏ –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —á–∞—Å—Ç—å –≥—Ä–∞—Ñ–∞. –ü—Ä–∏ —ç—Ç–æ–º –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –µ—â–µ –æ–¥–∏–Ω –ø—Ä–æ–µ–∫—Ç –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è. –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –ø–æ–ø–∞—Å—Ç—å –≤ –∫–∞–Ω–∞–ª —Å—Ç–∞–∂–∏—Ä–æ–≤–æ–∫, —Ç–æ –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ –Ω—É–∂–Ω–æ –ø—Ä–æ–π—Ç–∏ –≤–µ—Å—å –∫–∞—Ä—å–µ—Ä–Ω—ã–π —Ç—Ä–µ–∫.\n\n\no) –ï—Å–ª–∏ —è —É–∂–µ –µ—Å—Ç—å –≤ –∫–∞–Ω–∞–ª–µ —Å—Ç–∞–∂–∏—Ä–æ–≤–æ–∫, –º–µ–Ω—è —É–¥–∞–ª—è—Ç, –µ—Å–ª–∏ —è –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é –Ω–æ–≤—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º?\n–ù–µ—Ç.\n\n\n\n–°—Ç–∞–∂–∏—Ä–æ–≤–∫–∞\np) –ö–æ–≥–¥–∞ —è –º–æ–≥—É –Ω–∞—á–∞—Ç—å –ø—Ä–æ–µ–∫—Ç internship?\n–°—Ç–∞–∂–∏—Ä–æ–≤–∫–∞ —Å—Ç–∞–ª–∞ –¥–æ—Å—Ç—É–ø–Ω–æ–π –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –ª—é–±–æ–π –º–æ–º–µ–Ω—Ç –¥–æ –Ω–∞—á–∞–ª–∞ –µ–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è. –°—Ç–∞–∂–∏—Ä–æ–≤–∫—É –Ω–µ–ª—å–∑—è –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–Ω–∏–º —á–∏—Å–ª–æ–º, –µ—Å–ª–∏ –æ–Ω–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å –∏–ª–∏ –ø—Ä–æ—à–ª–æ –±–æ–ª–µ–µ 1.5 –º–µ—Å—è—Ü–∞ —Å –µ–µ –Ω–∞—á–∞–ª–∞.\n–ï—Å–ª–∏ –∂–µ —Ä–µ—á—å –∏–¥–µ—Ç –æ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–º —Ç—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ, —Ç–æ –µ–≥–æ –º–æ–∂–Ω–æ –∑–∞–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å, –Ω–æ —ç—Ç–æ –±—É–¥–µ—Ç –∏–¥—Ç–∏ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —Ñ–ª–æ—É —Å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–π –∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–æ–π –æ—Ç –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫–∞.\n\nq) –ú–æ–≥—É –ª–∏ —è –ø—Ä–æ–¥–ª–∏—Ç—å –¥–µ–¥–ª–∞–π–Ω –ø–æ –ø—Ä–∏—á–∏–Ω–µ –≤—ã—Ö–æ–¥–∞ –Ω–∞ —Å—Ç–∞–∂–∏—Ä–æ–≤–∫—É?\n–ü—Ä–æ–¥–ª–∏—Ç—å –¥–µ–¥–ª–∞–π–Ω –º–æ–∂–Ω–æ, –µ—Å–ª–∏ –≤ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç —Ç—ã –Ω–∞—Ö–æ–¥–∏—à—å—Å—è –Ω–∞ –ø—Ä–æ–µ–∫—Ç–∞—Ö –ë–∞–∑—ã. –í —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –ø–æ—Å–ª–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–∏ —É —Ç–µ–±—è –µ—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–ª–∏—Ç—å –≤—Å–µ –¥–µ–¥–ª–∞–π–Ω—ã –Ω–∞ –≤—Ä–µ–º—è —ç—Ç–æ–π —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–∏.\n\n–£—Å–ª–æ–≤–∏—è –ø—Ä–æ–¥–ª–µ–Ω–∏—è:\n\nadm –ø—Ä–æ–¥–ª–µ–≤–∞–µ—Ç –¥–µ–¥–ª–∞–π–Ω –∏–∑-–∑–∞ —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É –Ω–∞ –ø–æ—á—Ç–µ.\n–í–ê–ñ–ù–û! –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–¥–ª–µ–Ω–∏–µ –Ω–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç;\n–¥–µ–¥–ª–∞–π–Ω –ø—Ä–æ–¥–ª–µ–≤–∞–µ—Ç—Å—è –Ω–∞ —Å—Ä–æ–∫, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –¥–∞—Ç–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–∏.\n–ü—Ä–∏–º–µ—Ä: —Ç—ã –ø—Ä–∏—Å–ª–∞–ª –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø—Ä–æ–¥–ª–µ–Ω–∏–µ –¥–¥–ª –∑–∞ 20 –¥–Ω–µ–π –¥–æ –æ–∫–æ–Ω—á–∞–Ω–∏—è —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–∏, –¥–¥–ª –±—É–¥–µ—Ç –ø—Ä–æ–¥–ª–µ–Ω –Ω–∞ 20 –¥–Ω–µ–π.\n–ï—Å–ª–∏ —Ç—ã —Ñ–µ–π–ª–∏—à—å —Å—Ç–∞–∂–∏—Ä–æ–≤–∫—É –Ω–∞ —ç—Ç–∞–ø–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –ë–∞–∑—ã, —Ç–æ –ø—Ä–æ–¥–ª–µ–Ω–∏–µ –¥–µ–¥–ª–∞–π–Ω–∞ –Ω–∞ —ç—Ç–æ–º –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è.\n–ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–µ–π–ª–∞ —Ç—ã —Å–Ω–æ–≤–∞ –Ω–∞—Ö–æ–¥–∏—à—å —Å—Ç–∞–∂–∏—Ä–æ–≤–∫—É –≤–æ –≤—Ä–µ–º—è –ë–∞–∑—ã, —Ç–æ –º–æ–∂–µ—à—å —Å–Ω–æ–≤–∞ –∑–∞–ø—Ä–æ—Å–∏—Ç—å –Ω–æ–≤–æ–µ –ø—Ä–æ–¥–ª–µ–Ω–∏–µ –¥–µ–¥–ª–∞–π–Ω–∞ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å–æ —Å—Ä–æ–∫–æ–º –µ–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è.\n\nr) –ö–∞–∫ –ø–æ–ø–∞—Å—Ç—å –≤ –∫–∞–Ω–∞–ª #internship —Å–≤–æ–µ–≥–æ –∫–∞–º–ø—É—Å–∞?\n–î–æ—Å—Ç—É–ø –≤ –∫–∞–Ω–∞–ª #internship —Å–≤–æ–µ–≥–æ –∫–∞–º–ø—É—Å–∞ –∏ –∫ –≤–æ–ª–Ω–∞–º —Å—Ç–∞–∂–∏—Ä–æ–≤–æ–∫ –°–±–µ—Ä–∞:\n\n–ª–∏–±–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –º–∏–Ω–∏-—ç–∫–∑–∞–º–µ–Ω–∞ –ø–æ —è–∑—ã–∫–æ–≤–æ–π –≤–µ—Ç–∫–µ –≤–Ω—É—Ç—Ä–∏ –ë–∞–∑—ã (–≤ —Å–ª—É—á–∞–µ –∏–∑—É—á–µ–Ω–∏—è Go, —ç—Ç–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ AP2: SmartCalc –∏–ª–∏ BrickGame –Ω–∞ Go) + –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ (–ø—Ä–æ–µ–∫—Ç—ã 02-07)\n–ª–∏–±–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –º–∏–Ω–∏-—ç–∫–∑–∞–º–µ–Ω–æ–≤ –ø–æ DevOps –∏ SQL + –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ (–ø—Ä–æ–µ–∫—Ç—ã 02-07).\n–ú–∏–Ω–∏-—ç–∫–∑–∞–º–µ–Ω —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –∫–∞–∫ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—é. –ö–∞—Ä—å–µ—Ä–Ω—ã–π —Ç—Ä–µ–∫ –ø–æ–º–æ–≥–∞–µ—Ç \"—É–ø–∞–∫–æ–≤–∞—Ç—å—Å—è\" —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è —Ä–µ–∑—é–º–µ –∏ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∏—Å—å–º–∞, –∞ —Ç–∞–∫–∂–µ –±–æ–ª—å—à–µ –ø–æ–Ω—è—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–±–æ—Ç—ã –≤ –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è—Ö.\n–¢–∞–∫–∂–µ —Å–¥–µ–ª–∞–ª–∏ —à–∞–≥ –Ω–∞–≤—Å—Ç—Ä–µ—á—É —Ç–µ–º, –∫—Ç–æ –¥–≤–∏–≥–∞–µ—Ç—Å—è –ø–æ —Ç—Ä–µ–∫—É DevOps, –∏ –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –±–æ–ª—å—à–æ–π —Å–ø—Ä–æ—Å —É –°–±–µ—Ä–∞. –£ –≤–∞—Å –ø–æ—è–≤–∏–ª—Å—è –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ç—Ä–µ–∫ –≤ —ç—Ç–æ—Ç –∫–∞–Ω–∞–ª.\n\n–®–∫–æ–ª–∞ –∏–∑–º–µ–Ω–∏–ª–∞ –ø—Ä–∞–≤–∏–ª–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–∏ –∏ —Ä–∞—Å—à–∏—Ä–∏–ª–∞ —Å–ø–∏—Å–æ–∫ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–µ–π. –ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–∏ –∏ –∫—Ä–∏—Ç–µ—Ä–∏—è—Ö –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —ç—Ç–æ–º –≥–∞–π–¥–µ.\n\n\n\n–í—ã–ø—É—Å–∫\n–°–ø–∏—Å–æ–∫ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª–µ–π –ø–æ –∫–ª–∞—Å—Å–∞–º\n–£–∫–∞–∑–∞–Ω–Ω—ã–µ –≤ –Ω–∞—á–∞–ª–µ FAQ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è ¬´–û—Å–Ω–æ–≤–Ω–æ–≥–æ¬ª —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞.\n–†–∞–Ω–µ–µ –≤—ã –º–æ–≥–ª–∏ –ø–æ–ª—É—á–∏—Ç—å –ª–∏–±–æ ¬´–û—Å–Ω–æ–≤–Ω–æ–π¬ª —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç, –ª–∏–±–æ ¬´–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π¬ª.\n–¢–µ–ø–µ—Ä—å –≤—ã —Å–º–æ–∂–µ—Ç–µ –≤—ã–ø—É—Å—Ç–∏—Ç—å—Å—è –Ω–∞ ¬´–û—Å–Ω–æ–≤–Ω–æ–º¬ª —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–µ, –∞ –ø–æ—Ç–æ–º –ø—Ä–æ–∫–∞—á–∞—Ç—å –µ–≥–æ –¥–æ ¬´–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ¬ª\n\n\ns) –Ø —Ö–æ—á—É –≤—ã–ø—É—Å—Ç–∏—Ç—å—Å—è, —á—Ç–æ –¥–µ–ª–∞—Ç—å?\n–ï—Å–ª–∏ —Ç—ã –≥–æ—Ç–æ–≤ –≤—ã–ø—É—Å—Ç–∏—Ç—å—Å—è –∏ –ø–æ–¥—Ö–æ–¥–∏—à—å –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º - —Å–º–µ–ª–æ –∂–º–∏ –∫–Ω–æ–ø–∫—É ‚Äú–°—Ç–∞—Ç—å –≤—ã–ø—É—Å–∫–Ω–∏–∫–æ–º!‚Äù –Ω–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ\n–ü–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏ —Ç–≤–æ—è –∑–∞—è–≤–∫–∞ –ø–æ–ø–∞–¥–µ—Ç –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫—É –∫–æ–º–∞–Ω–¥–µ ADM/PIN. –ï—Å–ª–∏ —Ç—ã –ø–æ–¥—Ö–æ–¥–∏—à—å –ø–æ –≤—Å–µ–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º –≤—ã–ø—É—Å–∫–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–π–¥–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ, —Ç–µ–±–µ –±—É–¥–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∫–µ—Ç—É –≤—ã–ø—É—Å–∫–Ω–∏–∫–∞ –∏ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –≤—Å—Ç—Ä–µ—á—É-–≤—Ä—É—á–µ–Ω–∏–µ. –í—Å—Ç—Ä–µ—á–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º –≤—Ä—É—á–µ–Ω–∏–µ–º –∏–ª–∏ —Ç–æ—Ä–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –≤—ã–ø—É—Å–∫–Ω—ã–º.\n–ï—Å–ª–∏ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –æ–∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ —Ç—ã –Ω–µ –≤—ã–ø–æ–ª–Ω–∏–ª –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –¥–ª—è –≤—ã–ø—É—Å–∫–∞, —Å —Ç–æ–±–æ–π —Å–≤—è–∂–µ—Ç—Å—è –∫–æ–º–∞–Ω–¥–∞ ADM/PIN.\n\n\nt) –ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç?\n–ü–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –≤—ã–ø—É—Å–∫–Ω–∏–∫–∞ —Ç—ã —Å–º–æ–∂–µ—à—å –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –∏ –ø–æ–ª—É—á–∏—Ç—å —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Äú–û—Å–≤–æ–∏–ª –ø—Ä–æ–≥—Ä–∞–º–º—É –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∫—É—Ä—Å–∞‚Äù, –µ—Å–ª–∏:\n\n–∑–∞–≤–µ—Ä—à–∏—à—å –æ–¥–Ω—É –∏–∑ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã—Ö –≤–µ—Ç–æ–∫,\n–Ω–∞–±–µ—Ä–µ—à—å 13 —É—Ä–æ–≤–µ–Ω—å.\n\n–ü—Ä–∏ —ç—Ç–æ–º –Ω–µ –∫–∞–∂–¥–∞—è –≤–µ—Ç–∫–∞ –ø–æ—Å–ª–µ –ø—Ä–æ–µ–∫—Ç–æ–≤ –ë–∞–∑—ã –∑–∞—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –¥–ª—è –≤—ã–ø—É—Å–∫–∞ —Å —ç—Ç–∏–º —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–º. –ù–µ –∑–∞—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è:\n\n–≤–µ—Ç–∫–∞ A\n–≤–µ—Ç–∫–∞ AP\n–≤–µ—Ç–∫–∞ SQL\n–≤–µ—Ç–∫–∞ CPP\n–≤–µ—Ç–∫–∞ C\n–û—Å—Ç–∞–ª—å–Ω—ã–µ –≤–µ—Ç–∫–∏ –∑–∞—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –∑–∞ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–µ, –ø–æ—Å–∫–æ–ª—å–∫—É –¥–∞—é—Ç –ø–æ–Ω—è—Ç–Ω—É—é –¥–ª—è —Ä—ã–Ω–∫–∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é."
  }
]